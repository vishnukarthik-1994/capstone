{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bdfdad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import config\n",
    "from cnn_utils import (\n",
    "    get_model_instance_segmentation,\n",
    "    collate_fn,\n",
    "    get_transform,\n",
    "    myOwnDataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d2ed9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.10.0\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running on  cuda\n",
      "[{'boxes': tensor([[ 56.,  97.,  99., 121.],\n",
      "        [ 76., 123., 119., 142.],\n",
      "        [ 52., 148.,  97., 168.]], device='cuda:0'), 'labels': tensor([1, 1, 3], device='cuda:0'), 'image_id': tensor([154], device='cuda:0'), 'area': tensor([1032.,  817.,  900.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 64.,  72., 136., 147.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([256], device='cuda:0'), 'area': tensor([5400.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 60.,   4., 162., 221.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([96], device='cuda:0'), 'area': tensor([22134.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 79.,  58., 151., 120.],\n",
      "        [  7.,  60.,  78., 114.],\n",
      "        [ 68., 158., 108., 173.],\n",
      "        [ 82., 183., 140., 209.],\n",
      "        [169., 143., 191., 173.],\n",
      "        [148.,  78., 169., 107.]], device='cuda:0'), 'labels': tensor([0, 3, 2, 1, 3, 1], device='cuda:0'), 'image_id': tensor([86], device='cuda:0'), 'area': tensor([4464., 3834.,  600., 1508.,  660.,  609.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 82., 124., 121., 147.],\n",
      "        [111.,  11., 153.,  43.]], device='cuda:0'), 'labels': tensor([3, 1], device='cuda:0'), 'image_id': tensor([138], device='cuda:0'), 'area': tensor([ 897., 1344.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 58.,  45., 209., 186.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([41], device='cuda:0'), 'area': tensor([21291.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 81., 105., 158., 158.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([241], device='cuda:0'), 'area': tensor([4081.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 78., 175.,  88., 183.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([109], device='cuda:0'), 'area': tensor([80.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 87.,  64., 188., 160.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([16], device='cuda:0'), 'area': tensor([9696.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[115., 119., 152., 177.],\n",
      "        [144.,  94., 161., 109.]], device='cuda:0'), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([278], device='cuda:0'), 'area': tensor([2146.,  255.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 57.,  92., 129., 134.],\n",
      "        [162., 114., 212., 144.]], device='cuda:0'), 'labels': tensor([0, 1], device='cuda:0'), 'image_id': tensor([63], device='cuda:0'), 'area': tensor([3024., 1500.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[171.,  14., 193.,  43.],\n",
      "        [118., 197., 133., 216.]], device='cuda:0'), 'labels': tensor([2, 3], device='cuda:0'), 'image_id': tensor([307], device='cuda:0'), 'area': tensor([638., 285.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[143.,  51., 168.,  99.],\n",
      "        [ 91., 136., 114., 175.],\n",
      "        [ 93.,  91., 108., 116.]], device='cuda:0'), 'labels': tensor([1, 1, 1], device='cuda:0'), 'image_id': tensor([9], device='cuda:0'), 'area': tensor([1200.,  897.,  375.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 42.,  17., 198.,  92.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([70], device='cuda:0'), 'area': tensor([11700.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 29.,  40., 152., 100.],\n",
      "        [176.,  31., 224.,  66.]], device='cuda:0'), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([271], device='cuda:0'), 'area': tensor([7380., 1680.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 76., 119., 100., 222.],\n",
      "        [ 80.,   0., 115.,  99.]], device='cuda:0'), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([297], device='cuda:0'), 'area': tensor([2472., 3465.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[103.,  98., 158., 156.],\n",
      "        [ 69., 104.,  94., 131.]], device='cuda:0'), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([77], device='cuda:0'), 'area': tensor([3190.,  675.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 78., 139., 126., 165.],\n",
      "        [ 71.,  26., 122.,  74.],\n",
      "        [154., 147., 196., 194.],\n",
      "        [121., 124., 155., 171.],\n",
      "        [ 48.,  39.,  70.,  67.]], device='cuda:0'), 'labels': tensor([0, 0, 2, 0, 1], device='cuda:0'), 'image_id': tensor([216], device='cuda:0'), 'area': tensor([1248., 2448., 1974., 1598.,  616.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 31.,  16., 123.,  69.],\n",
      "        [152.,  32., 168.,  62.]], device='cuda:0'), 'labels': tensor([2, 1], device='cuda:0'), 'image_id': tensor([185], device='cuda:0'), 'area': tensor([4876.,  480.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 79.,  84., 151., 129.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([277], device='cuda:0'), 'area': tensor([3240.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[56., 43., 79., 82.]], device='cuda:0'), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([227], device='cuda:0'), 'area': tensor([897.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 46.,  94., 179., 156.],\n",
      "        [  3.,   0., 189.,  73.]], device='cuda:0'), 'labels': tensor([2, 0], device='cuda:0'), 'image_id': tensor([197], device='cuda:0'), 'area': tensor([ 8246., 13578.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[175.,  79., 207., 125.],\n",
      "        [ 40.,  70.,  77., 104.]], device='cuda:0'), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([156], device='cuda:0'), 'area': tensor([1472., 1258.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[140.,  95., 166., 120.],\n",
      "        [153.,  57., 181.,  68.],\n",
      "        [130.,  80., 154.,  96.],\n",
      "        [132.,  99., 141., 113.]], device='cuda:0'), 'labels': tensor([1, 0, 0, 0], device='cuda:0'), 'image_id': tensor([110], device='cuda:0'), 'area': tensor([650., 308., 384., 126.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 78.,  74., 115.,  80.],\n",
      "        [ 77.,  81., 157., 115.],\n",
      "        [ 12., 111.,  62., 138.]], device='cuda:0'), 'labels': tensor([1, 1, 1], device='cuda:0'), 'image_id': tensor([215], device='cuda:0'), 'area': tensor([ 222., 2720., 1350.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 24.,  44.,  56.,  88.],\n",
      "        [126.,  53., 164., 107.],\n",
      "        [  5.,  63.,  17.,  87.],\n",
      "        [ 30.,  95.,  62., 135.]], device='cuda:0'), 'labels': tensor([1, 1, 3, 3], device='cuda:0'), 'image_id': tensor([312], device='cuda:0'), 'area': tensor([1408., 2052.,  288., 1280.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 60.,  88.,  78., 112.],\n",
      "        [ 87.,  85., 122., 122.]], device='cuda:0'), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([300], device='cuda:0'), 'area': tensor([ 432., 1295.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[122., 180., 179., 205.],\n",
      "        [161.,   0., 224.,  47.],\n",
      "        [133.,  89., 156., 103.]], device='cuda:0'), 'labels': tensor([2, 2, 3], device='cuda:0'), 'image_id': tensor([265], device='cuda:0'), 'area': tensor([1425., 2961.,  322.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[102.,  32., 200.,  93.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([306], device='cuda:0'), 'area': tensor([5978.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 54.,  47., 100., 113.]], device='cuda:0'), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([287], device='cuda:0'), 'area': tensor([3036.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 55.,  21., 210., 117.]], device='cuda:0'), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([78], device='cuda:0'), 'area': tensor([14880.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[151.,  44., 193.,  80.],\n",
      "        [116., 148., 180., 180.]], device='cuda:0'), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([12], device='cuda:0'), 'area': tensor([1512., 2048.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 74.,  79., 131., 148.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([148], device='cuda:0'), 'area': tensor([3933.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[117.,  41., 145.,  93.],\n",
      "        [ 75.,  77., 120., 142.]], device='cuda:0'), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([22], device='cuda:0'), 'area': tensor([1456., 2925.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[  8.,  18., 176., 138.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([319], device='cuda:0'), 'area': tensor([20160.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 71.,  67., 153., 119.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([54], device='cuda:0'), 'area': tensor([4264.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[101., 130., 135., 183.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([95], device='cuda:0'), 'area': tensor([1802.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[139.,  22., 187.,  53.],\n",
      "        [159., 120., 191., 166.],\n",
      "        [100.,  31., 132.,  71.],\n",
      "        [ 76., 101., 119., 148.],\n",
      "        [130.,  74., 147., 116.],\n",
      "        [ 64.,  55.,  95.,  77.],\n",
      "        [ 48., 108.,  76., 156.]], device='cuda:0'), 'labels': tensor([0, 0, 1, 1, 1, 1, 2], device='cuda:0'), 'image_id': tensor([82], device='cuda:0'), 'area': tensor([1488., 1472., 1280., 2021.,  714.,  682., 1344.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0, 0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 85., 102., 157., 189.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([99], device='cuda:0'), 'area': tensor([6264.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[105., 127., 123., 142.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([243], device='cuda:0'), 'area': tensor([270.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[148., 110., 193., 132.],\n",
      "        [123.,  88., 170., 109.],\n",
      "        [144.,  63., 190.,  86.]], device='cuda:0'), 'labels': tensor([1, 1, 1], device='cuda:0'), 'image_id': tensor([193], device='cuda:0'), 'area': tensor([ 990.,  987., 1058.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'boxes': tensor([[ 53.,  47., 101., 107.]], device='cuda:0'), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([190], device='cuda:0'), 'area': tensor([2880.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[139.,  92., 180., 143.],\n",
      "        [ 25., 104.,  66., 152.],\n",
      "        [ 12., 110.,  26., 142.]], device='cuda:0'), 'labels': tensor([2, 2, 2], device='cuda:0'), 'image_id': tensor([160], device='cuda:0'), 'area': tensor([2091., 1968.,  448.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 87., 105., 175., 143.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([280], device='cuda:0'), 'area': tensor([3344.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 74., 137.,  92., 172.]], device='cuda:0'), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([240], device='cuda:0'), 'area': tensor([630.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[144., 121., 190., 150.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([294], device='cuda:0'), 'area': tensor([1334.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 56.,  83., 186., 132.],\n",
      "        [186.,  45., 224., 104.]], device='cuda:0'), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([140], device='cuda:0'), 'area': tensor([6370., 2242.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[114., 104., 132., 118.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([135], device='cuda:0'), 'area': tensor([252.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[78., 69., 94., 89.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([152], device='cuda:0'), 'area': tensor([320.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 54.,  25., 216., 182.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([14], device='cuda:0'), 'area': tensor([25434.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 67.,  71., 135., 160.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([62], device='cuda:0'), 'area': tensor([6052.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 65.,  84., 156., 185.],\n",
      "        [ 78.,  48., 139.,  84.],\n",
      "        [ 83., 189., 133., 214.]], device='cuda:0'), 'labels': tensor([0, 0, 0], device='cuda:0'), 'image_id': tensor([28], device='cuda:0'), 'area': tensor([9191., 2196., 1250.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 48.,  97., 217., 187.]], device='cuda:0'), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([168], device='cuda:0'), 'area': tensor([15210.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[176.,  29., 209.,  84.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([89], device='cuda:0'), 'area': tensor([1815.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 55., 152., 104., 168.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([121], device='cuda:0'), 'area': tensor([784.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[141.,  92., 181., 132.],\n",
      "        [163., 139., 196., 167.],\n",
      "        [127., 206., 171., 220.]], device='cuda:0'), 'labels': tensor([3, 1, 1], device='cuda:0'), 'image_id': tensor([101], device='cuda:0'), 'area': tensor([1600.,  924.,  616.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[151.,  92., 198., 150.],\n",
      "        [ 15.,  53.,  50.,  97.]], device='cuda:0'), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([65], device='cuda:0'), 'area': tensor([2726., 1540.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 73.,  98., 121., 163.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([60], device='cuda:0'), 'area': tensor([3120.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 52.,   7., 107.,  38.],\n",
      "        [111.,  11., 155.,  32.],\n",
      "        [141.,  25., 183.,  48.],\n",
      "        [154.,  46., 198.,  63.],\n",
      "        [ 82.,  51., 123.,  71.]], device='cuda:0'), 'labels': tensor([2, 2, 2, 2, 3], device='cuda:0'), 'image_id': tensor([53], device='cuda:0'), 'area': tensor([1705.,  924.,  966.,  748.,  820.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 20.,  10., 105.,  71.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([226], device='cuda:0'), 'area': tensor([5185.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 86., 102., 136., 207.],\n",
      "        [154.,  74., 209., 149.]], device='cuda:0'), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([13], device='cuda:0'), 'area': tensor([5250., 4125.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 63., 130., 115., 160.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([142], device='cuda:0'), 'area': tensor([1560.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[109.,   1., 138.,  34.]], device='cuda:0'), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([200], device='cuda:0'), 'area': tensor([957.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[133.,  68., 187., 169.],\n",
      "        [ 90., 112., 130., 195.],\n",
      "        [ 55., 117.,  88., 168.],\n",
      "        [ 36.,  76.,  67., 135.]], device='cuda:0'), 'labels': tensor([0, 0, 0, 0], device='cuda:0'), 'image_id': tensor([187], device='cuda:0'), 'area': tensor([5454., 3320., 1683., 1829.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[  7.,  69., 158., 120.],\n",
      "        [ 83., 118., 170., 154.],\n",
      "        [118.,   1., 197.,  52.]], device='cuda:0'), 'labels': tensor([0, 0, 3], device='cuda:0'), 'image_id': tensor([3], device='cuda:0'), 'area': tensor([7701., 3132., 4029.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[132.,  23., 194.,  67.],\n",
      "        [202.,  88., 214., 119.],\n",
      "        [154., 141., 174., 149.]], device='cuda:0'), 'labels': tensor([1, 1, 3], device='cuda:0'), 'image_id': tensor([258], device='cuda:0'), 'area': tensor([2728.,  372.,  160.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[172.,  38., 215.,  69.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([91], device='cuda:0'), 'area': tensor([1333.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[105.,   2., 137.,  22.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([253], device='cuda:0'), 'area': tensor([640.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[134., 115., 146., 132.],\n",
      "        [111.,  98., 118., 113.],\n",
      "        [133.,  96., 140., 106.]], device='cuda:0'), 'labels': tensor([3, 3, 3], device='cuda:0'), 'image_id': tensor([238], device='cuda:0'), 'area': tensor([204., 105.,  70.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 55.,  69., 118., 170.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([162], device='cuda:0'), 'area': tensor([6363.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 94., 174., 134., 197.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([228], device='cuda:0'), 'area': tensor([920.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[199.,   8., 220.,  78.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([220], device='cuda:0'), 'area': tensor([1470.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 72., 143.,  94., 173.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([274], device='cuda:0'), 'area': tensor([660.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 81.,  17., 218.,  82.],\n",
      "        [ 80., 138., 135., 156.],\n",
      "        [193., 123., 222., 160.]], device='cuda:0'), 'labels': tensor([0, 0, 3], device='cuda:0'), 'image_id': tensor([33], device='cuda:0'), 'area': tensor([8905.,  990., 1073.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 22.,   2., 201.,  69.],\n",
      "        [ 91.,  92., 145., 120.],\n",
      "        [ 43., 138., 154., 192.]], device='cuda:0'), 'labels': tensor([0, 0, 2], device='cuda:0'), 'image_id': tensor([46], device='cuda:0'), 'area': tensor([11993.,  1512.,  5994.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[117.,  26., 148.,  48.],\n",
      "        [153.,  33., 184.,  54.]], device='cuda:0'), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([37], device='cuda:0'), 'area': tensor([682., 651.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 34.,  33.,  76.,  66.],\n",
      "        [156.,  69., 187., 115.]], device='cuda:0'), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([182], device='cuda:0'), 'area': tensor([1386., 1426.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[101.,  70., 157., 105.],\n",
      "        [  6.,  37.,  32.,  71.]], device='cuda:0'), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([189], device='cuda:0'), 'area': tensor([1960.,  884.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 67.,  85., 150., 129.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([236], device='cuda:0'), 'area': tensor([3652.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 42.,  28., 190.,  93.]], device='cuda:0'), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([120], device='cuda:0'), 'area': tensor([9620.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 28.,  72.,  77., 148.],\n",
      "        [ 99.,  59., 138., 142.]], device='cuda:0'), 'labels': tensor([1, 0], device='cuda:0'), 'image_id': tensor([130], device='cuda:0'), 'area': tensor([3724., 3237.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 63.,  25., 161.,  75.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([308], device='cuda:0'), 'area': tensor([4900.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[107., 115., 224., 173.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([92], device='cuda:0'), 'area': tensor([6786.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[135.,  37., 184.,  62.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([246], device='cuda:0'), 'area': tensor([1225.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 40.,  46.,  62.,  59.],\n",
      "        [ 57.,  38.,  73.,  50.],\n",
      "        [126.,  34., 149.,  55.],\n",
      "        [152.,  37., 173.,  54.],\n",
      "        [177.,  40., 189.,  56.]], device='cuda:0'), 'labels': tensor([2, 2, 1, 1, 1], device='cuda:0'), 'image_id': tensor([206], device='cuda:0'), 'area': tensor([286., 192., 483., 357., 192.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0, 0], device='cuda:0')}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'boxes': tensor([[115., 171., 130., 196.],\n",
      "        [ 64., 137.,  77., 156.]], device='cuda:0'), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([289], device='cuda:0'), 'area': tensor([375., 247.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 71.,  88., 127., 122.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([74], device='cuda:0'), 'area': tensor([1904.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[115.,  15., 171.,  73.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1], device='cuda:0'), 'area': tensor([3248.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 52.,  52., 117., 112.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([282], device='cuda:0'), 'area': tensor([3900.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[42., 56., 63., 96.]], device='cuda:0'), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([149], device='cuda:0'), 'area': tensor([840.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 93., 185., 147., 203.],\n",
      "        [123.,   1., 154.,  17.],\n",
      "        [205., 101., 222., 121.]], device='cuda:0'), 'labels': tensor([3, 2, 3], device='cuda:0'), 'image_id': tensor([39], device='cuda:0'), 'area': tensor([972., 496., 340.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[192., 129., 216., 159.],\n",
      "        [ 96., 125., 133., 157.],\n",
      "        [ 72., 134.,  94., 155.]], device='cuda:0'), 'labels': tensor([1, 1, 2], device='cuda:0'), 'image_id': tensor([161], device='cuda:0'), 'area': tensor([ 720., 1184.,  462.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[182.,  18., 212.,  63.],\n",
      "        [134., 169., 165., 206.]], device='cuda:0'), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([333], device='cuda:0'), 'area': tensor([1350., 1147.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[132., 103., 172., 122.],\n",
      "        [125.,  77., 180., 101.],\n",
      "        [174., 112., 206., 140.],\n",
      "        [170., 141., 189., 152.]], device='cuda:0'), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([10], device='cuda:0'), 'area': tensor([ 760., 1320.,  896.,  209.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[114., 155., 157., 188.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([268], device='cuda:0'), 'area': tensor([1419.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[144., 103., 189., 147.],\n",
      "        [103.,  69., 172.,  99.],\n",
      "        [113.,  20., 162.,  64.]], device='cuda:0'), 'labels': tensor([0, 0, 2], device='cuda:0'), 'image_id': tensor([179], device='cuda:0'), 'area': tensor([1980., 2070., 2156.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 36.,  26.,  78.,  63.],\n",
      "        [104., 130., 162., 157.],\n",
      "        [ 89., 163., 131., 190.]], device='cuda:0'), 'labels': tensor([2, 3, 3], device='cuda:0'), 'image_id': tensor([239], device='cuda:0'), 'area': tensor([1554., 1566., 1134.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 50., 125.,  86., 176.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([0], device='cuda:0'), 'area': tensor([1836.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 73.,  21., 110.,  31.],\n",
      "        [ 40.,  28.,  70.,  39.],\n",
      "        [ 87.,  57., 104.,  64.]], device='cuda:0'), 'labels': tensor([2, 2, 3], device='cuda:0'), 'image_id': tensor([283], device='cuda:0'), 'area': tensor([370., 330., 119.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 98.,  12., 191.,  71.],\n",
      "        [177.,  79., 224., 115.],\n",
      "        [136., 166., 176., 181.],\n",
      "        [119., 193., 146., 205.],\n",
      "        [194., 125., 203., 146.]], device='cuda:0'), 'labels': tensor([1, 2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([295], device='cuda:0'), 'area': tensor([5487., 1692.,  600.,  324.,  189.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 87.,  48., 162.,  98.],\n",
      "        [139.,  16., 203.,  42.]], device='cuda:0'), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([281], device='cuda:0'), 'area': tensor([3750., 1664.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[155.,  76., 190.,  92.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([325], device='cuda:0'), 'area': tensor([560.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 29.,  62., 149., 128.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([217], device='cuda:0'), 'area': tensor([7920.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 17.,  18., 224., 141.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([177], device='cuda:0'), 'area': tensor([25461.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 29.,  47., 193., 155.]], device='cuda:0'), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([153], device='cuda:0'), 'area': tensor([17712.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 71.,  57., 220., 111.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([6], device='cuda:0'), 'area': tensor([8046.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 49.,  56., 145., 157.],\n",
      "        [ 86.,   2., 136.,  21.]], device='cuda:0'), 'labels': tensor([1, 3], device='cuda:0'), 'image_id': tensor([105], device='cuda:0'), 'area': tensor([9696.,  950.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 65.,  71., 107., 129.],\n",
      "        [  0.,  62.,  22., 107.]], device='cuda:0'), 'labels': tensor([0, 2], device='cuda:0'), 'image_id': tensor([175], device='cuda:0'), 'area': tensor([2436.,  990.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 13.,  26.,  67., 155.],\n",
      "        [ 71.,   2., 103.,  69.],\n",
      "        [115.,  20., 143.,  77.],\n",
      "        [131.,  67., 176., 150.],\n",
      "        [ 85., 133., 122., 185.]], device='cuda:0'), 'labels': tensor([2, 2, 2, 2, 3], device='cuda:0'), 'image_id': tensor([72], device='cuda:0'), 'area': tensor([6966., 2144., 1596., 3735., 1924.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 79.,  53., 108.,  86.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([203], device='cuda:0'), 'area': tensor([957.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 76.,  94.,  90., 108.],\n",
      "        [ 92.,  85., 116., 107.],\n",
      "        [143.,  73., 164.,  98.]], device='cuda:0'), 'labels': tensor([1, 1, 1], device='cuda:0'), 'image_id': tensor([21], device='cuda:0'), 'area': tensor([196., 528., 525.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 16.,  94.,  56., 123.],\n",
      "        [157.,  74., 203.,  98.]], device='cuda:0'), 'labels': tensor([1, 3], device='cuda:0'), 'image_id': tensor([76], device='cuda:0'), 'area': tensor([1160., 1104.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 48., 122.,  89., 137.],\n",
      "        [146., 103., 179., 120.]], device='cuda:0'), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([219], device='cuda:0'), 'area': tensor([615., 561.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 57.,  90., 133., 135.],\n",
      "        [160., 108., 217., 142.]], device='cuda:0'), 'labels': tensor([0, 1], device='cuda:0'), 'image_id': tensor([25], device='cuda:0'), 'area': tensor([3420., 1938.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 56., 100., 134., 123.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([181], device='cuda:0'), 'area': tensor([1794.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 75.,   1., 118.,  26.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([314], device='cuda:0'), 'area': tensor([1075.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[105., 125., 128., 159.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([195], device='cuda:0'), 'area': tensor([782.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 81.,  64., 163., 166.],\n",
      "        [ 33.,  77.,  58., 123.]], device='cuda:0'), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([157], device='cuda:0'), 'area': tensor([8364., 1150.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[111.,  35., 199., 129.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([93], device='cuda:0'), 'area': tensor([8272.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[160.,  31., 194., 103.],\n",
      "        [ 11.,  10.,  71., 111.],\n",
      "        [100.,  26., 156., 104.]], device='cuda:0'), 'labels': tensor([2, 1, 1], device='cuda:0'), 'image_id': tensor([290], device='cuda:0'), 'area': tensor([2448., 6060., 4368.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[124.,   2., 154.,  32.]], device='cuda:0'), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([36], device='cuda:0'), 'area': tensor([900.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 41.,  81., 189., 135.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([52], device='cuda:0'), 'area': tensor([7992.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 96.,  81., 118., 123.],\n",
      "        [ 52.,  41.,  86., 104.],\n",
      "        [ 57., 110.,  95., 166.]], device='cuda:0'), 'labels': tensor([1, 1, 1], device='cuda:0'), 'image_id': tensor([44], device='cuda:0'), 'area': tensor([ 924., 2142., 2128.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 77., 116., 130., 171.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([90], device='cuda:0'), 'area': tensor([2915.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[17., 56., 49., 85.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([169], device='cuda:0'), 'area': tensor([928.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 58.,  80.,  87., 112.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([194], device='cuda:0'), 'area': tensor([928.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[119.,  19., 216., 195.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([68], device='cuda:0'), 'area': tensor([17072.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[125.,   2., 218., 165.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([309], device='cuda:0'), 'area': tensor([15159.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 92.,  65., 138., 142.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([128], device='cuda:0'), 'area': tensor([3542.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'boxes': tensor([[ 31.,   0., 215., 120.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([83], device='cuda:0'), 'area': tensor([22080.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[  0.,  31.,  38., 123.],\n",
      "        [ 48.,  10.,  89.,  89.],\n",
      "        [ 87.,   7., 119.,  76.],\n",
      "        [167., 102., 207., 160.],\n",
      "        [153.,  58., 183., 129.],\n",
      "        [122.,  38., 148.,  71.]], device='cuda:0'), 'labels': tensor([2, 2, 2, 3, 2, 3], device='cuda:0'), 'image_id': tensor([310], device='cuda:0'), 'area': tensor([3496., 3239., 2208., 2320., 2130.,  858.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 60., 104., 133., 128.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([210], device='cuda:0'), 'area': tensor([1752.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 70.,  22., 177.,  73.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([151], device='cuda:0'), 'area': tensor([5457.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[196.,   6., 218.,  83.],\n",
      "        [161., 134., 190., 202.]], device='cuda:0'), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([328], device='cuda:0'), 'area': tensor([1694., 1972.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 73.,  55.,  91.,  80.],\n",
      "        [ 72.,  84., 100., 122.],\n",
      "        [108.,  67., 117.,  80.]], device='cuda:0'), 'labels': tensor([2, 3, 2], device='cuda:0'), 'image_id': tensor([229], device='cuda:0'), 'area': tensor([ 450., 1064.,  117.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[181.,  59., 204.,  91.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([122], device='cuda:0'), 'area': tensor([736.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[  9.,   7., 173., 182.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([224], device='cuda:0'), 'area': tensor([28700.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 89.,  58., 130., 120.],\n",
      "        [ 72.,  15., 101.,  51.]], device='cuda:0'), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([326], device='cuda:0'), 'area': tensor([2542., 1044.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[124.,  36., 147.,  59.],\n",
      "        [ 62., 160.,  79., 181.]], device='cuda:0'), 'labels': tensor([1, 2], device='cuda:0'), 'image_id': tensor([24], device='cuda:0'), 'area': tensor([529., 357.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[170., 103., 188., 133.],\n",
      "        [ 56.,  83.,  83., 119.],\n",
      "        [107.,  11., 144.,  40.],\n",
      "        [ 72.,  24., 103.,  49.],\n",
      "        [ 53.,  36.,  73.,  79.],\n",
      "        [150.,   4., 190.,  35.]], device='cuda:0'), 'labels': tensor([2, 2, 2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([139], device='cuda:0'), 'area': tensor([ 540.,  972., 1073.,  775.,  860., 1240.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 16.,  42., 158., 182.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([127], device='cuda:0'), 'area': tensor([19880.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 73.,   8., 126.,  40.],\n",
      "        [167., 103., 204., 139.],\n",
      "        [ 48., 134., 124., 167.]], device='cuda:0'), 'labels': tensor([1, 3, 2], device='cuda:0'), 'image_id': tensor([31], device='cuda:0'), 'area': tensor([1696., 1332., 2508.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 98., 188., 171., 209.]], device='cuda:0'), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([178], device='cuda:0'), 'area': tensor([1533.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 57.,  15.,  93.,  29.],\n",
      "        [ 89.,   0., 134.,  15.]], device='cuda:0'), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([214], device='cuda:0'), 'area': tensor([504., 675.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 97.,  88., 140., 114.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([298], device='cuda:0'), 'area': tensor([1118.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 59.,  18.,  97.,  37.],\n",
      "        [104.,   5., 142.,  19.]], device='cuda:0'), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([104], device='cuda:0'), 'area': tensor([722., 532.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 47., 102.,  85., 120.],\n",
      "        [146.,  93., 179., 107.]], device='cuda:0'), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([322], device='cuda:0'), 'area': tensor([684., 462.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 24.,  55.,  86., 115.],\n",
      "        [ 10., 126.,  59., 156.],\n",
      "        [ 88.,  95., 177., 131.]], device='cuda:0'), 'labels': tensor([0, 2, 3], device='cuda:0'), 'image_id': tensor([276], device='cuda:0'), 'area': tensor([3720., 1470., 3204.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[151.,   9., 196.,  70.],\n",
      "        [ 64., 150., 110., 166.],\n",
      "        [ 57.,  85.,  78.,  96.]], device='cuda:0'), 'labels': tensor([0, 3, 3], device='cuda:0'), 'image_id': tensor([249], device='cuda:0'), 'area': tensor([2745.,  736.,  231.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 57., 103., 164., 150.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([150], device='cuda:0'), 'area': tensor([5029.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 49.,  10., 164., 160.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([17], device='cuda:0'), 'area': tensor([17250.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 36.,   7.,  66.,  52.],\n",
      "        [144.,  36., 163.,  62.]], device='cuda:0'), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([327], device='cuda:0'), 'area': tensor([1350.,  494.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 74., 181.,  79., 189.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([248], device='cuda:0'), 'area': tensor([40.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 28.,  93., 139., 158.],\n",
      "        [ 81.,  43., 201., 112.],\n",
      "        [129.,  21., 210.,  46.],\n",
      "        [157.,   0., 220.,  29.]], device='cuda:0'), 'labels': tensor([1, 1, 2, 1], device='cuda:0'), 'image_id': tensor([15], device='cuda:0'), 'area': tensor([7215., 8280., 2025., 1827.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 41.,   1., 222., 171.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([131], device='cuda:0'), 'area': tensor([30770.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 97.,  55., 182.,  76.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([213], device='cuda:0'), 'area': tensor([1785.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 48., 108.,  85., 151.],\n",
      "        [164.,  56., 185.,  94.],\n",
      "        [ 16., 136.,  33., 161.]], device='cuda:0'), 'labels': tensor([1, 3, 3], device='cuda:0'), 'image_id': tensor([267], device='cuda:0'), 'area': tensor([1591.,  798.,  425.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 4., 51., 33., 94.]], device='cuda:0'), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([332], device='cuda:0'), 'area': tensor([1247.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 85.,  88., 132., 115.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([292], device='cuda:0'), 'area': tensor([1269.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 75.,  51., 170., 125.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([85], device='cuda:0'), 'area': tensor([7030.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[141.,  52., 165., 101.],\n",
      "        [ 94., 140., 109., 174.],\n",
      "        [ 95.,  96., 109., 113.]], device='cuda:0'), 'labels': tensor([1, 1, 1], device='cuda:0'), 'image_id': tensor([61], device='cuda:0'), 'area': tensor([1176.,  510.,  238.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[173., 104., 202., 154.],\n",
      "        [ 52.,  68.,  82., 146.],\n",
      "        [ 87.,  39., 109., 128.],\n",
      "        [101.,  12., 142.,  44.],\n",
      "        [145.,  11., 153., 101.]], device='cuda:0'), 'labels': tensor([2, 2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([255], device='cuda:0'), 'area': tensor([1450., 2340., 1958., 1312.,  720.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 18.,   0., 124.,  77.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([87], device='cuda:0'), 'area': tensor([8162.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 21., 102.,  58., 173.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([112], device='cuda:0'), 'area': tensor([2627.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[117., 112., 141., 157.],\n",
      "        [140.,  83., 165., 158.]], device='cuda:0'), 'labels': tensor([1, 3], device='cuda:0'), 'image_id': tensor([23], device='cuda:0'), 'area': tensor([1080., 1875.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[115.,  83., 154., 140.],\n",
      "        [ 47.,  69.,  68., 125.]], device='cuda:0'), 'labels': tensor([1, 2], device='cuda:0'), 'image_id': tensor([174], device='cuda:0'), 'area': tensor([2223., 1176.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[117.,  81., 155., 146.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([126], device='cuda:0'), 'area': tensor([2470.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[132.,  44., 168., 130.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([84], device='cuda:0'), 'area': tensor([3096.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 42.,  72., 172., 125.],\n",
      "        [ 63.,  33., 153.,  65.],\n",
      "        [ 50.,   6., 171.,  29.]], device='cuda:0'), 'labels': tensor([2, 2, 1], device='cuda:0'), 'image_id': tensor([27], device='cuda:0'), 'area': tensor([6890., 2880., 2783.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[126., 161., 184., 191.],\n",
      "        [ 71.,   1.,  89.,  12.],\n",
      "        [ 50.,  52.,  72.,  78.]], device='cuda:0'), 'labels': tensor([3, 1, 3], device='cuda:0'), 'image_id': tensor([51], device='cuda:0'), 'area': tensor([1740.,  198.,  572.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'boxes': tensor([[ 41.,  89.,  69., 112.]], device='cuda:0'), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([305], device='cuda:0'), 'area': tensor([644.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 49.,  62., 121., 162.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([34], device='cuda:0'), 'area': tensor([7200.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 70.,  78., 120., 162.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([316], device='cuda:0'), 'area': tensor([4200.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[102.,  21., 168., 145.],\n",
      "        [163., 153., 215., 180.]], device='cuda:0'), 'labels': tensor([0, 0], device='cuda:0'), 'image_id': tensor([47], device='cuda:0'), 'area': tensor([8184., 1404.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 14.,  68.,  56.,  90.],\n",
      "        [203.,  73., 224.,  90.]], device='cuda:0'), 'labels': tensor([1, 3], device='cuda:0'), 'image_id': tensor([136], device='cuda:0'), 'area': tensor([924., 357.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[104., 104., 139., 141.],\n",
      "        [ 87.,  46., 109.,  75.]], device='cuda:0'), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([32], device='cuda:0'), 'area': tensor([1295.,  638.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 41.,   7., 145.,  65.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([94], device='cuda:0'), 'area': tensor([6032.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[138.,  74., 193., 114.],\n",
      "        [ 12.,  12.,  89.,  89.]], device='cuda:0'), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([167], device='cuda:0'), 'area': tensor([2200., 5929.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 84., 108., 114., 151.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([232], device='cuda:0'), 'area': tensor([1290.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[103.,  29., 193., 206.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([69], device='cuda:0'), 'area': tensor([15930.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[130., 101., 148., 160.]], device='cuda:0'), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([155], device='cuda:0'), 'area': tensor([1062.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 33.,  52.,  92.,  83.],\n",
      "        [103.,  54., 132.,  78.]], device='cuda:0'), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([30], device='cuda:0'), 'area': tensor([1829.,  696.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 69., 163.,  88., 186.],\n",
      "        [149., 103., 165., 122.]], device='cuda:0'), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([114], device='cuda:0'), 'area': tensor([437., 304.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 42.,  71.,  73., 103.],\n",
      "        [172.,  81., 203., 130.]], device='cuda:0'), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([303], device='cuda:0'), 'area': tensor([ 992., 1519.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[116.,  77., 157., 136.],\n",
      "        [ 30.,  58.,  53.,  91.]], device='cuda:0'), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([291], device='cuda:0'), 'area': tensor([2419.,  759.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 30.,  75., 120., 108.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([315], device='cuda:0'), 'area': tensor([2970.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 68.,  12.,  92.,  53.],\n",
      "        [147., 168., 170., 185.]], device='cuda:0'), 'labels': tensor([1, 3], device='cuda:0'), 'image_id': tensor([302], device='cuda:0'), 'area': tensor([984., 391.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 80.,   0., 137.,  24.],\n",
      "        [182.,  31., 211.,  49.],\n",
      "        [155.,  25., 174.,  40.]], device='cuda:0'), 'labels': tensor([2, 2, 2], device='cuda:0'), 'image_id': tensor([8], device='cuda:0'), 'area': tensor([1368.,  522.,  285.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 99.,  68., 132., 123.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([270], device='cuda:0'), 'area': tensor([1815.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[118.,  72., 170., 160.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([259], device='cuda:0'), 'area': tensor([4576.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 55.,  65., 177., 112.],\n",
      "        [ 92.,  42., 124.,  55.]], device='cuda:0'), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([180], device='cuda:0'), 'area': tensor([5734.,  416.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 61., 100.,  79., 112.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([331], device='cuda:0'), 'area': tensor([216.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[157., 140., 197., 179.],\n",
      "        [ 98.,  25., 168.,  95.],\n",
      "        [ 46.,  93.,  83., 143.]], device='cuda:0'), 'labels': tensor([2, 2, 2], device='cuda:0'), 'image_id': tensor([257], device='cuda:0'), 'area': tensor([1560., 4900., 1850.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 78., 105., 115., 151.],\n",
      "        [151.,  61., 172., 102.],\n",
      "        [ 55., 142.,  77., 176.]], device='cuda:0'), 'labels': tensor([1, 1, 1], device='cuda:0'), 'image_id': tensor([88], device='cuda:0'), 'area': tensor([1702.,  861.,  748.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 86.,  13., 150.,  41.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([272], device='cuda:0'), 'area': tensor([1792.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 68.,  26., 139., 149.],\n",
      "        [155.,  35., 198.,  91.]], device='cuda:0'), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([2], device='cuda:0'), 'area': tensor([8733., 2408.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[191.,  49., 216.,  70.],\n",
      "        [ 12.,  93.,  24., 104.]], device='cuda:0'), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([171], device='cuda:0'), 'area': tensor([525., 132.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 95.,   4., 142.,  47.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([137], device='cuda:0'), 'area': tensor([2021.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 36., 106.,  65., 123.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([244], device='cuda:0'), 'area': tensor([493.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[107.,  88., 153., 129.],\n",
      "        [ 84.,  96., 102., 126.]], device='cuda:0'), 'labels': tensor([0, 0], device='cuda:0'), 'image_id': tensor([208], device='cuda:0'), 'area': tensor([1886.,  540.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 82.,  87., 104., 104.],\n",
      "        [ 40.,  86.,  76.,  98.],\n",
      "        [ 30.,  62.,  56.,  84.]], device='cuda:0'), 'labels': tensor([1, 1, 1], device='cuda:0'), 'image_id': tensor([134], device='cuda:0'), 'area': tensor([374., 432., 572.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[180., 106., 206., 149.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([19], device='cuda:0'), 'area': tensor([1118.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 71., 141., 108., 214.],\n",
      "        [  9.,  75.,  63., 163.]], device='cuda:0'), 'labels': tensor([1, 3], device='cuda:0'), 'image_id': tensor([218], device='cuda:0'), 'area': tensor([2701., 4752.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 65.,  62., 112.,  94.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([132], device='cuda:0'), 'area': tensor([1504.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[116., 111., 145., 189.]], device='cuda:0'), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([223], device='cuda:0'), 'area': tensor([2262.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 31.,   3.,  96.,  81.],\n",
      "        [ 41.,  87., 120., 130.],\n",
      "        [ 72., 135., 124., 159.],\n",
      "        [ 90., 162., 149., 196.]], device='cuda:0'), 'labels': tensor([2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([209], device='cuda:0'), 'area': tensor([5070., 3397., 1248., 2006.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[130.,  32., 181.,  79.],\n",
      "        [ 35.,  48.,  68.,  87.]], device='cuda:0'), 'labels': tensor([1, 3], device='cuda:0'), 'image_id': tensor([119], device='cuda:0'), 'area': tensor([2397., 1287.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[169.,  65., 199., 119.],\n",
      "        [ 34.,  35.,  64.,  58.]], device='cuda:0'), 'labels': tensor([1, 3], device='cuda:0'), 'image_id': tensor([123], device='cuda:0'), 'area': tensor([1620.,  690.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 15.,  30., 186., 123.],\n",
      "        [ 17., 139., 117., 191.]], device='cuda:0'), 'labels': tensor([1, 2], device='cuda:0'), 'image_id': tensor([48], device='cuda:0'), 'area': tensor([15903.,  5200.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[143.,  31., 157.,  44.],\n",
      "        [169.,  45., 180.,  56.]], device='cuda:0'), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([252], device='cuda:0'), 'area': tensor([182., 121.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 35.,  90., 133., 116.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([71], device='cuda:0'), 'area': tensor([2548.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 12.,  35., 206., 108.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([201], device='cuda:0'), 'area': tensor([14162.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 95., 119., 118., 156.],\n",
      "        [ 97., 172., 127., 222.]], device='cuda:0'), 'labels': tensor([0, 1], device='cuda:0'), 'image_id': tensor([49], device='cuda:0'), 'area': tensor([ 851., 1500.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 76., 122., 123., 155.],\n",
      "        [ 48.,  15., 203.,  68.]], device='cuda:0'), 'labels': tensor([3, 0], device='cuda:0'), 'image_id': tensor([113], device='cuda:0'), 'area': tensor([1551., 8215.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 46.,  92., 121., 125.],\n",
      "        [ 78., 129., 132., 155.],\n",
      "        [150., 104., 177., 123.]], device='cuda:0'), 'labels': tensor([1, 1, 3], device='cuda:0'), 'image_id': tensor([263], device='cuda:0'), 'area': tensor([2475., 1404.,  513.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[51.,  3., 64., 25.]], device='cuda:0'), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([323], device='cuda:0'), 'area': tensor([286.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[192.,  27., 217.,  54.],\n",
      "        [144.,  36., 156.,  48.]], device='cuda:0'), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([266], device='cuda:0'), 'area': tensor([675., 144.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'boxes': tensor([[ 58., 141., 106., 159.],\n",
      "        [192., 107., 220., 127.]], device='cuda:0'), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([296], device='cuda:0'), 'area': tensor([864., 560.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[124.,   1., 151.,  18.],\n",
      "        [ 68., 186., 143., 206.],\n",
      "        [204., 100., 224., 121.]], device='cuda:0'), 'labels': tensor([2, 3, 3], device='cuda:0'), 'image_id': tensor([103], device='cuda:0'), 'area': tensor([ 459., 1500.,  420.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[103., 174., 143., 188.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([235], device='cuda:0'), 'area': tensor([560.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 51.,  31., 108.,  96.]], device='cuda:0'), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([234], device='cuda:0'), 'area': tensor([3705.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 36.,  73.,  61., 150.],\n",
      "        [ 55., 115.,  89., 173.],\n",
      "        [ 91., 114., 131., 196.],\n",
      "        [130.,  62., 191., 178.]], device='cuda:0'), 'labels': tensor([0, 0, 0, 0], device='cuda:0'), 'image_id': tensor([116], device='cuda:0'), 'area': tensor([1925., 1972., 3280., 7076.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 13., 105.,  79., 163.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([144], device='cuda:0'), 'area': tensor([3828.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 44.,  55., 103., 171.],\n",
      "        [118.,  57., 161., 160.]], device='cuda:0'), 'labels': tensor([0, 0], device='cuda:0'), 'image_id': tensor([176], device='cuda:0'), 'area': tensor([6844., 4429.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 67.,  76., 105., 112.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([183], device='cuda:0'), 'area': tensor([1368.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 19.,  59.,  48., 102.],\n",
      "        [156.,  85., 195., 139.],\n",
      "        [  0.,  74.,  11.,  95.]], device='cuda:0'), 'labels': tensor([3, 3, 3], device='cuda:0'), 'image_id': tensor([286], device='cuda:0'), 'area': tensor([1247., 2106.,  231.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[144.,  60., 183., 142.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([129], device='cuda:0'), 'area': tensor([3198.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 61., 186., 142., 211.],\n",
      "        [115.,   0., 144.,  13.],\n",
      "        [201.,  94., 220., 115.]], device='cuda:0'), 'labels': tensor([3, 2, 3], device='cuda:0'), 'image_id': tensor([57], device='cuda:0'), 'area': tensor([2025.,  377.,  399.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[122.,  47., 147.,  97.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([191], device='cuda:0'), 'area': tensor([1250.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[62., 22., 78., 44.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([293], device='cuda:0'), 'area': tensor([352.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 55.,  67., 105.,  99.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([5], device='cuda:0'), 'area': tensor([1600.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[113., 172., 168., 209.],\n",
      "        [193.,  86., 207., 121.]], device='cuda:0'), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([38], device='cuda:0'), 'area': tensor([2035.,  490.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 43.,  48., 206., 131.],\n",
      "        [116., 142., 221., 182.]], device='cuda:0'), 'labels': tensor([0, 2], device='cuda:0'), 'image_id': tensor([211], device='cuda:0'), 'area': tensor([13529.,  4200.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 41., 120.,  79., 150.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([40], device='cuda:0'), 'area': tensor([1140.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 12.,  83., 106., 116.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([81], device='cuda:0'), 'area': tensor([3102.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 69.,  96., 124., 177.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([42], device='cuda:0'), 'area': tensor([4455.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[127., 162., 150., 186.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([242], device='cuda:0'), 'area': tensor([552.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 48.,  30.,  89.,  43.],\n",
      "        [ 86.,  15., 133.,  36.],\n",
      "        [110.,  53., 138.,  72.]], device='cuda:0'), 'labels': tensor([1, 1, 1], device='cuda:0'), 'image_id': tensor([64], device='cuda:0'), 'area': tensor([533., 987., 532.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 75., 103., 160., 159.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([143], device='cuda:0'), 'area': tensor([4760.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 69.,   2., 120.,  42.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([202], device='cuda:0'), 'area': tensor([2040.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 87., 101., 139., 151.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([124], device='cuda:0'), 'area': tensor([2600.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 59.,  43., 140., 172.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([11], device='cuda:0'), 'area': tensor([10449.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 69.,  52., 121., 170.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([221], device='cuda:0'), 'area': tensor([6136.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[112., 102., 134., 114.],\n",
      "        [ 72., 107., 100., 121.]], device='cuda:0'), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([212], device='cuda:0'), 'area': tensor([264., 392.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[133.,  92., 159., 149.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([320], device='cuda:0'), 'area': tensor([1482.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[103.,  44., 204., 109.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([329], device='cuda:0'), 'area': tensor([6565.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[136.,  98., 173., 146.],\n",
      "        [ 22.,  77.,  59., 114.],\n",
      "        [  8.,  87.,  23., 121.]], device='cuda:0'), 'labels': tensor([2, 2, 2], device='cuda:0'), 'image_id': tensor([163], device='cuda:0'), 'area': tensor([1776., 1369.,  510.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 98., 130., 178., 155.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([26], device='cuda:0'), 'area': tensor([2000.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 98.,  97., 127., 128.],\n",
      "        [ 73., 110.,  91., 131.],\n",
      "        [192.,  98., 216., 129.]], device='cuda:0'), 'labels': tensor([3, 3, 3], device='cuda:0'), 'image_id': tensor([313], device='cuda:0'), 'area': tensor([899., 378., 744.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 84.,  75., 169., 126.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([7], device='cuda:0'), 'area': tensor([4335.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 73.,  58., 113.,  75.],\n",
      "        [ 40.,  89.,  65., 126.],\n",
      "        [ 65.,  98., 110., 122.]], device='cuda:0'), 'labels': tensor([2, 2, 1], device='cuda:0'), 'image_id': tensor([147], device='cuda:0'), 'area': tensor([ 680.,  925., 1080.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 83.,  76., 153., 117.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([43], device='cuda:0'), 'area': tensor([2870.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 77.,  68., 205., 132.],\n",
      "        [ 24., 120., 132., 159.],\n",
      "        [ 13., 155., 105., 184.],\n",
      "        [ 80.,  31., 170.,  55.],\n",
      "        [ 21.,   0., 175.,  15.]], device='cuda:0'), 'labels': tensor([2, 2, 2, 2, 1], device='cuda:0'), 'image_id': tensor([67], device='cuda:0'), 'area': tensor([8192., 4212., 2668., 2160., 2310.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 33.,   4., 133., 202.]], device='cuda:0'), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([260], device='cuda:0'), 'area': tensor([19800.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 3., 25., 82., 67.]], device='cuda:0'), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([261], device='cuda:0'), 'area': tensor([3318.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 53.,  61., 210., 146.],\n",
      "        [120., 154., 222., 197.]], device='cuda:0'), 'labels': tensor([1, 0], device='cuda:0'), 'image_id': tensor([111], device='cuda:0'), 'area': tensor([13345.,  4386.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 95.,  59., 147.,  83.],\n",
      "        [ 13.,   0.,  83.,  20.],\n",
      "        [ 60.,  13., 134.,  56.]], device='cuda:0'), 'labels': tensor([0, 2, 2], device='cuda:0'), 'image_id': tensor([284], device='cuda:0'), 'area': tensor([1248., 1400., 3182.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 90.,  13., 130.,  70.],\n",
      "        [ 52., 163.,  93., 194.]], device='cuda:0'), 'labels': tensor([1, 3], device='cuda:0'), 'image_id': tensor([118], device='cuda:0'), 'area': tensor([2280., 1271.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 49.,   5., 109.,  30.],\n",
      "        [110.,   8., 151.,  31.],\n",
      "        [144.,  22., 180.,  46.],\n",
      "        [159.,  44., 196.,  65.]], device='cuda:0'), 'labels': tensor([2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([301], device='cuda:0'), 'area': tensor([1500.,  943.,  864.,  777.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[108.,  63., 170.,  90.],\n",
      "        [ 18.,  51.,  52.,  62.]], device='cuda:0'), 'labels': tensor([0, 3], device='cuda:0'), 'image_id': tensor([254], device='cuda:0'), 'area': tensor([1674.,  374.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 94.,  30., 205., 147.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([108], device='cuda:0'), 'area': tensor([12987.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[117.,  87., 157., 139.],\n",
      "        [ 47.,  70.,  65.,  98.]], device='cuda:0'), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([55], device='cuda:0'), 'area': tensor([2080.,  504.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 60.,  99.,  90., 156.],\n",
      "        [ 47.,  47.,  70.,  91.],\n",
      "        [  2.,  39.,  43., 118.]], device='cuda:0'), 'labels': tensor([2, 2, 3], device='cuda:0'), 'image_id': tensor([222], device='cuda:0'), 'area': tensor([1710., 1012., 3239.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'boxes': tensor([[ 77.,  79., 106., 112.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([285], device='cuda:0'), 'area': tensor([957.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 95., 119., 116., 152.]], device='cuda:0'), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([186], device='cuda:0'), 'area': tensor([693.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[125.,  54., 162., 109.],\n",
      "        [  4.,  61.,  20.,  87.],\n",
      "        [ 26.,  42.,  58.,  86.],\n",
      "        [ 29.,  97.,  62., 136.]], device='cuda:0'), 'labels': tensor([1, 1, 1, 2], device='cuda:0'), 'image_id': tensor([106], device='cuda:0'), 'area': tensor([2035.,  416., 1408., 1287.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[160.,  18., 196.,  42.],\n",
      "        [109.,  25., 126.,  50.]], device='cuda:0'), 'labels': tensor([0, 0], device='cuda:0'), 'image_id': tensor([196], device='cuda:0'), 'area': tensor([864., 425.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[  6.,  93.,  57., 113.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([100], device='cuda:0'), 'area': tensor([1020.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 87., 103., 171., 199.],\n",
      "        [131.,   0., 179.,  52.]], device='cuda:0'), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([311], device='cuda:0'), 'area': tensor([8064., 2496.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[162., 104., 191., 141.],\n",
      "        [ 20.,  57.,  47.,  97.]], device='cuda:0'), 'labels': tensor([2, 3], device='cuda:0'), 'image_id': tensor([237], device='cuda:0'), 'area': tensor([1073., 1080.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 92., 132., 112., 168.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([275], device='cuda:0'), 'area': tensor([720.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[100.,  77., 123., 102.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([133], device='cuda:0'), 'area': tensor([575.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[158.,  98., 197., 161.],\n",
      "        [ 46.,  68., 100., 131.]], device='cuda:0'), 'labels': tensor([1, 2], device='cuda:0'), 'image_id': tensor([188], device='cuda:0'), 'area': tensor([2457., 3402.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[126.,  35., 189.,  95.],\n",
      "        [ 27.,  42.,  60.,  97.]], device='cuda:0'), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([56], device='cuda:0'), 'area': tensor([3780., 1815.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 64.,  46., 164., 117.],\n",
      "        [ 96., 195., 143., 216.]], device='cuda:0'), 'labels': tensor([0, 1], device='cuda:0'), 'image_id': tensor([4], device='cuda:0'), 'area': tensor([7100.,  987.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 87.,  61., 168., 163.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([29], device='cuda:0'), 'area': tensor([8262.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[177., 118., 216., 184.],\n",
      "        [ 46.,  59.,  83., 106.],\n",
      "        [ 21.,  66.,  38.,  91.]], device='cuda:0'), 'labels': tensor([1, 1, 1], device='cuda:0'), 'image_id': tensor([125], device='cuda:0'), 'area': tensor([2574., 1739.,  425.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 86.,  81., 154., 110.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([173], device='cuda:0'), 'area': tensor([1972.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 55., 136.,  82., 176.],\n",
      "        [111., 162., 133., 197.]], device='cuda:0'), 'labels': tensor([0, 1], device='cuda:0'), 'image_id': tensor([98], device='cuda:0'), 'area': tensor([1080.,  770.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 53., 131.,  86., 147.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([251], device='cuda:0'), 'area': tensor([528.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[  1.,  56., 197., 144.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([97], device='cuda:0'), 'area': tensor([17248.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 23.,   0., 104.,  21.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([262], device='cuda:0'), 'area': tensor([1701.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[153., 105., 194., 146.],\n",
      "        [109., 122., 132., 145.]], device='cuda:0'), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([334], device='cuda:0'), 'area': tensor([1681.,  529.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[  8.,  39., 102.,  86.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([66], device='cuda:0'), 'area': tensor([4418.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 59.,  56.,  98.,  82.],\n",
      "        [101.,  44., 172.,  74.]], device='cuda:0'), 'labels': tensor([2, 1], device='cuda:0'), 'image_id': tensor([184], device='cuda:0'), 'area': tensor([1014., 2130.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 76.,  79., 174., 128.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([159], device='cuda:0'), 'area': tensor([4802.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 92.,  28., 144.,  91.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([35], device='cuda:0'), 'area': tensor([3276.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[  1.,   9., 105.,  69.],\n",
      "        [105.,  44., 208.,  81.],\n",
      "        [  0.,  75., 112., 173.],\n",
      "        [131.,  79., 219., 111.],\n",
      "        [150., 118., 190., 132.]], device='cuda:0'), 'labels': tensor([0, 2, 0, 2, 2], device='cuda:0'), 'image_id': tensor([317], device='cuda:0'), 'area': tensor([ 6240.,  3811., 10976.,  2816.,   560.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 97., 171., 147., 187.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([204], device='cuda:0'), 'area': tensor([800.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[27., 24., 59., 84.]], device='cuda:0'), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([330], device='cuda:0'), 'area': tensor([1920.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 43.,  95., 199., 159.],\n",
      "        [106., 164., 194., 191.],\n",
      "        [ 26.,  62., 176.,  92.]], device='cuda:0'), 'labels': tensor([0, 2, 2], device='cuda:0'), 'image_id': tensor([170], device='cuda:0'), 'area': tensor([9984., 2376., 4500.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 33.,  13., 173., 189.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([75], device='cuda:0'), 'area': tensor([24640.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[150., 104., 181., 123.],\n",
      "        [ 63., 130., 137., 155.],\n",
      "        [ 35.,  95., 121., 126.]], device='cuda:0'), 'labels': tensor([0, 0, 0], device='cuda:0'), 'image_id': tensor([158], device='cuda:0'), 'area': tensor([ 589., 1850., 2666.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 72.,   1., 193.,  57.],\n",
      "        [123.,  61., 224., 106.],\n",
      "        [ 93., 107., 193., 147.],\n",
      "        [ 69., 146., 172., 188.],\n",
      "        [ 29., 187., 122., 216.]], device='cuda:0'), 'labels': tensor([0, 2, 0, 1, 1], device='cuda:0'), 'image_id': tensor([198], device='cuda:0'), 'area': tensor([6776., 4545., 4000., 4326., 2697.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 34.,  66.,  98., 116.],\n",
      "        [109.,  18., 133.,  40.],\n",
      "        [ 59.,  96., 162., 146.]], device='cuda:0'), 'labels': tensor([1, 2, 2], device='cuda:0'), 'image_id': tensor([18], device='cuda:0'), 'area': tensor([3200.,  528., 5150.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 57.,   2., 117.,  25.],\n",
      "        [ 82., 126., 109., 155.]], device='cuda:0'), 'labels': tensor([3, 2], device='cuda:0'), 'image_id': tensor([304], device='cuda:0'), 'area': tensor([1380.,  783.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 96., 145., 155., 173.]], device='cuda:0'), 'labels': tensor([0], device='cuda:0'), 'image_id': tensor([166], device='cuda:0'), 'area': tensor([1652.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 65.,  78., 151., 122.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([264], device='cuda:0'), 'area': tensor([3784.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 75., 118., 101., 143.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([207], device='cuda:0'), 'area': tensor([650.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 91., 116., 134., 172.],\n",
      "        [133.,  77., 155., 114.]], device='cuda:0'), 'labels': tensor([1, 3], device='cuda:0'), 'image_id': tensor([50], device='cuda:0'), 'area': tensor([2408.,  814.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 48.,  59., 209., 142.],\n",
      "        [103., 155., 221., 193.]], device='cuda:0'), 'labels': tensor([0, 2], device='cuda:0'), 'image_id': tensor([146], device='cuda:0'), 'area': tensor([13363.,  4484.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[125.,   0., 223.,  63.],\n",
      "        [ 39., 136., 175., 201.],\n",
      "        [146.,  77., 222., 127.],\n",
      "        [  0., 187.,  89., 223.]], device='cuda:0'), 'labels': tensor([2, 3, 3, 3], device='cuda:0'), 'image_id': tensor([250], device='cuda:0'), 'area': tensor([6174., 8840., 3800., 3204.], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 41.,  89., 123., 126.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([205], device='cuda:0'), 'area': tensor([3034.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 12.,  47.,  88.,  96.],\n",
      "        [ 47., 106., 102., 135.]], device='cuda:0'), 'labels': tensor([1, 2], device='cuda:0'), 'image_id': tensor([321], device='cuda:0'), 'area': tensor([3724., 1595.], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[104., 124., 127., 155.]], device='cuda:0'), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([164], device='cuda:0'), 'area': tensor([713.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n",
      "[{'boxes': tensor([[ 42.,  98., 131., 190.]], device='cuda:0'), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([58], device='cuda:0'), 'area': tensor([8188.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karthik\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1/306, Loss: 2.106976270675659\n",
      "Iteration: 2/306, Loss: 1.9484976530075073\n",
      "Iteration: 3/306, Loss: 1.5076851844787598\n",
      "Iteration: 4/306, Loss: 1.410470962524414\n",
      "Iteration: 5/306, Loss: 1.4985779523849487\n",
      "Iteration: 6/306, Loss: 0.8078312873840332\n",
      "Iteration: 7/306, Loss: 0.6464524865150452\n",
      "Iteration: 8/306, Loss: 0.33936911821365356\n",
      "Iteration: 9/306, Loss: 0.9657710790634155\n",
      "Iteration: 10/306, Loss: 0.37313854694366455\n",
      "Iteration: 11/306, Loss: 0.6037735939025879\n",
      "Iteration: 12/306, Loss: 0.5426183342933655\n",
      "Iteration: 13/306, Loss: 0.10720476508140564\n",
      "Iteration: 14/306, Loss: 0.48466697335243225\n",
      "Iteration: 15/306, Loss: 0.8216969966888428\n",
      "Iteration: 16/306, Loss: 0.16239774227142334\n",
      "Iteration: 17/306, Loss: 0.33453115820884705\n",
      "Iteration: 18/306, Loss: 0.16952195763587952\n",
      "Iteration: 19/306, Loss: 0.07147762179374695\n",
      "Iteration: 20/306, Loss: 0.20120839774608612\n",
      "Iteration: 21/306, Loss: 0.18156854808330536\n",
      "Iteration: 22/306, Loss: 0.02627553790807724\n",
      "Iteration: 23/306, Loss: 0.10394357144832611\n",
      "Iteration: 24/306, Loss: 0.22398489713668823\n",
      "Iteration: 25/306, Loss: 0.480469673871994\n",
      "Iteration: 26/306, Loss: 0.17943976819515228\n",
      "Iteration: 27/306, Loss: 0.19153867661952972\n",
      "Iteration: 28/306, Loss: 0.2121438831090927\n",
      "Iteration: 29/306, Loss: 0.13222937285900116\n",
      "Iteration: 30/306, Loss: 0.053028352558612823\n",
      "Iteration: 31/306, Loss: 0.06237422674894333\n",
      "Iteration: 32/306, Loss: 0.37341731786727905\n",
      "Iteration: 33/306, Loss: 0.31558701395988464\n",
      "Iteration: 34/306, Loss: 0.1841302067041397\n",
      "Iteration: 35/306, Loss: 0.5485074520111084\n",
      "Iteration: 36/306, Loss: 0.24358594417572021\n",
      "Iteration: 37/306, Loss: 0.20369300246238708\n",
      "Iteration: 38/306, Loss: 0.42509886622428894\n",
      "Iteration: 39/306, Loss: 0.3301916718482971\n",
      "Iteration: 40/306, Loss: 0.14692245423793793\n",
      "Iteration: 41/306, Loss: 0.6241604089736938\n",
      "Iteration: 42/306, Loss: 0.19709184765815735\n",
      "Iteration: 43/306, Loss: 0.10883811861276627\n",
      "Iteration: 44/306, Loss: 0.18806643784046173\n",
      "Iteration: 45/306, Loss: 0.36345505714416504\n",
      "Iteration: 46/306, Loss: 0.04762909561395645\n",
      "Iteration: 47/306, Loss: 0.3448094129562378\n",
      "Iteration: 48/306, Loss: 0.13579513132572174\n",
      "Iteration: 49/306, Loss: 0.27428194880485535\n",
      "Iteration: 50/306, Loss: 0.09588064253330231\n",
      "Iteration: 51/306, Loss: 0.2508821189403534\n",
      "Iteration: 52/306, Loss: 0.2563941180706024\n",
      "Iteration: 53/306, Loss: 0.13589859008789062\n",
      "Iteration: 54/306, Loss: 0.2570587396621704\n",
      "Iteration: 55/306, Loss: 0.08748573064804077\n",
      "Iteration: 56/306, Loss: 0.06528373062610626\n",
      "Iteration: 57/306, Loss: 0.6416382789611816\n",
      "Iteration: 58/306, Loss: 0.22016561031341553\n",
      "Iteration: 59/306, Loss: 0.06995664536952972\n",
      "Iteration: 60/306, Loss: 0.33555060625076294\n",
      "Iteration: 61/306, Loss: 0.1131751537322998\n",
      "Iteration: 62/306, Loss: 0.6568835973739624\n",
      "Iteration: 63/306, Loss: 0.08627975732088089\n",
      "Iteration: 64/306, Loss: 0.11886122822761536\n",
      "Iteration: 65/306, Loss: 0.16084836423397064\n",
      "Iteration: 66/306, Loss: 0.3946486711502075\n",
      "Iteration: 67/306, Loss: 0.535624086856842\n",
      "Iteration: 68/306, Loss: 0.07649505138397217\n",
      "Iteration: 69/306, Loss: 0.20960411429405212\n",
      "Iteration: 70/306, Loss: 0.06411191076040268\n",
      "Iteration: 71/306, Loss: 0.10122257471084595\n",
      "Iteration: 72/306, Loss: 0.6111108660697937\n",
      "Iteration: 73/306, Loss: 0.3376024067401886\n",
      "Iteration: 74/306, Loss: 0.08986888080835342\n",
      "Iteration: 75/306, Loss: 0.12456345558166504\n",
      "Iteration: 76/306, Loss: 0.5091451406478882\n",
      "Iteration: 77/306, Loss: 0.15462803840637207\n",
      "Iteration: 78/306, Loss: 0.06012425199151039\n",
      "Iteration: 79/306, Loss: 0.4644702970981598\n",
      "Iteration: 80/306, Loss: 0.23536497354507446\n",
      "Iteration: 81/306, Loss: 0.24622933566570282\n",
      "Iteration: 82/306, Loss: 0.07237976789474487\n",
      "Iteration: 83/306, Loss: 0.2477293610572815\n",
      "Iteration: 84/306, Loss: 0.32455185055732727\n",
      "Iteration: 85/306, Loss: 0.6820594668388367\n",
      "Iteration: 86/306, Loss: 0.6617504358291626\n",
      "Iteration: 87/306, Loss: 0.3761863112449646\n",
      "Iteration: 88/306, Loss: 0.37542805075645447\n",
      "Iteration: 89/306, Loss: 0.3745896518230438\n",
      "Iteration: 90/306, Loss: 0.43270206451416016\n",
      "Iteration: 91/306, Loss: 0.2399607002735138\n",
      "Iteration: 92/306, Loss: 0.3470548987388611\n",
      "Iteration: 93/306, Loss: 0.19680149853229523\n",
      "Iteration: 94/306, Loss: 0.2596902549266815\n",
      "Iteration: 95/306, Loss: 0.27606505155563354\n",
      "Iteration: 96/306, Loss: 0.1584814339876175\n",
      "Iteration: 97/306, Loss: 0.5336236357688904\n",
      "Iteration: 98/306, Loss: 0.39688944816589355\n",
      "Iteration: 99/306, Loss: 0.6416557431221008\n",
      "Iteration: 100/306, Loss: 0.14377151429653168\n",
      "Iteration: 101/306, Loss: 0.4588263928890228\n",
      "Iteration: 102/306, Loss: 0.2961996793746948\n",
      "Iteration: 103/306, Loss: 0.19637590646743774\n",
      "Iteration: 104/306, Loss: 0.4101080596446991\n",
      "Iteration: 105/306, Loss: 0.24814820289611816\n",
      "Iteration: 106/306, Loss: 0.27070170640945435\n",
      "Iteration: 107/306, Loss: 0.3837476670742035\n",
      "Iteration: 108/306, Loss: 0.1949540227651596\n",
      "Iteration: 109/306, Loss: 0.2239239662885666\n",
      "Iteration: 110/306, Loss: 0.2865733802318573\n",
      "Iteration: 111/306, Loss: 0.06686625629663467\n",
      "Iteration: 112/306, Loss: 0.20574092864990234\n",
      "Iteration: 113/306, Loss: 0.1967642903327942\n",
      "Iteration: 114/306, Loss: 0.13711313903331757\n",
      "Iteration: 115/306, Loss: 0.15141475200653076\n",
      "Iteration: 116/306, Loss: 0.12265617400407791\n",
      "Iteration: 117/306, Loss: 0.4913555383682251\n",
      "Iteration: 118/306, Loss: 0.14569061994552612\n",
      "Iteration: 119/306, Loss: 0.3015728294849396\n",
      "Iteration: 120/306, Loss: 0.25045284628868103\n",
      "Iteration: 121/306, Loss: 0.3695351779460907\n",
      "Iteration: 122/306, Loss: 0.4692998230457306\n",
      "Iteration: 123/306, Loss: 0.40838339924812317\n",
      "Iteration: 124/306, Loss: 0.3050066828727722\n",
      "Iteration: 125/306, Loss: 0.3582161068916321\n",
      "Iteration: 126/306, Loss: 0.917384147644043\n",
      "Iteration: 127/306, Loss: 0.4093458354473114\n",
      "Iteration: 128/306, Loss: 0.26377439498901367\n",
      "Iteration: 129/306, Loss: 0.31407594680786133\n",
      "Iteration: 130/306, Loss: 0.35596930980682373\n",
      "Iteration: 131/306, Loss: 0.18604706227779388\n",
      "Iteration: 132/306, Loss: 0.07813773304224014\n",
      "Iteration: 133/306, Loss: 0.10714413225650787\n",
      "Iteration: 134/306, Loss: 0.3221818208694458\n",
      "Iteration: 135/306, Loss: 0.1840970367193222\n",
      "Iteration: 136/306, Loss: 0.35468462109565735\n",
      "Iteration: 137/306, Loss: 0.4164649248123169\n",
      "Iteration: 138/306, Loss: 0.6738283038139343\n",
      "Iteration: 139/306, Loss: 0.6725043654441833\n",
      "Iteration: 140/306, Loss: 0.6207006573677063\n",
      "Iteration: 141/306, Loss: 0.42880094051361084\n",
      "Iteration: 142/306, Loss: 0.15974688529968262\n",
      "Iteration: 143/306, Loss: 0.6480614542961121\n",
      "Iteration: 144/306, Loss: 0.4209481477737427\n",
      "Iteration: 145/306, Loss: 0.5427589416503906\n",
      "Iteration: 146/306, Loss: 0.34416013956069946\n",
      "Iteration: 147/306, Loss: 0.5267261266708374\n",
      "Iteration: 148/306, Loss: 0.2057422548532486\n",
      "Iteration: 149/306, Loss: 0.19685834646224976\n",
      "Iteration: 150/306, Loss: 0.4991814196109772\n",
      "Iteration: 151/306, Loss: 0.5667670369148254\n",
      "Iteration: 152/306, Loss: 0.31888917088508606\n",
      "Iteration: 153/306, Loss: 0.21772994101047516\n",
      "Iteration: 154/306, Loss: 0.579306423664093\n",
      "Iteration: 155/306, Loss: 0.16309481859207153\n",
      "Iteration: 156/306, Loss: 0.3938056230545044\n",
      "Iteration: 157/306, Loss: 0.1519652009010315\n",
      "Iteration: 158/306, Loss: 0.4479367136955261\n",
      "Iteration: 159/306, Loss: 0.3654133379459381\n",
      "Iteration: 160/306, Loss: 0.36140432953834534\n",
      "Iteration: 161/306, Loss: 0.7039895057678223\n",
      "Iteration: 162/306, Loss: 0.3168123662471771\n",
      "Iteration: 163/306, Loss: 0.48383629322052\n",
      "Iteration: 164/306, Loss: 0.3535159230232239\n",
      "Iteration: 165/306, Loss: 0.3971940577030182\n",
      "Iteration: 166/306, Loss: 0.927945613861084\n",
      "Iteration: 167/306, Loss: 0.2080886960029602\n",
      "Iteration: 168/306, Loss: 0.45464277267456055\n",
      "Iteration: 169/306, Loss: 0.3907627761363983\n",
      "Iteration: 170/306, Loss: 0.19536185264587402\n",
      "Iteration: 171/306, Loss: 0.2945815920829773\n",
      "Iteration: 172/306, Loss: 0.5292882323265076\n",
      "Iteration: 173/306, Loss: 0.259653776884079\n",
      "Iteration: 174/306, Loss: 0.33449509739875793\n",
      "Iteration: 175/306, Loss: 0.31172606348991394\n",
      "Iteration: 176/306, Loss: 0.4990660846233368\n",
      "Iteration: 177/306, Loss: 0.07393753528594971\n",
      "Iteration: 178/306, Loss: 0.29837971925735474\n",
      "Iteration: 179/306, Loss: 0.2592400908470154\n",
      "Iteration: 180/306, Loss: 0.17234791815280914\n",
      "Iteration: 181/306, Loss: 0.16664379835128784\n",
      "Iteration: 182/306, Loss: 0.17824406921863556\n",
      "Iteration: 183/306, Loss: 0.601166307926178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 184/306, Loss: 0.13670898973941803\n",
      "Iteration: 185/306, Loss: 0.3302924335002899\n",
      "Iteration: 186/306, Loss: 0.530869722366333\n",
      "Iteration: 187/306, Loss: 0.6925699710845947\n",
      "Iteration: 188/306, Loss: 0.7086398601531982\n",
      "Iteration: 189/306, Loss: 0.41337984800338745\n",
      "Iteration: 190/306, Loss: 1.0737640857696533\n",
      "Iteration: 191/306, Loss: 0.14107199013233185\n",
      "Iteration: 192/306, Loss: 0.08241023868322372\n",
      "Iteration: 193/306, Loss: 0.8509453535079956\n",
      "Iteration: 194/306, Loss: 0.05597386136651039\n",
      "Iteration: 195/306, Loss: 0.05687881261110306\n",
      "Iteration: 196/306, Loss: 0.936244547367096\n",
      "Iteration: 197/306, Loss: 0.27433472871780396\n",
      "Iteration: 198/306, Loss: 0.25561410188674927\n",
      "Iteration: 199/306, Loss: 1.1073615550994873\n",
      "Iteration: 200/306, Loss: 0.30085885524749756\n",
      "Iteration: 201/306, Loss: 0.5091655850410461\n",
      "Iteration: 202/306, Loss: 0.12611940503120422\n",
      "Iteration: 203/306, Loss: 0.9063398241996765\n",
      "Iteration: 204/306, Loss: 0.0646485984325409\n",
      "Iteration: 205/306, Loss: 0.2559554874897003\n",
      "Iteration: 206/306, Loss: 0.23297210037708282\n",
      "Iteration: 207/306, Loss: 0.8105655908584595\n",
      "Iteration: 208/306, Loss: 0.6118004322052002\n",
      "Iteration: 209/306, Loss: 0.29027363657951355\n",
      "Iteration: 210/306, Loss: 0.37279587984085083\n",
      "Iteration: 211/306, Loss: 0.6307117938995361\n",
      "Iteration: 212/306, Loss: 0.4391302764415741\n",
      "Iteration: 213/306, Loss: 0.648684561252594\n",
      "Iteration: 214/306, Loss: 0.2480800896883011\n",
      "Iteration: 215/306, Loss: 0.7354435324668884\n",
      "Iteration: 216/306, Loss: 0.24625439941883087\n",
      "Iteration: 217/306, Loss: 0.4430330693721771\n",
      "Iteration: 218/306, Loss: 0.3365901708602905\n",
      "Iteration: 219/306, Loss: 0.20247292518615723\n",
      "Iteration: 220/306, Loss: 0.2617213726043701\n",
      "Iteration: 221/306, Loss: 0.47718554735183716\n",
      "Iteration: 222/306, Loss: 0.8018329739570618\n",
      "Iteration: 223/306, Loss: 0.2861325442790985\n",
      "Iteration: 224/306, Loss: 0.4087497293949127\n",
      "Iteration: 225/306, Loss: 0.24883811175823212\n",
      "Iteration: 226/306, Loss: 0.24889110028743744\n",
      "Iteration: 227/306, Loss: 0.21341010928153992\n",
      "Iteration: 228/306, Loss: 0.15202239155769348\n",
      "Iteration: 229/306, Loss: 0.38041019439697266\n",
      "Iteration: 230/306, Loss: 0.28001704812049866\n",
      "Iteration: 231/306, Loss: 1.0905128717422485\n",
      "Iteration: 232/306, Loss: 0.5252037644386292\n",
      "Iteration: 233/306, Loss: 0.2681090533733368\n",
      "Iteration: 234/306, Loss: 0.38258588314056396\n",
      "Iteration: 235/306, Loss: 0.1329391747713089\n",
      "Iteration: 236/306, Loss: 0.20132435858249664\n",
      "Iteration: 237/306, Loss: 0.19910314679145813\n",
      "Iteration: 238/306, Loss: 0.5533425211906433\n",
      "Iteration: 239/306, Loss: 0.29120388627052307\n",
      "Iteration: 240/306, Loss: 0.05984843149781227\n",
      "Iteration: 241/306, Loss: 0.4727218449115753\n",
      "Iteration: 242/306, Loss: 0.21769052743911743\n",
      "Iteration: 243/306, Loss: 0.19298072159290314\n",
      "Iteration: 244/306, Loss: 0.03447085991501808\n",
      "Iteration: 245/306, Loss: 0.4095454514026642\n",
      "Iteration: 246/306, Loss: 0.33953529596328735\n",
      "Iteration: 247/306, Loss: 0.29139041900634766\n",
      "Iteration: 248/306, Loss: 0.5762643218040466\n",
      "Iteration: 249/306, Loss: 0.216814786195755\n",
      "Iteration: 250/306, Loss: 0.2597525119781494\n",
      "Iteration: 251/306, Loss: 0.5005379319190979\n",
      "Iteration: 252/306, Loss: 0.6854477524757385\n",
      "Iteration: 253/306, Loss: 0.2372724711894989\n",
      "Iteration: 254/306, Loss: 0.2830761969089508\n",
      "Iteration: 255/306, Loss: 0.1495658904314041\n",
      "Iteration: 256/306, Loss: 0.311768114566803\n",
      "Iteration: 257/306, Loss: 0.2714812159538269\n",
      "Iteration: 258/306, Loss: 0.14582763612270355\n",
      "Iteration: 259/306, Loss: 0.29815828800201416\n",
      "Iteration: 260/306, Loss: 0.222089484333992\n",
      "Iteration: 261/306, Loss: 0.08195319771766663\n",
      "Iteration: 262/306, Loss: 0.4248853325843811\n",
      "Iteration: 263/306, Loss: 0.30182039737701416\n",
      "Iteration: 264/306, Loss: 0.29940715432167053\n",
      "Iteration: 265/306, Loss: 0.23687610030174255\n",
      "Iteration: 266/306, Loss: 0.08101389557123184\n",
      "Iteration: 267/306, Loss: 0.4728943407535553\n",
      "Iteration: 268/306, Loss: 0.37845659255981445\n",
      "Iteration: 269/306, Loss: 0.4711436927318573\n",
      "Iteration: 270/306, Loss: 0.2625105381011963\n",
      "Iteration: 271/306, Loss: 0.12729129195213318\n",
      "Iteration: 272/306, Loss: 0.13277888298034668\n",
      "Iteration: 273/306, Loss: 0.3207203447818756\n",
      "Iteration: 274/306, Loss: 0.09197509288787842\n",
      "Iteration: 275/306, Loss: 0.39164260029792786\n",
      "Iteration: 276/306, Loss: 0.06315798312425613\n",
      "Iteration: 277/306, Loss: 0.18968653678894043\n",
      "Iteration: 278/306, Loss: 0.4589070975780487\n",
      "Iteration: 279/306, Loss: 0.25668206810951233\n",
      "Iteration: 280/306, Loss: 0.6471819281578064\n",
      "Iteration: 281/306, Loss: 0.36626338958740234\n",
      "Iteration: 282/306, Loss: 0.16315099596977234\n",
      "Iteration: 283/306, Loss: 0.40612778067588806\n",
      "Iteration: 284/306, Loss: 0.4264835715293884\n",
      "Iteration: 285/306, Loss: 0.33394870162010193\n",
      "Iteration: 286/306, Loss: 0.24645859003067017\n",
      "Iteration: 287/306, Loss: 0.43969354033470154\n",
      "Iteration: 288/306, Loss: 0.5590626001358032\n",
      "Iteration: 289/306, Loss: 0.25245407223701477\n",
      "Iteration: 290/306, Loss: 0.2724892795085907\n",
      "Iteration: 291/306, Loss: 0.09321092814207077\n",
      "Iteration: 292/306, Loss: 0.2372550517320633\n",
      "Iteration: 293/306, Loss: 0.48218637704849243\n",
      "Iteration: 294/306, Loss: 0.07108593732118607\n",
      "Iteration: 295/306, Loss: 0.19172218441963196\n",
      "Iteration: 296/306, Loss: 0.300911009311676\n",
      "Iteration: 297/306, Loss: 0.2994541525840759\n",
      "Iteration: 298/306, Loss: 0.08721700310707092\n",
      "Iteration: 299/306, Loss: 0.18857814371585846\n",
      "Iteration: 300/306, Loss: 0.7723727226257324\n",
      "Iteration: 301/306, Loss: 0.27358996868133545\n",
      "Iteration: 302/306, Loss: 0.2524968385696411\n",
      "Iteration: 303/306, Loss: 0.3591358959674835\n",
      "Iteration: 304/306, Loss: 0.23384040594100952\n",
      "Iteration: 305/306, Loss: 0.2183140516281128\n",
      "Iteration: 306/306, Loss: 0.25193309783935547\n",
      "Epoch: 1/10\n",
      "Iteration: 1/306, Loss: 0.2866576910018921\n",
      "Iteration: 2/306, Loss: 0.13664545118808746\n",
      "Iteration: 3/306, Loss: 0.36821866035461426\n",
      "Iteration: 4/306, Loss: 0.14513403177261353\n",
      "Iteration: 5/306, Loss: 0.180490180850029\n",
      "Iteration: 6/306, Loss: 0.37634557485580444\n",
      "Iteration: 7/306, Loss: 0.21215441823005676\n",
      "Iteration: 8/306, Loss: 0.3384014964103699\n",
      "Iteration: 9/306, Loss: 0.5996869206428528\n",
      "Iteration: 10/306, Loss: 0.45266398787498474\n",
      "Iteration: 11/306, Loss: 0.10542328655719757\n",
      "Iteration: 12/306, Loss: 0.25819164514541626\n",
      "Iteration: 13/306, Loss: 0.24537216126918793\n",
      "Iteration: 14/306, Loss: 0.3307443857192993\n",
      "Iteration: 15/306, Loss: 0.22095991671085358\n",
      "Iteration: 16/306, Loss: 0.17984366416931152\n",
      "Iteration: 17/306, Loss: 0.4967469573020935\n",
      "Iteration: 18/306, Loss: 0.18100929260253906\n",
      "Iteration: 19/306, Loss: 0.2335600107908249\n",
      "Iteration: 20/306, Loss: 0.4815985858440399\n",
      "Iteration: 21/306, Loss: 0.21082371473312378\n",
      "Iteration: 22/306, Loss: 0.2802751958370209\n",
      "Iteration: 23/306, Loss: 0.42522165179252625\n",
      "Iteration: 24/306, Loss: 0.06148827448487282\n",
      "Iteration: 25/306, Loss: 0.26955920457839966\n",
      "Iteration: 26/306, Loss: 0.18296590447425842\n",
      "Iteration: 27/306, Loss: 0.2735598683357239\n",
      "Iteration: 28/306, Loss: 0.2408260703086853\n",
      "Iteration: 29/306, Loss: 0.1409839391708374\n",
      "Iteration: 30/306, Loss: 0.4896833598613739\n",
      "Iteration: 31/306, Loss: 0.07014564424753189\n",
      "Iteration: 32/306, Loss: 0.7852125763893127\n",
      "Iteration: 33/306, Loss: 0.25292715430259705\n",
      "Iteration: 34/306, Loss: 0.4662816524505615\n",
      "Iteration: 35/306, Loss: 0.4087698757648468\n",
      "Iteration: 36/306, Loss: 0.4395623803138733\n",
      "Iteration: 37/306, Loss: 0.12730418145656586\n",
      "Iteration: 38/306, Loss: 0.3257085382938385\n",
      "Iteration: 39/306, Loss: 0.2910107374191284\n",
      "Iteration: 40/306, Loss: 0.9013572335243225\n",
      "Iteration: 41/306, Loss: 0.19804732501506805\n",
      "Iteration: 42/306, Loss: 0.21731196343898773\n",
      "Iteration: 43/306, Loss: 0.19117993116378784\n",
      "Iteration: 44/306, Loss: 0.42287665605545044\n",
      "Iteration: 45/306, Loss: 0.261489599943161\n",
      "Iteration: 46/306, Loss: 0.30206799507141113\n",
      "Iteration: 47/306, Loss: 0.3824649751186371\n",
      "Iteration: 48/306, Loss: 0.11797069758176804\n",
      "Iteration: 49/306, Loss: 0.33843758702278137\n",
      "Iteration: 50/306, Loss: 0.2657538056373596\n",
      "Iteration: 51/306, Loss: 0.25343015789985657\n",
      "Iteration: 52/306, Loss: 0.37716856598854065\n",
      "Iteration: 53/306, Loss: 0.09369180351495743\n",
      "Iteration: 54/306, Loss: 0.13643354177474976\n",
      "Iteration: 55/306, Loss: 0.41208693385124207\n",
      "Iteration: 56/306, Loss: 0.1737559586763382\n",
      "Iteration: 57/306, Loss: 0.09509148448705673\n",
      "Iteration: 58/306, Loss: 0.33194664120674133\n",
      "Iteration: 59/306, Loss: 0.3339696526527405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 60/306, Loss: 1.0935558080673218\n",
      "Iteration: 61/306, Loss: 0.5021992921829224\n",
      "Iteration: 62/306, Loss: 0.101265549659729\n",
      "Iteration: 63/306, Loss: 0.5800639390945435\n",
      "Iteration: 64/306, Loss: 0.7087922096252441\n",
      "Iteration: 65/306, Loss: 0.3690321445465088\n",
      "Iteration: 66/306, Loss: 0.19660639762878418\n",
      "Iteration: 67/306, Loss: 0.27835091948509216\n",
      "Iteration: 68/306, Loss: 0.18498827517032623\n",
      "Iteration: 69/306, Loss: 0.11612261831760406\n",
      "Iteration: 70/306, Loss: 0.5550630688667297\n",
      "Iteration: 71/306, Loss: 1.1503159999847412\n",
      "Iteration: 72/306, Loss: 0.13724520802497864\n",
      "Iteration: 73/306, Loss: 0.07447746396064758\n",
      "Iteration: 74/306, Loss: 0.47462213039398193\n",
      "Iteration: 75/306, Loss: 0.1992281675338745\n",
      "Iteration: 76/306, Loss: 1.0701568126678467\n",
      "Iteration: 77/306, Loss: 0.75599205493927\n",
      "Iteration: 78/306, Loss: 0.10752785950899124\n",
      "Iteration: 79/306, Loss: 0.19951048493385315\n",
      "Iteration: 80/306, Loss: 0.21496346592903137\n",
      "Iteration: 81/306, Loss: 0.40879395604133606\n",
      "Iteration: 82/306, Loss: 0.04729052260518074\n",
      "Iteration: 83/306, Loss: 0.18629097938537598\n",
      "Iteration: 84/306, Loss: 0.043019119650125504\n",
      "Iteration: 85/306, Loss: 0.6187426447868347\n",
      "Iteration: 86/306, Loss: 0.35070478916168213\n",
      "Iteration: 87/306, Loss: 0.21190659701824188\n",
      "Iteration: 88/306, Loss: 0.3705793023109436\n",
      "Iteration: 89/306, Loss: 0.4646112620830536\n",
      "Iteration: 90/306, Loss: 0.7509203553199768\n",
      "Iteration: 91/306, Loss: 0.2510378658771515\n",
      "Iteration: 92/306, Loss: 0.7291168570518494\n",
      "Iteration: 93/306, Loss: 0.3743246793746948\n",
      "Iteration: 94/306, Loss: 0.751039445400238\n",
      "Iteration: 95/306, Loss: 0.9208399653434753\n",
      "Iteration: 96/306, Loss: 0.5448631644248962\n",
      "Iteration: 97/306, Loss: 0.8198487758636475\n",
      "Iteration: 98/306, Loss: 0.4599657654762268\n",
      "Iteration: 99/306, Loss: 0.13876968622207642\n",
      "Iteration: 100/306, Loss: 0.17143823206424713\n",
      "Iteration: 101/306, Loss: 0.0574234239757061\n",
      "Iteration: 102/306, Loss: 0.33124208450317383\n",
      "Iteration: 103/306, Loss: 0.3332716226577759\n",
      "Iteration: 104/306, Loss: 0.6287140846252441\n",
      "Iteration: 105/306, Loss: 0.31544214487075806\n",
      "Iteration: 106/306, Loss: 0.4863089919090271\n",
      "Iteration: 107/306, Loss: 0.45217078924179077\n",
      "Iteration: 108/306, Loss: 0.27193865180015564\n",
      "Iteration: 109/306, Loss: 0.1969207227230072\n",
      "Iteration: 110/306, Loss: 0.7625782489776611\n",
      "Iteration: 111/306, Loss: 0.7657989859580994\n",
      "Iteration: 112/306, Loss: 0.5499728322029114\n",
      "Iteration: 113/306, Loss: 0.4043155610561371\n",
      "Iteration: 114/306, Loss: 0.15921373665332794\n",
      "Iteration: 115/306, Loss: 0.2266203612089157\n",
      "Iteration: 116/306, Loss: 0.6183019280433655\n",
      "Iteration: 117/306, Loss: 0.22591006755828857\n",
      "Iteration: 118/306, Loss: 0.4423169195652008\n",
      "Iteration: 119/306, Loss: 0.41007906198501587\n",
      "Iteration: 120/306, Loss: 0.26212549209594727\n",
      "Iteration: 121/306, Loss: 0.5415316820144653\n",
      "Iteration: 122/306, Loss: 0.3024507761001587\n",
      "Iteration: 123/306, Loss: 0.16800571978092194\n",
      "Iteration: 124/306, Loss: 0.20698271691799164\n",
      "Iteration: 125/306, Loss: 0.5413102507591248\n",
      "Iteration: 126/306, Loss: 0.6115235090255737\n",
      "Iteration: 127/306, Loss: 0.10033765435218811\n",
      "Iteration: 128/306, Loss: 0.2633463144302368\n",
      "Iteration: 129/306, Loss: 0.10262823849916458\n",
      "Iteration: 130/306, Loss: 0.36004000902175903\n",
      "Iteration: 131/306, Loss: 0.43637385964393616\n",
      "Iteration: 132/306, Loss: 0.7065670490264893\n",
      "Iteration: 133/306, Loss: 0.07004250586032867\n",
      "Iteration: 134/306, Loss: 0.5851654410362244\n",
      "Iteration: 135/306, Loss: 0.18778596818447113\n",
      "Iteration: 136/306, Loss: 0.2881552278995514\n",
      "Iteration: 137/306, Loss: 0.024098262190818787\n",
      "Iteration: 138/306, Loss: 0.35995960235595703\n",
      "Iteration: 139/306, Loss: 0.26834750175476074\n",
      "Iteration: 140/306, Loss: 0.5693809390068054\n",
      "Iteration: 141/306, Loss: 0.1725490391254425\n",
      "Iteration: 142/306, Loss: 0.5274438858032227\n",
      "Iteration: 143/306, Loss: 0.6694949865341187\n",
      "Iteration: 144/306, Loss: 0.304857075214386\n",
      "Iteration: 145/306, Loss: 0.24422666430473328\n",
      "Iteration: 146/306, Loss: 0.47225746512413025\n",
      "Iteration: 147/306, Loss: 0.4149145781993866\n",
      "Iteration: 148/306, Loss: 0.3671133816242218\n",
      "Iteration: 149/306, Loss: 0.2376764565706253\n",
      "Iteration: 150/306, Loss: 0.13621588051319122\n",
      "Iteration: 151/306, Loss: 0.12436914443969727\n",
      "Iteration: 152/306, Loss: 0.10398365557193756\n",
      "Iteration: 153/306, Loss: 0.4946461319923401\n",
      "Iteration: 154/306, Loss: 0.10657207667827606\n",
      "Iteration: 155/306, Loss: 0.3211924433708191\n",
      "Iteration: 156/306, Loss: 0.11087207496166229\n",
      "Iteration: 157/306, Loss: 0.012450293637812138\n",
      "Iteration: 158/306, Loss: 0.26459282636642456\n",
      "Iteration: 159/306, Loss: 0.35221177339553833\n",
      "Iteration: 160/306, Loss: 0.2162267416715622\n",
      "Iteration: 161/306, Loss: 0.20473691821098328\n",
      "Iteration: 162/306, Loss: 0.4362492561340332\n",
      "Iteration: 163/306, Loss: 0.5924956798553467\n",
      "Iteration: 164/306, Loss: 0.03567545488476753\n",
      "Iteration: 165/306, Loss: 0.416064977645874\n",
      "Iteration: 166/306, Loss: 0.428398072719574\n",
      "Iteration: 167/306, Loss: 0.41636377573013306\n",
      "Iteration: 168/306, Loss: 0.3223407566547394\n",
      "Iteration: 169/306, Loss: 0.28397175669670105\n",
      "Iteration: 170/306, Loss: 0.5291641354560852\n",
      "Iteration: 171/306, Loss: 0.4202444851398468\n",
      "Iteration: 172/306, Loss: 0.42582929134368896\n",
      "Iteration: 173/306, Loss: 0.3162863850593567\n",
      "Iteration: 174/306, Loss: 0.21525683999061584\n",
      "Iteration: 175/306, Loss: 0.047705166041851044\n",
      "Iteration: 176/306, Loss: 0.3179444670677185\n",
      "Iteration: 177/306, Loss: 0.47540560364723206\n",
      "Iteration: 178/306, Loss: 0.20927593111991882\n",
      "Iteration: 179/306, Loss: 0.8946796655654907\n",
      "Iteration: 180/306, Loss: 0.04348266124725342\n",
      "Iteration: 181/306, Loss: 0.3347187638282776\n",
      "Iteration: 182/306, Loss: 0.5256744027137756\n",
      "Iteration: 183/306, Loss: 0.3635428547859192\n",
      "Iteration: 184/306, Loss: 0.1457296460866928\n",
      "Iteration: 185/306, Loss: 0.20534972846508026\n",
      "Iteration: 186/306, Loss: 0.17837117612361908\n",
      "Iteration: 187/306, Loss: 0.15577837824821472\n",
      "Iteration: 188/306, Loss: 0.5661853551864624\n",
      "Iteration: 189/306, Loss: 0.5454204678535461\n",
      "Iteration: 190/306, Loss: 0.16681629419326782\n",
      "Iteration: 191/306, Loss: 1.0294278860092163\n",
      "Iteration: 192/306, Loss: 0.7306960225105286\n",
      "Iteration: 193/306, Loss: 0.08325833082199097\n",
      "Iteration: 194/306, Loss: 0.15426765382289886\n",
      "Iteration: 195/306, Loss: 0.29142892360687256\n",
      "Iteration: 196/306, Loss: 0.314426064491272\n",
      "Iteration: 197/306, Loss: 1.4051121473312378\n",
      "Iteration: 198/306, Loss: 0.688487708568573\n",
      "Iteration: 199/306, Loss: 0.14725494384765625\n",
      "Iteration: 200/306, Loss: 0.4322446584701538\n",
      "Iteration: 201/306, Loss: 0.6009213328361511\n",
      "Iteration: 202/306, Loss: 1.2508262395858765\n",
      "Iteration: 203/306, Loss: 0.22422058880329132\n",
      "Iteration: 204/306, Loss: 0.23156775534152985\n",
      "Iteration: 205/306, Loss: 0.7562302947044373\n",
      "Iteration: 206/306, Loss: 0.44000208377838135\n",
      "Iteration: 207/306, Loss: 0.053017280995845795\n",
      "Iteration: 208/306, Loss: 0.21608439087867737\n",
      "Iteration: 209/306, Loss: 0.6742614507675171\n",
      "Iteration: 210/306, Loss: 0.6196036338806152\n",
      "Iteration: 211/306, Loss: 0.05845918878912926\n",
      "Iteration: 212/306, Loss: 0.6381869912147522\n",
      "Iteration: 213/306, Loss: 0.4331233501434326\n",
      "Iteration: 214/306, Loss: 0.6603801846504211\n",
      "Iteration: 215/306, Loss: 0.296036034822464\n",
      "Iteration: 216/306, Loss: 0.17486563324928284\n",
      "Iteration: 217/306, Loss: 0.22560153901576996\n",
      "Iteration: 218/306, Loss: 0.2310861498117447\n",
      "Iteration: 219/306, Loss: 0.3255768418312073\n",
      "Iteration: 220/306, Loss: 1.0150368213653564\n",
      "Iteration: 221/306, Loss: 0.21973508596420288\n",
      "Iteration: 222/306, Loss: 0.6178801655769348\n",
      "Iteration: 223/306, Loss: 0.2277662456035614\n",
      "Iteration: 224/306, Loss: 0.3204554319381714\n",
      "Iteration: 225/306, Loss: 0.5594214200973511\n",
      "Iteration: 226/306, Loss: 0.22664014995098114\n",
      "Iteration: 227/306, Loss: 0.5667944550514221\n",
      "Iteration: 228/306, Loss: 0.22990873456001282\n",
      "Iteration: 229/306, Loss: 0.18957297503948212\n",
      "Iteration: 230/306, Loss: 0.31066396832466125\n",
      "Iteration: 231/306, Loss: 0.10648642480373383\n",
      "Iteration: 232/306, Loss: 0.7040489315986633\n",
      "Iteration: 233/306, Loss: 0.1957760453224182\n",
      "Iteration: 234/306, Loss: 0.21545623242855072\n",
      "Iteration: 235/306, Loss: 0.8970882296562195\n",
      "Iteration: 236/306, Loss: 0.20075994729995728\n",
      "Iteration: 237/306, Loss: 1.020939588546753\n",
      "Iteration: 238/306, Loss: 0.16415712237358093\n",
      "Iteration: 239/306, Loss: 0.5790988206863403\n",
      "Iteration: 240/306, Loss: 0.6133589148521423\n",
      "Iteration: 241/306, Loss: 0.3340301513671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 242/306, Loss: 0.21979641914367676\n",
      "Iteration: 243/306, Loss: 0.30205485224723816\n",
      "Iteration: 244/306, Loss: 0.11944025754928589\n",
      "Iteration: 245/306, Loss: 0.3281822204589844\n",
      "Iteration: 246/306, Loss: 0.31109124422073364\n",
      "Iteration: 247/306, Loss: 0.21851029992103577\n",
      "Iteration: 248/306, Loss: 0.6564146876335144\n",
      "Iteration: 249/306, Loss: 0.8113196492195129\n",
      "Iteration: 250/306, Loss: 0.47319987416267395\n",
      "Iteration: 251/306, Loss: 0.2544577121734619\n",
      "Iteration: 252/306, Loss: 0.4538347125053406\n",
      "Iteration: 253/306, Loss: 0.7537944912910461\n",
      "Iteration: 254/306, Loss: 0.3862030506134033\n",
      "Iteration: 255/306, Loss: 0.6920005679130554\n",
      "Iteration: 256/306, Loss: 0.06491602212190628\n",
      "Iteration: 257/306, Loss: 0.6791156530380249\n",
      "Iteration: 258/306, Loss: 0.14875788986682892\n",
      "Iteration: 259/306, Loss: 0.3030660152435303\n",
      "Iteration: 260/306, Loss: 0.2007569968700409\n",
      "Iteration: 261/306, Loss: 0.18730826675891876\n",
      "Iteration: 262/306, Loss: 0.3192933201789856\n",
      "Iteration: 263/306, Loss: 0.509598970413208\n",
      "Iteration: 264/306, Loss: 0.38804396986961365\n",
      "Iteration: 265/306, Loss: 1.2985084056854248\n",
      "Iteration: 266/306, Loss: 0.08753595501184464\n",
      "Iteration: 267/306, Loss: 0.3470333218574524\n",
      "Iteration: 268/306, Loss: 0.30688363313674927\n",
      "Iteration: 269/306, Loss: 0.35775285959243774\n",
      "Iteration: 270/306, Loss: 0.8949403762817383\n",
      "Iteration: 271/306, Loss: 0.30035141110420227\n",
      "Iteration: 272/306, Loss: 0.22243790328502655\n",
      "Iteration: 273/306, Loss: 0.19741125404834747\n",
      "Iteration: 274/306, Loss: 0.36296921968460083\n",
      "Iteration: 275/306, Loss: 0.16882742941379547\n",
      "Iteration: 276/306, Loss: 0.21676962077617645\n",
      "Iteration: 277/306, Loss: 0.2036302536725998\n",
      "Iteration: 278/306, Loss: 0.686190128326416\n",
      "Iteration: 279/306, Loss: 0.18931622803211212\n",
      "Iteration: 280/306, Loss: 0.5338122248649597\n",
      "Iteration: 281/306, Loss: 0.24619214236736298\n",
      "Iteration: 282/306, Loss: 0.326610803604126\n",
      "Iteration: 283/306, Loss: 0.17432789504528046\n",
      "Iteration: 284/306, Loss: 0.38079318404197693\n",
      "Iteration: 285/306, Loss: 0.24232187867164612\n",
      "Iteration: 286/306, Loss: 0.20690685510635376\n",
      "Iteration: 287/306, Loss: 0.24730686843395233\n",
      "Iteration: 288/306, Loss: 0.1092972606420517\n",
      "Iteration: 289/306, Loss: 0.1942979246377945\n",
      "Iteration: 290/306, Loss: 0.23959273099899292\n",
      "Iteration: 291/306, Loss: 0.44257548451423645\n",
      "Iteration: 292/306, Loss: 0.44294992089271545\n",
      "Iteration: 293/306, Loss: 0.24049344658851624\n",
      "Iteration: 294/306, Loss: 0.46727269887924194\n",
      "Iteration: 295/306, Loss: 0.04672807455062866\n",
      "Iteration: 296/306, Loss: 0.2932046949863434\n",
      "Iteration: 297/306, Loss: 0.12641173601150513\n",
      "Iteration: 298/306, Loss: 0.2788495123386383\n",
      "Iteration: 299/306, Loss: 0.2853228449821472\n",
      "Iteration: 300/306, Loss: 0.32040920853614807\n",
      "Iteration: 301/306, Loss: 0.17932523787021637\n",
      "Iteration: 302/306, Loss: 0.029045870527625084\n",
      "Iteration: 303/306, Loss: 0.4324275553226471\n",
      "Iteration: 304/306, Loss: 0.430510938167572\n",
      "Iteration: 305/306, Loss: 0.22496171295642853\n",
      "Iteration: 306/306, Loss: 0.4850722551345825\n",
      "Epoch: 2/10\n",
      "Iteration: 1/306, Loss: 0.3158852756023407\n",
      "Iteration: 2/306, Loss: 0.44832685589790344\n",
      "Iteration: 3/306, Loss: 0.21304187178611755\n",
      "Iteration: 4/306, Loss: 0.5386939644813538\n",
      "Iteration: 5/306, Loss: 0.35113489627838135\n",
      "Iteration: 6/306, Loss: 0.18002410233020782\n",
      "Iteration: 7/306, Loss: 0.46685320138931274\n",
      "Iteration: 8/306, Loss: 0.198303684592247\n",
      "Iteration: 9/306, Loss: 0.8260014653205872\n",
      "Iteration: 10/306, Loss: 0.16539683938026428\n",
      "Iteration: 11/306, Loss: 0.3846976161003113\n",
      "Iteration: 12/306, Loss: 0.21108223497867584\n",
      "Iteration: 13/306, Loss: 0.23711422085762024\n",
      "Iteration: 14/306, Loss: 0.1459210216999054\n",
      "Iteration: 15/306, Loss: 0.11320248991250992\n",
      "Iteration: 16/306, Loss: 0.3298279047012329\n",
      "Iteration: 17/306, Loss: 0.20849543809890747\n",
      "Iteration: 18/306, Loss: 0.42626649141311646\n",
      "Iteration: 19/306, Loss: 0.21173806488513947\n",
      "Iteration: 20/306, Loss: 0.20115311443805695\n",
      "Iteration: 21/306, Loss: 0.5756663680076599\n",
      "Iteration: 22/306, Loss: 0.6967855095863342\n",
      "Iteration: 23/306, Loss: 0.43010491132736206\n",
      "Iteration: 24/306, Loss: 0.45227476954460144\n",
      "Iteration: 25/306, Loss: 0.4904671013355255\n",
      "Iteration: 26/306, Loss: 0.21201816201210022\n",
      "Iteration: 27/306, Loss: 0.4343020021915436\n",
      "Iteration: 28/306, Loss: 0.7721576690673828\n",
      "Iteration: 29/306, Loss: 0.800441563129425\n",
      "Iteration: 30/306, Loss: 0.2385423183441162\n",
      "Iteration: 31/306, Loss: 0.05808846279978752\n",
      "Iteration: 32/306, Loss: 0.23054617643356323\n",
      "Iteration: 33/306, Loss: 0.32137882709503174\n",
      "Iteration: 34/306, Loss: 0.2492160201072693\n",
      "Iteration: 35/306, Loss: 0.24234937131404877\n",
      "Iteration: 36/306, Loss: 1.2391351461410522\n",
      "Iteration: 37/306, Loss: 0.24343356490135193\n",
      "Iteration: 38/306, Loss: 0.05284232646226883\n",
      "Iteration: 39/306, Loss: 0.5332853198051453\n",
      "Iteration: 40/306, Loss: 0.6079814434051514\n",
      "Iteration: 41/306, Loss: 0.23157009482383728\n",
      "Iteration: 42/306, Loss: 0.19669264554977417\n",
      "Iteration: 43/306, Loss: 0.28532299399375916\n",
      "Iteration: 44/306, Loss: 0.1322171688079834\n",
      "Iteration: 45/306, Loss: 0.6055667996406555\n",
      "Iteration: 46/306, Loss: 0.8066282272338867\n",
      "Iteration: 47/306, Loss: 0.4059790372848511\n",
      "Iteration: 48/306, Loss: 0.2994058132171631\n",
      "Iteration: 49/306, Loss: 0.37442657351493835\n",
      "Iteration: 50/306, Loss: 0.1188732385635376\n",
      "Iteration: 51/306, Loss: 0.2613533139228821\n",
      "Iteration: 52/306, Loss: 0.9313265085220337\n",
      "Iteration: 53/306, Loss: 0.09642808884382248\n",
      "Iteration: 54/306, Loss: 0.06418177485466003\n",
      "Iteration: 55/306, Loss: 0.30838561058044434\n",
      "Iteration: 56/306, Loss: 0.1787688285112381\n",
      "Iteration: 57/306, Loss: 0.22903843224048615\n",
      "Iteration: 58/306, Loss: 0.21713028848171234\n",
      "Iteration: 59/306, Loss: 0.45924749970436096\n",
      "Iteration: 60/306, Loss: 0.6835967898368835\n",
      "Iteration: 61/306, Loss: 0.09772621095180511\n",
      "Iteration: 62/306, Loss: 0.39109131693840027\n",
      "Iteration: 63/306, Loss: 0.2763115167617798\n",
      "Iteration: 64/306, Loss: 0.3380642831325531\n",
      "Iteration: 65/306, Loss: 0.3650630712509155\n",
      "Iteration: 66/306, Loss: 0.27343204617500305\n",
      "Iteration: 67/306, Loss: 0.12972058355808258\n",
      "Iteration: 68/306, Loss: 0.27949872612953186\n",
      "Iteration: 69/306, Loss: 0.35239139199256897\n",
      "Iteration: 70/306, Loss: 0.26306939125061035\n",
      "Iteration: 71/306, Loss: 0.1788988709449768\n",
      "Iteration: 72/306, Loss: 0.4369487166404724\n",
      "Iteration: 73/306, Loss: 0.35222128033638\n",
      "Iteration: 74/306, Loss: 0.04440123587846756\n",
      "Iteration: 75/306, Loss: 0.051780786365270615\n",
      "Iteration: 76/306, Loss: 0.2882121801376343\n",
      "Iteration: 77/306, Loss: 0.30954378843307495\n",
      "Iteration: 78/306, Loss: 0.18236973881721497\n",
      "Iteration: 79/306, Loss: 0.5892006754875183\n",
      "Iteration: 80/306, Loss: 0.155242919921875\n",
      "Iteration: 81/306, Loss: 0.2861372232437134\n",
      "Iteration: 82/306, Loss: 0.20128922164440155\n",
      "Iteration: 83/306, Loss: 0.04623081907629967\n",
      "Iteration: 84/306, Loss: 0.173013836145401\n",
      "Iteration: 85/306, Loss: 0.06880691647529602\n",
      "Iteration: 86/306, Loss: 0.2527911365032196\n",
      "Iteration: 87/306, Loss: 0.025495698675513268\n",
      "Iteration: 88/306, Loss: 0.1460241973400116\n",
      "Iteration: 89/306, Loss: 0.23096179962158203\n",
      "Iteration: 90/306, Loss: 0.20366717875003815\n",
      "Iteration: 91/306, Loss: 0.2993737459182739\n",
      "Iteration: 92/306, Loss: 0.15163327753543854\n",
      "Iteration: 93/306, Loss: 0.4668377637863159\n",
      "Iteration: 94/306, Loss: 0.04780356585979462\n",
      "Iteration: 95/306, Loss: 0.5617246627807617\n",
      "Iteration: 96/306, Loss: 0.4139346182346344\n",
      "Iteration: 97/306, Loss: 0.13681210577487946\n",
      "Iteration: 98/306, Loss: 0.34149160981178284\n",
      "Iteration: 99/306, Loss: 0.632496178150177\n",
      "Iteration: 100/306, Loss: 0.3448534607887268\n",
      "Iteration: 101/306, Loss: 0.20441745221614838\n",
      "Iteration: 102/306, Loss: 1.1827398538589478\n",
      "Iteration: 103/306, Loss: 0.4671753942966461\n",
      "Iteration: 104/306, Loss: 0.45614251494407654\n",
      "Iteration: 105/306, Loss: 0.724553644657135\n",
      "Iteration: 106/306, Loss: 0.46855276823043823\n",
      "Iteration: 107/306, Loss: 0.5101169943809509\n",
      "Iteration: 108/306, Loss: 0.0435296855866909\n",
      "Iteration: 109/306, Loss: 1.0054062604904175\n",
      "Iteration: 110/306, Loss: 0.19876545667648315\n",
      "Iteration: 111/306, Loss: 0.4601825773715973\n",
      "Iteration: 112/306, Loss: 0.13903196156024933\n",
      "Iteration: 113/306, Loss: 0.2620142996311188\n",
      "Iteration: 114/306, Loss: 0.9464905261993408\n",
      "Iteration: 115/306, Loss: 0.016041960567235947\n",
      "Iteration: 116/306, Loss: 0.05027949810028076\n",
      "Iteration: 117/306, Loss: 0.3117704391479492\n",
      "Iteration: 118/306, Loss: 0.2041034698486328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 119/306, Loss: 0.573678731918335\n",
      "Iteration: 120/306, Loss: 0.47221702337265015\n",
      "Iteration: 121/306, Loss: 0.2661897838115692\n",
      "Iteration: 122/306, Loss: 0.21801462769508362\n",
      "Iteration: 123/306, Loss: 0.37584877014160156\n",
      "Iteration: 124/306, Loss: 0.13662803173065186\n",
      "Iteration: 125/306, Loss: 1.5652931928634644\n",
      "Iteration: 126/306, Loss: 0.28885725140571594\n",
      "Iteration: 127/306, Loss: 0.22304226458072662\n",
      "Iteration: 128/306, Loss: 0.6390160918235779\n",
      "Iteration: 129/306, Loss: 0.6246113181114197\n",
      "Iteration: 130/306, Loss: 0.36600735783576965\n",
      "Iteration: 131/306, Loss: 0.07523925602436066\n",
      "Iteration: 132/306, Loss: 0.33517998456954956\n",
      "Iteration: 133/306, Loss: 0.1741134524345398\n",
      "Iteration: 134/306, Loss: 0.07729551196098328\n",
      "Iteration: 135/306, Loss: 0.5795560479164124\n",
      "Iteration: 136/306, Loss: 0.10242840647697449\n",
      "Iteration: 137/306, Loss: 0.2589268684387207\n",
      "Iteration: 138/306, Loss: 0.19113291800022125\n",
      "Iteration: 139/306, Loss: 0.5090381503105164\n",
      "Iteration: 140/306, Loss: 0.668133020401001\n",
      "Iteration: 141/306, Loss: 0.2596680521965027\n",
      "Iteration: 142/306, Loss: 0.5431081056594849\n",
      "Iteration: 143/306, Loss: 0.12397553026676178\n",
      "Iteration: 144/306, Loss: 0.1676548570394516\n",
      "Iteration: 145/306, Loss: 1.051192283630371\n",
      "Iteration: 146/306, Loss: 0.19912096858024597\n",
      "Iteration: 147/306, Loss: 0.28024575114250183\n",
      "Iteration: 148/306, Loss: 0.10522931069135666\n",
      "Iteration: 149/306, Loss: 0.22225022315979004\n",
      "Iteration: 150/306, Loss: 0.33483490347862244\n",
      "Iteration: 151/306, Loss: 0.23511981964111328\n",
      "Iteration: 152/306, Loss: 0.16829617321491241\n",
      "Iteration: 153/306, Loss: 0.265510231256485\n",
      "Iteration: 154/306, Loss: 0.14489610493183136\n",
      "Iteration: 155/306, Loss: 0.47057461738586426\n",
      "Iteration: 156/306, Loss: 0.1793716847896576\n",
      "Iteration: 157/306, Loss: 0.21068067848682404\n",
      "Iteration: 158/306, Loss: 0.02606242522597313\n",
      "Iteration: 159/306, Loss: 0.43048518896102905\n",
      "Iteration: 160/306, Loss: 0.09084858000278473\n",
      "Iteration: 161/306, Loss: 0.1734141856431961\n",
      "Iteration: 162/306, Loss: 0.375882625579834\n",
      "Iteration: 163/306, Loss: 0.08910008519887924\n",
      "Iteration: 164/306, Loss: 0.2460051327943802\n",
      "Iteration: 165/306, Loss: 0.6090397834777832\n",
      "Iteration: 166/306, Loss: 0.176509290933609\n",
      "Iteration: 167/306, Loss: 0.27376702427864075\n",
      "Iteration: 168/306, Loss: 0.7042006850242615\n",
      "Iteration: 169/306, Loss: 0.4195695221424103\n",
      "Iteration: 170/306, Loss: 0.4913993179798126\n",
      "Iteration: 171/306, Loss: 0.4508017599582672\n",
      "Iteration: 172/306, Loss: 0.23219701647758484\n",
      "Iteration: 173/306, Loss: 0.7789868116378784\n",
      "Iteration: 174/306, Loss: 0.09303949773311615\n",
      "Iteration: 175/306, Loss: 0.9787431955337524\n",
      "Iteration: 176/306, Loss: 0.16945795714855194\n",
      "Iteration: 177/306, Loss: 0.159062460064888\n",
      "Iteration: 178/306, Loss: 0.3674126863479614\n",
      "Iteration: 179/306, Loss: 0.6005710959434509\n",
      "Iteration: 180/306, Loss: 0.12329870462417603\n",
      "Iteration: 181/306, Loss: 0.25882768630981445\n",
      "Iteration: 182/306, Loss: 0.20384050905704498\n",
      "Iteration: 183/306, Loss: 0.6004422307014465\n",
      "Iteration: 184/306, Loss: 0.20036888122558594\n",
      "Iteration: 185/306, Loss: 0.2559278905391693\n",
      "Iteration: 186/306, Loss: 0.3046078383922577\n",
      "Iteration: 187/306, Loss: 0.3285079300403595\n",
      "Iteration: 188/306, Loss: 0.873291552066803\n",
      "Iteration: 189/306, Loss: 0.5117857456207275\n",
      "Iteration: 190/306, Loss: 0.37790611386299133\n",
      "Iteration: 191/306, Loss: 0.5362428426742554\n",
      "Iteration: 192/306, Loss: 0.3889479637145996\n",
      "Iteration: 193/306, Loss: 0.6410165429115295\n",
      "Iteration: 194/306, Loss: 0.37537500262260437\n",
      "Iteration: 195/306, Loss: 0.3114934265613556\n",
      "Iteration: 196/306, Loss: 0.2695530951023102\n",
      "Iteration: 197/306, Loss: 0.20073285698890686\n",
      "Iteration: 198/306, Loss: 0.04883185774087906\n",
      "Iteration: 199/306, Loss: 0.16474927961826324\n",
      "Iteration: 200/306, Loss: 0.060632795095443726\n",
      "Iteration: 201/306, Loss: 0.41022366285324097\n",
      "Iteration: 202/306, Loss: 0.37795162200927734\n",
      "Iteration: 203/306, Loss: 0.1482463777065277\n",
      "Iteration: 204/306, Loss: 0.6416838765144348\n",
      "Iteration: 205/306, Loss: 0.20929645001888275\n",
      "Iteration: 206/306, Loss: 0.2043941766023636\n",
      "Iteration: 207/306, Loss: 0.6075654625892639\n",
      "Iteration: 208/306, Loss: 0.20382708311080933\n",
      "Iteration: 209/306, Loss: 0.3823573589324951\n",
      "Iteration: 210/306, Loss: 0.49859631061553955\n",
      "Iteration: 211/306, Loss: 0.6586095690727234\n",
      "Iteration: 212/306, Loss: 0.17703072726726532\n",
      "Iteration: 213/306, Loss: 0.18273527920246124\n",
      "Iteration: 214/306, Loss: 0.20372793078422546\n",
      "Iteration: 215/306, Loss: 0.3760896325111389\n",
      "Iteration: 216/306, Loss: 0.322161465883255\n",
      "Iteration: 217/306, Loss: 0.5778043866157532\n",
      "Iteration: 218/306, Loss: 0.4963682293891907\n",
      "Iteration: 219/306, Loss: 0.2584512233734131\n",
      "Iteration: 220/306, Loss: 0.19710741937160492\n",
      "Iteration: 221/306, Loss: 0.8530515432357788\n",
      "Iteration: 222/306, Loss: 0.19267752766609192\n",
      "Iteration: 223/306, Loss: 0.7135193943977356\n",
      "Iteration: 224/306, Loss: 0.06516025215387344\n",
      "Iteration: 225/306, Loss: 0.2963847517967224\n",
      "Iteration: 226/306, Loss: 0.30520421266555786\n",
      "Iteration: 227/306, Loss: 0.5086873769760132\n",
      "Iteration: 228/306, Loss: 0.36660486459732056\n",
      "Iteration: 229/306, Loss: 0.07658171653747559\n",
      "Iteration: 230/306, Loss: 0.18140119314193726\n",
      "Iteration: 231/306, Loss: 0.9698968529701233\n",
      "Iteration: 232/306, Loss: 0.16869233548641205\n",
      "Iteration: 233/306, Loss: 0.7757723331451416\n",
      "Iteration: 234/306, Loss: 0.30380070209503174\n",
      "Iteration: 235/306, Loss: 0.19926588237285614\n",
      "Iteration: 236/306, Loss: 0.3294547498226166\n",
      "Iteration: 237/306, Loss: 0.20351958274841309\n",
      "Iteration: 238/306, Loss: 0.7843508124351501\n",
      "Iteration: 239/306, Loss: 0.18768815696239471\n",
      "Iteration: 240/306, Loss: 0.48040202260017395\n",
      "Iteration: 241/306, Loss: 0.39486029744148254\n",
      "Iteration: 242/306, Loss: 0.3046311140060425\n",
      "Iteration: 243/306, Loss: 0.23287083208560944\n",
      "Iteration: 244/306, Loss: 0.2220623940229416\n",
      "Iteration: 245/306, Loss: 0.4326778054237366\n",
      "Iteration: 246/306, Loss: 0.4639509320259094\n",
      "Iteration: 247/306, Loss: 0.20595557987689972\n",
      "Iteration: 248/306, Loss: 0.0577889159321785\n",
      "Iteration: 249/306, Loss: 0.10795213282108307\n",
      "Iteration: 250/306, Loss: 0.3288399577140808\n",
      "Iteration: 251/306, Loss: 0.17046067118644714\n",
      "Iteration: 252/306, Loss: 0.2824251353740692\n",
      "Iteration: 253/306, Loss: 0.5830336213111877\n",
      "Iteration: 254/306, Loss: 0.1473887711763382\n",
      "Iteration: 255/306, Loss: 0.23707208037376404\n",
      "Iteration: 256/306, Loss: 0.31169959902763367\n",
      "Iteration: 257/306, Loss: 0.18831898272037506\n",
      "Iteration: 258/306, Loss: 0.18026408553123474\n",
      "Iteration: 259/306, Loss: 0.09351065009832382\n",
      "Iteration: 260/306, Loss: 0.38638201355934143\n",
      "Iteration: 261/306, Loss: 0.7350831031799316\n",
      "Iteration: 262/306, Loss: 0.20841330289840698\n",
      "Iteration: 263/306, Loss: 0.1905740350484848\n",
      "Iteration: 264/306, Loss: 0.16104446351528168\n",
      "Iteration: 265/306, Loss: 0.21433275938034058\n",
      "Iteration: 266/306, Loss: 0.1272694319486618\n",
      "Iteration: 267/306, Loss: 0.2431740164756775\n",
      "Iteration: 268/306, Loss: 0.4650256633758545\n",
      "Iteration: 269/306, Loss: 0.15752291679382324\n",
      "Iteration: 270/306, Loss: 0.18354123830795288\n",
      "Iteration: 271/306, Loss: 1.0238059759140015\n",
      "Iteration: 272/306, Loss: 0.2555907666683197\n",
      "Iteration: 273/306, Loss: 0.19623398780822754\n",
      "Iteration: 274/306, Loss: 0.14360401034355164\n",
      "Iteration: 275/306, Loss: 0.12307406216859818\n",
      "Iteration: 276/306, Loss: 0.20681796967983246\n",
      "Iteration: 277/306, Loss: 0.14334094524383545\n",
      "Iteration: 278/306, Loss: 0.4661339521408081\n",
      "Iteration: 279/306, Loss: 0.17169873416423798\n",
      "Iteration: 280/306, Loss: 0.06745360046625137\n",
      "Iteration: 281/306, Loss: 0.2110215723514557\n",
      "Iteration: 282/306, Loss: 0.18760588765144348\n",
      "Iteration: 283/306, Loss: 0.18751081824302673\n",
      "Iteration: 284/306, Loss: 0.3072461783885956\n",
      "Iteration: 285/306, Loss: 0.3350611627101898\n",
      "Iteration: 286/306, Loss: 0.21345624327659607\n",
      "Iteration: 287/306, Loss: 0.32967159152030945\n",
      "Iteration: 288/306, Loss: 0.3912689685821533\n",
      "Iteration: 289/306, Loss: 0.15724420547485352\n",
      "Iteration: 290/306, Loss: 0.2593677341938019\n",
      "Iteration: 291/306, Loss: 0.17324298620224\n",
      "Iteration: 292/306, Loss: 0.1471371054649353\n",
      "Iteration: 293/306, Loss: 0.12246055901050568\n",
      "Iteration: 294/306, Loss: 0.3330066502094269\n",
      "Iteration: 295/306, Loss: 0.15066249668598175\n",
      "Iteration: 296/306, Loss: 0.17964057624340057\n",
      "Iteration: 297/306, Loss: 0.2060307115316391\n",
      "Iteration: 298/306, Loss: 0.13718777894973755\n",
      "Iteration: 299/306, Loss: 0.14551521837711334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 300/306, Loss: 0.9103072285652161\n",
      "Iteration: 301/306, Loss: 0.17731010913848877\n",
      "Iteration: 302/306, Loss: 0.4931587278842926\n",
      "Iteration: 303/306, Loss: 0.4836885631084442\n",
      "Iteration: 304/306, Loss: 0.19561956822872162\n",
      "Iteration: 305/306, Loss: 0.2524788975715637\n",
      "Iteration: 306/306, Loss: 0.23324330151081085\n",
      "Epoch: 3/10\n",
      "Iteration: 1/306, Loss: 0.2537381649017334\n",
      "Iteration: 2/306, Loss: 0.24341943860054016\n",
      "Iteration: 3/306, Loss: 0.7652291655540466\n",
      "Iteration: 4/306, Loss: 0.4558379054069519\n",
      "Iteration: 5/306, Loss: 0.3177189528942108\n",
      "Iteration: 6/306, Loss: 0.6627232432365417\n",
      "Iteration: 7/306, Loss: 0.4699121117591858\n",
      "Iteration: 8/306, Loss: 0.2029709368944168\n",
      "Iteration: 9/306, Loss: 0.689796507358551\n",
      "Iteration: 10/306, Loss: 0.34559324383735657\n",
      "Iteration: 11/306, Loss: 0.12757275998592377\n",
      "Iteration: 12/306, Loss: 0.20155149698257446\n",
      "Iteration: 13/306, Loss: 0.1734880954027176\n",
      "Iteration: 14/306, Loss: 0.2303205132484436\n",
      "Iteration: 15/306, Loss: 0.1867491453886032\n",
      "Iteration: 16/306, Loss: 0.028841566294431686\n",
      "Iteration: 17/306, Loss: 0.49907147884368896\n",
      "Iteration: 18/306, Loss: 0.11805424094200134\n",
      "Iteration: 19/306, Loss: 0.4328358471393585\n",
      "Iteration: 20/306, Loss: 0.14513646066188812\n",
      "Iteration: 21/306, Loss: 0.19028711318969727\n",
      "Iteration: 22/306, Loss: 0.23104065656661987\n",
      "Iteration: 23/306, Loss: 0.3846200406551361\n",
      "Iteration: 24/306, Loss: 0.1926651895046234\n",
      "Iteration: 25/306, Loss: 0.07247251272201538\n",
      "Iteration: 26/306, Loss: 0.2574669122695923\n",
      "Iteration: 27/306, Loss: 1.0247080326080322\n",
      "Iteration: 28/306, Loss: 0.5373204946517944\n",
      "Iteration: 29/306, Loss: 0.18787389993667603\n",
      "Iteration: 30/306, Loss: 0.29508522152900696\n",
      "Iteration: 31/306, Loss: 0.584415078163147\n",
      "Iteration: 32/306, Loss: 0.5012345314025879\n",
      "Iteration: 33/306, Loss: 0.32134512066841125\n",
      "Iteration: 34/306, Loss: 0.14436407387256622\n",
      "Iteration: 35/306, Loss: 0.293974906206131\n",
      "Iteration: 36/306, Loss: 0.6503886580467224\n",
      "Iteration: 37/306, Loss: 0.09361201524734497\n",
      "Iteration: 38/306, Loss: 0.3914511799812317\n",
      "Iteration: 39/306, Loss: 0.30515599250793457\n",
      "Iteration: 40/306, Loss: 0.08684460818767548\n",
      "Iteration: 41/306, Loss: 0.4960038661956787\n",
      "Iteration: 42/306, Loss: 0.20650194585323334\n",
      "Iteration: 43/306, Loss: 0.47527334094047546\n",
      "Iteration: 44/306, Loss: 0.17208977043628693\n",
      "Iteration: 45/306, Loss: 0.08307807892560959\n",
      "Iteration: 46/306, Loss: 0.15370899438858032\n",
      "Iteration: 47/306, Loss: 0.1264878362417221\n",
      "Iteration: 48/306, Loss: 0.40956905484199524\n",
      "Iteration: 49/306, Loss: 0.11958779394626617\n",
      "Iteration: 50/306, Loss: 0.7768871784210205\n",
      "Iteration: 51/306, Loss: 1.068045973777771\n",
      "Iteration: 52/306, Loss: 0.1356462985277176\n",
      "Iteration: 53/306, Loss: 0.309402734041214\n",
      "Iteration: 54/306, Loss: 0.38656556606292725\n",
      "Iteration: 55/306, Loss: 0.8259062170982361\n",
      "Iteration: 56/306, Loss: 0.7932166457176208\n",
      "Iteration: 57/306, Loss: 0.1825835406780243\n",
      "Iteration: 58/306, Loss: 0.3012717664241791\n",
      "Iteration: 59/306, Loss: 0.10959477722644806\n",
      "Iteration: 60/306, Loss: 0.5213562846183777\n",
      "Iteration: 61/306, Loss: 0.088910773396492\n",
      "Iteration: 62/306, Loss: 0.2282477617263794\n",
      "Iteration: 63/306, Loss: 0.1572481095790863\n",
      "Iteration: 64/306, Loss: 0.31912603974342346\n",
      "Iteration: 65/306, Loss: 0.2586135268211365\n",
      "Iteration: 66/306, Loss: 0.3496803641319275\n",
      "Iteration: 67/306, Loss: 0.5620971322059631\n",
      "Iteration: 68/306, Loss: 0.045372724533081055\n",
      "Iteration: 69/306, Loss: 0.2436220347881317\n",
      "Iteration: 70/306, Loss: 0.5314494371414185\n",
      "Iteration: 71/306, Loss: 0.25960779190063477\n",
      "Iteration: 72/306, Loss: 0.5776826739311218\n",
      "Iteration: 73/306, Loss: 0.08145192265510559\n",
      "Iteration: 74/306, Loss: 0.046240806579589844\n",
      "Iteration: 75/306, Loss: 0.5577990412712097\n",
      "Iteration: 76/306, Loss: 0.214166522026062\n",
      "Iteration: 77/306, Loss: 0.2707730233669281\n",
      "Iteration: 78/306, Loss: 0.2244625836610794\n",
      "Iteration: 79/306, Loss: 0.7384734153747559\n",
      "Iteration: 80/306, Loss: 0.20397821068763733\n",
      "Iteration: 81/306, Loss: 0.10050144046545029\n",
      "Iteration: 82/306, Loss: 0.6763078570365906\n",
      "Iteration: 83/306, Loss: 0.5113871097564697\n",
      "Iteration: 84/306, Loss: 0.319509893655777\n",
      "Iteration: 85/306, Loss: 0.46511998772621155\n",
      "Iteration: 86/306, Loss: 0.16790176928043365\n",
      "Iteration: 87/306, Loss: 0.6509611010551453\n",
      "Iteration: 88/306, Loss: 0.16957047581672668\n",
      "Iteration: 89/306, Loss: 0.9804718494415283\n",
      "Iteration: 90/306, Loss: 0.3928830027580261\n",
      "Iteration: 91/306, Loss: 0.403755247592926\n",
      "Iteration: 92/306, Loss: 0.3777608871459961\n",
      "Iteration: 93/306, Loss: 0.1796295940876007\n",
      "Iteration: 94/306, Loss: 0.4564935564994812\n",
      "Iteration: 95/306, Loss: 0.29788732528686523\n",
      "Iteration: 96/306, Loss: 0.2678290605545044\n",
      "Iteration: 97/306, Loss: 0.29240524768829346\n",
      "Iteration: 98/306, Loss: 0.08689713478088379\n",
      "Iteration: 99/306, Loss: 0.3601239025592804\n",
      "Iteration: 100/306, Loss: 0.18030817806720734\n",
      "Iteration: 101/306, Loss: 0.38302507996559143\n",
      "Iteration: 102/306, Loss: 0.5987494587898254\n",
      "Iteration: 103/306, Loss: 0.17718163132667542\n",
      "Iteration: 104/306, Loss: 0.10677589476108551\n",
      "Iteration: 105/306, Loss: 0.12488466501235962\n",
      "Iteration: 106/306, Loss: 0.19680367410182953\n",
      "Iteration: 107/306, Loss: 0.5271009206771851\n",
      "Iteration: 108/306, Loss: 0.2800363004207611\n",
      "Iteration: 109/306, Loss: 0.3094255030155182\n",
      "Iteration: 110/306, Loss: 0.22233405709266663\n",
      "Iteration: 111/306, Loss: 0.19756871461868286\n",
      "Iteration: 112/306, Loss: 0.49020659923553467\n",
      "Iteration: 113/306, Loss: 0.11421898007392883\n",
      "Iteration: 114/306, Loss: 0.24382975697517395\n",
      "Iteration: 115/306, Loss: 0.10875773429870605\n",
      "Iteration: 116/306, Loss: 0.14392618834972382\n",
      "Iteration: 117/306, Loss: 0.10391069948673248\n",
      "Iteration: 118/306, Loss: 0.27710840106010437\n",
      "Iteration: 119/306, Loss: 0.18743491172790527\n",
      "Iteration: 120/306, Loss: 0.16030433773994446\n",
      "Iteration: 121/306, Loss: 0.6166098117828369\n",
      "Iteration: 122/306, Loss: 0.19308026134967804\n",
      "Iteration: 123/306, Loss: 0.24543625116348267\n",
      "Iteration: 124/306, Loss: 0.26454147696495056\n",
      "Iteration: 125/306, Loss: 0.13852952420711517\n",
      "Iteration: 126/306, Loss: 0.2205951064825058\n",
      "Iteration: 127/306, Loss: 0.11795531958341599\n",
      "Iteration: 128/306, Loss: 0.3845902681350708\n",
      "Iteration: 129/306, Loss: 0.30397164821624756\n",
      "Iteration: 130/306, Loss: 0.05968790128827095\n",
      "Iteration: 131/306, Loss: 0.22495727241039276\n",
      "Iteration: 132/306, Loss: 0.3605520725250244\n",
      "Iteration: 133/306, Loss: 0.13121677935123444\n",
      "Iteration: 134/306, Loss: 0.33478933572769165\n",
      "Iteration: 135/306, Loss: 0.20862962305545807\n",
      "Iteration: 136/306, Loss: 0.2775517702102661\n",
      "Iteration: 137/306, Loss: 0.26640498638153076\n",
      "Iteration: 138/306, Loss: 0.2666536569595337\n",
      "Iteration: 139/306, Loss: 0.7136250734329224\n",
      "Iteration: 140/306, Loss: 0.4543052017688751\n",
      "Iteration: 141/306, Loss: 0.37116357684135437\n",
      "Iteration: 142/306, Loss: 0.25116515159606934\n",
      "Iteration: 143/306, Loss: 0.26919740438461304\n",
      "Iteration: 144/306, Loss: 0.13348741829395294\n",
      "Iteration: 145/306, Loss: 0.18727409839630127\n",
      "Iteration: 146/306, Loss: 0.1441756635904312\n",
      "Iteration: 147/306, Loss: 0.851182222366333\n",
      "Iteration: 148/306, Loss: 0.15356548130512238\n",
      "Iteration: 149/306, Loss: 0.21822813153266907\n",
      "Iteration: 150/306, Loss: 0.2347564697265625\n",
      "Iteration: 151/306, Loss: 0.36373215913772583\n",
      "Iteration: 152/306, Loss: 0.3765740692615509\n",
      "Iteration: 153/306, Loss: 0.46081051230430603\n",
      "Iteration: 154/306, Loss: 0.16486908495426178\n",
      "Iteration: 155/306, Loss: 0.543458104133606\n",
      "Iteration: 156/306, Loss: 0.30945906043052673\n",
      "Iteration: 157/306, Loss: 0.3188202977180481\n",
      "Iteration: 158/306, Loss: 0.06842035800218582\n",
      "Iteration: 159/306, Loss: 0.33601871132850647\n",
      "Iteration: 160/306, Loss: 0.1652848869562149\n",
      "Iteration: 161/306, Loss: 0.29119986295700073\n",
      "Iteration: 162/306, Loss: 0.32655805349349976\n",
      "Iteration: 163/306, Loss: 0.5475385785102844\n",
      "Iteration: 164/306, Loss: 0.17606012523174286\n",
      "Iteration: 165/306, Loss: 0.22936314344406128\n",
      "Iteration: 166/306, Loss: 0.185023695230484\n",
      "Iteration: 167/306, Loss: 0.15326368808746338\n",
      "Iteration: 168/306, Loss: 0.3601870536804199\n",
      "Iteration: 169/306, Loss: 0.2850041687488556\n",
      "Iteration: 170/306, Loss: 0.7620059251785278\n",
      "Iteration: 171/306, Loss: 0.12479262799024582\n",
      "Iteration: 172/306, Loss: 0.19651071727275848\n",
      "Iteration: 173/306, Loss: 0.20740550756454468\n",
      "Iteration: 174/306, Loss: 0.6994146704673767\n",
      "Iteration: 175/306, Loss: 0.12603572010993958\n",
      "Iteration: 176/306, Loss: 0.1743089258670807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 177/306, Loss: 0.2567868232727051\n",
      "Iteration: 178/306, Loss: 0.148703470826149\n",
      "Iteration: 179/306, Loss: 0.09506945312023163\n",
      "Iteration: 180/306, Loss: 0.031312402337789536\n",
      "Iteration: 181/306, Loss: 0.35204049944877625\n",
      "Iteration: 182/306, Loss: 0.20260436832904816\n",
      "Iteration: 183/306, Loss: 0.7368695735931396\n",
      "Iteration: 184/306, Loss: 0.27017906308174133\n",
      "Iteration: 185/306, Loss: 0.26726099848747253\n",
      "Iteration: 186/306, Loss: 0.46044179797172546\n",
      "Iteration: 187/306, Loss: 0.2984713613986969\n",
      "Iteration: 188/306, Loss: 0.2967302203178406\n",
      "Iteration: 189/306, Loss: 0.07281037420034409\n",
      "Iteration: 190/306, Loss: 0.6994426250457764\n",
      "Iteration: 191/306, Loss: 0.1162397712469101\n",
      "Iteration: 192/306, Loss: 0.06474796682596207\n",
      "Iteration: 193/306, Loss: 0.6135586500167847\n",
      "Iteration: 194/306, Loss: 0.6554551124572754\n",
      "Iteration: 195/306, Loss: 0.1987079679965973\n",
      "Iteration: 196/306, Loss: 0.0876549780368805\n",
      "Iteration: 197/306, Loss: 0.07828351855278015\n",
      "Iteration: 198/306, Loss: 0.2082241326570511\n",
      "Iteration: 199/306, Loss: 0.23080182075500488\n",
      "Iteration: 200/306, Loss: 0.23658332228660583\n",
      "Iteration: 201/306, Loss: 0.04257224500179291\n",
      "Iteration: 202/306, Loss: 0.17314893007278442\n",
      "Iteration: 203/306, Loss: 0.35190314054489136\n",
      "Iteration: 204/306, Loss: 0.21863801777362823\n",
      "Iteration: 205/306, Loss: 0.10883623361587524\n",
      "Iteration: 206/306, Loss: 0.4460305869579315\n",
      "Iteration: 207/306, Loss: 0.22162318229675293\n",
      "Iteration: 208/306, Loss: 1.2374879121780396\n",
      "Iteration: 209/306, Loss: 0.1554747372865677\n",
      "Iteration: 210/306, Loss: 0.3122442364692688\n",
      "Iteration: 211/306, Loss: 0.17192095518112183\n",
      "Iteration: 212/306, Loss: 0.6702806353569031\n",
      "Iteration: 213/306, Loss: 0.23268558084964752\n",
      "Iteration: 214/306, Loss: 0.2348083257675171\n",
      "Iteration: 215/306, Loss: 0.44786345958709717\n",
      "Iteration: 216/306, Loss: 0.23525941371917725\n",
      "Iteration: 217/306, Loss: 0.11913951486349106\n",
      "Iteration: 218/306, Loss: 0.21309396624565125\n",
      "Iteration: 219/306, Loss: 0.1515512764453888\n",
      "Iteration: 220/306, Loss: 0.4359979033470154\n",
      "Iteration: 221/306, Loss: 0.5514354109764099\n",
      "Iteration: 222/306, Loss: 0.15658466517925262\n",
      "Iteration: 223/306, Loss: 0.20652616024017334\n",
      "Iteration: 224/306, Loss: 0.024617135524749756\n",
      "Iteration: 225/306, Loss: 0.2604743540287018\n",
      "Iteration: 226/306, Loss: 0.018053477630019188\n",
      "Iteration: 227/306, Loss: 0.4311974048614502\n",
      "Iteration: 228/306, Loss: 0.23895104229450226\n",
      "Iteration: 229/306, Loss: 0.5090500116348267\n",
      "Iteration: 230/306, Loss: 0.30877137184143066\n",
      "Iteration: 231/306, Loss: 0.2186475396156311\n",
      "Iteration: 232/306, Loss: 0.47533005475997925\n",
      "Iteration: 233/306, Loss: 0.26775041222572327\n",
      "Iteration: 234/306, Loss: 0.8799028992652893\n",
      "Iteration: 235/306, Loss: 0.11794144660234451\n",
      "Iteration: 236/306, Loss: 0.25142452120780945\n",
      "Iteration: 237/306, Loss: 0.15706729888916016\n",
      "Iteration: 238/306, Loss: 0.14602316915988922\n",
      "Iteration: 239/306, Loss: 0.09642112255096436\n",
      "Iteration: 240/306, Loss: 0.2032797634601593\n",
      "Iteration: 241/306, Loss: 0.24583302438259125\n",
      "Iteration: 242/306, Loss: 0.17010150849819183\n",
      "Iteration: 243/306, Loss: 0.11517658084630966\n",
      "Iteration: 244/306, Loss: 0.39824068546295166\n",
      "Iteration: 245/306, Loss: 0.46534451842308044\n",
      "Iteration: 246/306, Loss: 0.03716476261615753\n",
      "Iteration: 247/306, Loss: 0.1725904792547226\n",
      "Iteration: 248/306, Loss: 0.7179890275001526\n",
      "Iteration: 249/306, Loss: 0.3055366575717926\n",
      "Iteration: 250/306, Loss: 0.18386754393577576\n",
      "Iteration: 251/306, Loss: 0.722811758518219\n",
      "Iteration: 252/306, Loss: 0.19777321815490723\n",
      "Iteration: 253/306, Loss: 0.5023123621940613\n",
      "Iteration: 254/306, Loss: 0.20197388529777527\n",
      "Iteration: 255/306, Loss: 0.14581798017024994\n",
      "Iteration: 256/306, Loss: 0.37552180886268616\n",
      "Iteration: 257/306, Loss: 0.3726319372653961\n",
      "Iteration: 258/306, Loss: 0.6693719625473022\n",
      "Iteration: 259/306, Loss: 0.1926746964454651\n",
      "Iteration: 260/306, Loss: 0.18750007450580597\n",
      "Iteration: 261/306, Loss: 0.183608278632164\n",
      "Iteration: 262/306, Loss: 0.29216837882995605\n",
      "Iteration: 263/306, Loss: 0.2983696758747101\n",
      "Iteration: 264/306, Loss: 0.517367959022522\n",
      "Iteration: 265/306, Loss: 0.2002139836549759\n",
      "Iteration: 266/306, Loss: 0.23494300246238708\n",
      "Iteration: 267/306, Loss: 0.25247326493263245\n",
      "Iteration: 268/306, Loss: 0.5509118437767029\n",
      "Iteration: 269/306, Loss: 0.38055410981178284\n",
      "Iteration: 270/306, Loss: 0.22545747458934784\n",
      "Iteration: 271/306, Loss: 0.3928707242012024\n",
      "Iteration: 272/306, Loss: 0.12045231461524963\n",
      "Iteration: 273/306, Loss: 0.20251984894275665\n",
      "Iteration: 274/306, Loss: 0.202012300491333\n",
      "Iteration: 275/306, Loss: 0.5270553231239319\n",
      "Iteration: 276/306, Loss: 0.22446253895759583\n",
      "Iteration: 277/306, Loss: 0.6621851325035095\n",
      "Iteration: 278/306, Loss: 0.18701878190040588\n",
      "Iteration: 279/306, Loss: 0.19730880856513977\n",
      "Iteration: 280/306, Loss: 0.15225650370121002\n",
      "Iteration: 281/306, Loss: 0.267852783203125\n",
      "Iteration: 282/306, Loss: 1.191299319267273\n",
      "Iteration: 283/306, Loss: 0.43226850032806396\n",
      "Iteration: 284/306, Loss: 0.1579824686050415\n",
      "Iteration: 285/306, Loss: 0.309187114238739\n",
      "Iteration: 286/306, Loss: 0.5508406758308411\n",
      "Iteration: 287/306, Loss: 0.2574923038482666\n",
      "Iteration: 288/306, Loss: 0.7338232398033142\n",
      "Iteration: 289/306, Loss: 0.02465846762061119\n",
      "Iteration: 290/306, Loss: 0.03057883121073246\n",
      "Iteration: 291/306, Loss: 0.359798789024353\n",
      "Iteration: 292/306, Loss: 0.04312293976545334\n",
      "Iteration: 293/306, Loss: 0.20551837980747223\n",
      "Iteration: 294/306, Loss: 0.522711455821991\n",
      "Iteration: 295/306, Loss: 0.2865125238895416\n",
      "Iteration: 296/306, Loss: 0.16393890976905823\n",
      "Iteration: 297/306, Loss: 0.34615153074264526\n",
      "Iteration: 298/306, Loss: 0.11145167052745819\n",
      "Iteration: 299/306, Loss: 0.42161402106285095\n",
      "Iteration: 300/306, Loss: 0.7106769680976868\n",
      "Iteration: 301/306, Loss: 0.37833940982818604\n",
      "Iteration: 302/306, Loss: 0.10453339666128159\n",
      "Iteration: 303/306, Loss: 0.6767768263816833\n",
      "Iteration: 304/306, Loss: 0.4518791735172272\n",
      "Iteration: 305/306, Loss: 0.18827272951602936\n",
      "Iteration: 306/306, Loss: 0.5430623292922974\n",
      "Epoch: 4/10\n",
      "Iteration: 1/306, Loss: 0.4742185175418854\n",
      "Iteration: 2/306, Loss: 0.35981932282447815\n",
      "Iteration: 3/306, Loss: 0.35024264454841614\n",
      "Iteration: 4/306, Loss: 0.503041684627533\n",
      "Iteration: 5/306, Loss: 0.32782527804374695\n",
      "Iteration: 6/306, Loss: 0.1967993825674057\n",
      "Iteration: 7/306, Loss: 0.4573042392730713\n",
      "Iteration: 8/306, Loss: 0.5683256983757019\n",
      "Iteration: 9/306, Loss: 0.7639630436897278\n",
      "Iteration: 10/306, Loss: 0.4738898277282715\n",
      "Iteration: 11/306, Loss: 0.2998654842376709\n",
      "Iteration: 12/306, Loss: 0.2086750566959381\n",
      "Iteration: 13/306, Loss: 0.05786740407347679\n",
      "Iteration: 14/306, Loss: 0.15605726838111877\n",
      "Iteration: 15/306, Loss: 0.21083669364452362\n",
      "Iteration: 16/306, Loss: 0.177745521068573\n",
      "Iteration: 17/306, Loss: 0.22303646802902222\n",
      "Iteration: 18/306, Loss: 0.411325603723526\n",
      "Iteration: 19/306, Loss: 0.15807972848415375\n",
      "Iteration: 20/306, Loss: 0.32726114988327026\n",
      "Iteration: 21/306, Loss: 0.14503689110279083\n",
      "Iteration: 22/306, Loss: 0.18757569789886475\n",
      "Iteration: 23/306, Loss: 0.18295082449913025\n",
      "Iteration: 24/306, Loss: 0.12415744364261627\n",
      "Iteration: 25/306, Loss: 0.1642434149980545\n",
      "Iteration: 26/306, Loss: 0.5083954334259033\n",
      "Iteration: 27/306, Loss: 0.1959202140569687\n",
      "Iteration: 28/306, Loss: 0.05952610820531845\n",
      "Iteration: 29/306, Loss: 0.5531241297721863\n",
      "Iteration: 30/306, Loss: 0.026305796578526497\n",
      "Iteration: 31/306, Loss: 1.0270674228668213\n",
      "Iteration: 32/306, Loss: 0.1715686172246933\n",
      "Iteration: 33/306, Loss: 0.16970762610435486\n",
      "Iteration: 34/306, Loss: 0.533259928226471\n",
      "Iteration: 35/306, Loss: 0.11261648684740067\n",
      "Iteration: 36/306, Loss: 0.4764118790626526\n",
      "Iteration: 37/306, Loss: 0.3435930013656616\n",
      "Iteration: 38/306, Loss: 0.14832435548305511\n",
      "Iteration: 39/306, Loss: 1.0526050329208374\n",
      "Iteration: 40/306, Loss: 0.2167586088180542\n",
      "Iteration: 41/306, Loss: 0.3532686233520508\n",
      "Iteration: 42/306, Loss: 0.3095826506614685\n",
      "Iteration: 43/306, Loss: 0.1721206158399582\n",
      "Iteration: 44/306, Loss: 0.07059037685394287\n",
      "Iteration: 45/306, Loss: 0.0771276205778122\n",
      "Iteration: 46/306, Loss: 0.26080089807510376\n",
      "Iteration: 47/306, Loss: 0.022842900827527046\n",
      "Iteration: 48/306, Loss: 0.060045842081308365\n",
      "Iteration: 49/306, Loss: 0.8487015962600708\n",
      "Iteration: 50/306, Loss: 0.1819906234741211\n",
      "Iteration: 51/306, Loss: 0.3471003770828247\n",
      "Iteration: 52/306, Loss: 0.4781677722930908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 53/306, Loss: 0.9405106902122498\n",
      "Iteration: 54/306, Loss: 0.1671696901321411\n",
      "Iteration: 55/306, Loss: 0.05446813255548477\n",
      "Iteration: 56/306, Loss: 0.2881734073162079\n",
      "Iteration: 57/306, Loss: 0.27558112144470215\n",
      "Iteration: 58/306, Loss: 0.3547980785369873\n",
      "Iteration: 59/306, Loss: 0.12108083069324493\n",
      "Iteration: 60/306, Loss: 0.19295752048492432\n",
      "Iteration: 61/306, Loss: 0.48976171016693115\n",
      "Iteration: 62/306, Loss: 0.3431518077850342\n",
      "Iteration: 63/306, Loss: 0.3483031988143921\n",
      "Iteration: 64/306, Loss: 0.12232806533575058\n",
      "Iteration: 65/306, Loss: 0.21629399061203003\n",
      "Iteration: 66/306, Loss: 0.1440090537071228\n",
      "Iteration: 67/306, Loss: 0.17522107064723969\n",
      "Iteration: 68/306, Loss: 0.22763021290302277\n",
      "Iteration: 69/306, Loss: 0.324670672416687\n",
      "Iteration: 70/306, Loss: 0.15477070212364197\n",
      "Iteration: 71/306, Loss: 0.15176013112068176\n",
      "Iteration: 72/306, Loss: 0.14849111437797546\n",
      "Iteration: 73/306, Loss: 0.07588841021060944\n",
      "Iteration: 74/306, Loss: 0.17548848688602448\n",
      "Iteration: 75/306, Loss: 0.1452634483575821\n",
      "Iteration: 76/306, Loss: 0.9419673085212708\n",
      "Iteration: 77/306, Loss: 0.4523313641548157\n",
      "Iteration: 78/306, Loss: 0.18761032819747925\n",
      "Iteration: 79/306, Loss: 0.1835213154554367\n",
      "Iteration: 80/306, Loss: 0.2815084457397461\n",
      "Iteration: 81/306, Loss: 0.420011043548584\n",
      "Iteration: 82/306, Loss: 0.4594159424304962\n",
      "Iteration: 83/306, Loss: 0.3103853464126587\n",
      "Iteration: 84/306, Loss: 0.1594814658164978\n",
      "Iteration: 85/306, Loss: 0.39281243085861206\n",
      "Iteration: 86/306, Loss: 0.4422975182533264\n",
      "Iteration: 87/306, Loss: 0.24332861602306366\n",
      "Iteration: 88/306, Loss: 0.5153251886367798\n",
      "Iteration: 89/306, Loss: 0.06002826988697052\n",
      "Iteration: 90/306, Loss: 0.25510963797569275\n",
      "Iteration: 91/306, Loss: 0.325174480676651\n",
      "Iteration: 92/306, Loss: 0.8461052179336548\n",
      "Iteration: 93/306, Loss: 0.1601579189300537\n",
      "Iteration: 94/306, Loss: 0.1801663041114807\n",
      "Iteration: 95/306, Loss: 0.3075365126132965\n",
      "Iteration: 96/306, Loss: 0.15879030525684357\n",
      "Iteration: 97/306, Loss: 0.2002578228712082\n",
      "Iteration: 98/306, Loss: 0.11636210978031158\n",
      "Iteration: 99/306, Loss: 0.12115417420864105\n",
      "Iteration: 100/306, Loss: 0.164340540766716\n",
      "Iteration: 101/306, Loss: 0.041575293987989426\n",
      "Iteration: 102/306, Loss: 0.13581381738185883\n",
      "Iteration: 103/306, Loss: 0.029834099113941193\n",
      "Iteration: 104/306, Loss: 0.34517744183540344\n",
      "Iteration: 105/306, Loss: 0.14908088743686676\n",
      "Iteration: 106/306, Loss: 0.3646000921726227\n",
      "Iteration: 107/306, Loss: 0.2749786674976349\n",
      "Iteration: 108/306, Loss: 0.019536860287189484\n",
      "Iteration: 109/306, Loss: 0.11984607577323914\n",
      "Iteration: 110/306, Loss: 0.4904717803001404\n",
      "Iteration: 111/306, Loss: 0.07805153727531433\n",
      "Iteration: 112/306, Loss: 0.1725536286830902\n",
      "Iteration: 113/306, Loss: 0.7986034154891968\n",
      "Iteration: 114/306, Loss: 0.3944616913795471\n",
      "Iteration: 115/306, Loss: 0.3008567690849304\n",
      "Iteration: 116/306, Loss: 0.5603134632110596\n",
      "Iteration: 117/306, Loss: 0.5012184977531433\n",
      "Iteration: 118/306, Loss: 0.19036053121089935\n",
      "Iteration: 119/306, Loss: 0.529548168182373\n",
      "Iteration: 120/306, Loss: 0.17926740646362305\n",
      "Iteration: 121/306, Loss: 0.23598404228687286\n",
      "Iteration: 122/306, Loss: 0.029681753367185593\n",
      "Iteration: 123/306, Loss: 0.17150650918483734\n",
      "Iteration: 124/306, Loss: 0.33552637696266174\n",
      "Iteration: 125/306, Loss: 0.9734132885932922\n",
      "Iteration: 126/306, Loss: 0.24008426070213318\n",
      "Iteration: 127/306, Loss: 0.21357525885105133\n",
      "Iteration: 128/306, Loss: 0.2783864736557007\n",
      "Iteration: 129/306, Loss: 0.19062113761901855\n",
      "Iteration: 130/306, Loss: 0.28821489214897156\n",
      "Iteration: 131/306, Loss: 0.4648779630661011\n",
      "Iteration: 132/306, Loss: 0.2782159447669983\n",
      "Iteration: 133/306, Loss: 0.24623896181583405\n",
      "Iteration: 134/306, Loss: 0.15957196056842804\n",
      "Iteration: 135/306, Loss: 0.2656892240047455\n",
      "Iteration: 136/306, Loss: 0.12428368628025055\n",
      "Iteration: 137/306, Loss: 0.24050074815750122\n",
      "Iteration: 138/306, Loss: 0.6022001504898071\n",
      "Iteration: 139/306, Loss: 0.18212458491325378\n",
      "Iteration: 140/306, Loss: 0.17710177600383759\n",
      "Iteration: 141/306, Loss: 0.2842041254043579\n",
      "Iteration: 142/306, Loss: 0.22935332357883453\n",
      "Iteration: 143/306, Loss: 0.45389723777770996\n",
      "Iteration: 144/306, Loss: 0.7176640629768372\n",
      "Iteration: 145/306, Loss: 0.39948874711990356\n",
      "Iteration: 146/306, Loss: 0.25542664527893066\n",
      "Iteration: 147/306, Loss: 0.21000508964061737\n",
      "Iteration: 148/306, Loss: 0.9216225743293762\n",
      "Iteration: 149/306, Loss: 0.3383810222148895\n",
      "Iteration: 150/306, Loss: 0.16238968074321747\n",
      "Iteration: 151/306, Loss: 0.26700347661972046\n",
      "Iteration: 152/306, Loss: 0.1789686530828476\n",
      "Iteration: 153/306, Loss: 0.15065564215183258\n",
      "Iteration: 154/306, Loss: 0.04670330509543419\n",
      "Iteration: 155/306, Loss: 0.25960367918014526\n",
      "Iteration: 156/306, Loss: 0.1611698865890503\n",
      "Iteration: 157/306, Loss: 0.14933250844478607\n",
      "Iteration: 158/306, Loss: 0.1985124796628952\n",
      "Iteration: 159/306, Loss: 0.8007952570915222\n",
      "Iteration: 160/306, Loss: 0.3448726236820221\n",
      "Iteration: 161/306, Loss: 0.034021612256765366\n",
      "Iteration: 162/306, Loss: 0.5794313549995422\n",
      "Iteration: 163/306, Loss: 0.10165616869926453\n",
      "Iteration: 164/306, Loss: 0.5753938555717468\n",
      "Iteration: 165/306, Loss: 0.17177176475524902\n",
      "Iteration: 166/306, Loss: 0.19207152724266052\n",
      "Iteration: 167/306, Loss: 0.16881345212459564\n",
      "Iteration: 168/306, Loss: 0.48510289192199707\n",
      "Iteration: 169/306, Loss: 0.19424158334732056\n",
      "Iteration: 170/306, Loss: 0.15790557861328125\n",
      "Iteration: 171/306, Loss: 0.45614972710609436\n",
      "Iteration: 172/306, Loss: 0.5401678681373596\n",
      "Iteration: 173/306, Loss: 0.6749648451805115\n",
      "Iteration: 174/306, Loss: 1.089337944984436\n",
      "Iteration: 175/306, Loss: 0.22411756217479706\n",
      "Iteration: 176/306, Loss: 0.2675773501396179\n",
      "Iteration: 177/306, Loss: 0.340275377035141\n",
      "Iteration: 178/306, Loss: 0.8843503594398499\n",
      "Iteration: 179/306, Loss: 0.1402222365140915\n",
      "Iteration: 180/306, Loss: 0.45869362354278564\n",
      "Iteration: 181/306, Loss: 0.3264803886413574\n",
      "Iteration: 182/306, Loss: 0.28582778573036194\n",
      "Iteration: 183/306, Loss: 0.48321157693862915\n",
      "Iteration: 184/306, Loss: 0.9489288926124573\n",
      "Iteration: 185/306, Loss: 0.6062718629837036\n",
      "Iteration: 186/306, Loss: 0.7031455039978027\n",
      "Iteration: 187/306, Loss: 0.7183064818382263\n",
      "Iteration: 188/306, Loss: 0.35601338744163513\n",
      "Iteration: 189/306, Loss: 0.19798396527767181\n",
      "Iteration: 190/306, Loss: 0.2536197900772095\n",
      "Iteration: 191/306, Loss: 0.659282922744751\n",
      "Iteration: 192/306, Loss: 0.07231051474809647\n",
      "Iteration: 193/306, Loss: 0.2804892063140869\n",
      "Iteration: 194/306, Loss: 0.22977286577224731\n",
      "Iteration: 195/306, Loss: 0.35178443789482117\n",
      "Iteration: 196/306, Loss: 0.2438243329524994\n",
      "Iteration: 197/306, Loss: 0.3388414680957794\n",
      "Iteration: 198/306, Loss: 0.38882753252983093\n",
      "Iteration: 199/306, Loss: 0.24572457373142242\n",
      "Iteration: 200/306, Loss: 0.17765171825885773\n",
      "Iteration: 201/306, Loss: 0.19189777970314026\n",
      "Iteration: 202/306, Loss: 0.14824576675891876\n",
      "Iteration: 203/306, Loss: 0.5472772717475891\n",
      "Iteration: 204/306, Loss: 0.33602890372276306\n",
      "Iteration: 205/306, Loss: 0.4184836149215698\n",
      "Iteration: 206/306, Loss: 0.27537646889686584\n",
      "Iteration: 207/306, Loss: 0.42571622133255005\n",
      "Iteration: 208/306, Loss: 0.025268608704209328\n",
      "Iteration: 209/306, Loss: 0.23144219815731049\n",
      "Iteration: 210/306, Loss: 0.036667559295892715\n",
      "Iteration: 211/306, Loss: 0.25115859508514404\n",
      "Iteration: 212/306, Loss: 0.11755074560642242\n",
      "Iteration: 213/306, Loss: 0.02209285832941532\n",
      "Iteration: 214/306, Loss: 0.621624231338501\n",
      "Iteration: 215/306, Loss: 0.19672884047031403\n",
      "Iteration: 216/306, Loss: 0.007764922454953194\n",
      "Iteration: 217/306, Loss: 0.08688926696777344\n",
      "Iteration: 218/306, Loss: 0.24920885264873505\n",
      "Iteration: 219/306, Loss: 1.1423746347427368\n",
      "Iteration: 220/306, Loss: 0.18839430809020996\n",
      "Iteration: 221/306, Loss: 0.23313242197036743\n",
      "Iteration: 222/306, Loss: 0.4937732219696045\n",
      "Iteration: 223/306, Loss: 0.4844738841056824\n",
      "Iteration: 224/306, Loss: 0.14999136328697205\n",
      "Iteration: 225/306, Loss: 0.08597173541784286\n",
      "Iteration: 226/306, Loss: 0.5364283323287964\n",
      "Iteration: 227/306, Loss: 0.23670785129070282\n",
      "Iteration: 228/306, Loss: 0.18537092208862305\n",
      "Iteration: 229/306, Loss: 0.1308244913816452\n",
      "Iteration: 230/306, Loss: 0.26594632863998413\n",
      "Iteration: 231/306, Loss: 0.2147894650697708\n",
      "Iteration: 232/306, Loss: 0.25130289793014526\n",
      "Iteration: 233/306, Loss: 0.16839063167572021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 234/306, Loss: 0.872679591178894\n",
      "Iteration: 235/306, Loss: 0.44184592366218567\n",
      "Iteration: 236/306, Loss: 0.23669017851352692\n",
      "Iteration: 237/306, Loss: 0.3151116669178009\n",
      "Iteration: 238/306, Loss: 0.2431601583957672\n",
      "Iteration: 239/306, Loss: 0.24288414418697357\n",
      "Iteration: 240/306, Loss: 0.16017211973667145\n",
      "Iteration: 241/306, Loss: 0.22188185155391693\n",
      "Iteration: 242/306, Loss: 0.3510950207710266\n",
      "Iteration: 243/306, Loss: 0.7935048341751099\n",
      "Iteration: 244/306, Loss: 0.959901750087738\n",
      "Iteration: 245/306, Loss: 0.28808078169822693\n",
      "Iteration: 246/306, Loss: 0.37430545687675476\n",
      "Iteration: 247/306, Loss: 0.16322092711925507\n",
      "Iteration: 248/306, Loss: 0.11164319515228271\n",
      "Iteration: 249/306, Loss: 0.3980701267719269\n",
      "Iteration: 250/306, Loss: 0.37493157386779785\n",
      "Iteration: 251/306, Loss: 0.4952722191810608\n",
      "Iteration: 252/306, Loss: 0.1974198967218399\n",
      "Iteration: 253/306, Loss: 0.26772990822792053\n",
      "Iteration: 254/306, Loss: 0.40230000019073486\n",
      "Iteration: 255/306, Loss: 0.5804935693740845\n",
      "Iteration: 256/306, Loss: 0.1721324473619461\n",
      "Iteration: 257/306, Loss: 0.43538716435432434\n",
      "Iteration: 258/306, Loss: 0.30028659105300903\n",
      "Iteration: 259/306, Loss: 0.3809332549571991\n",
      "Iteration: 260/306, Loss: 0.04796508699655533\n",
      "Iteration: 261/306, Loss: 0.12346360087394714\n",
      "Iteration: 262/306, Loss: 0.012467503547668457\n",
      "Iteration: 263/306, Loss: 0.034494224935770035\n",
      "Iteration: 264/306, Loss: 0.30512940883636475\n",
      "Iteration: 265/306, Loss: 0.2867511212825775\n",
      "Iteration: 266/306, Loss: 0.3117274045944214\n",
      "Iteration: 267/306, Loss: 0.18862482905387878\n",
      "Iteration: 268/306, Loss: 0.14925959706306458\n",
      "Iteration: 269/306, Loss: 0.6088705062866211\n",
      "Iteration: 270/306, Loss: 1.2291780710220337\n",
      "Iteration: 271/306, Loss: 0.23755811154842377\n",
      "Iteration: 272/306, Loss: 0.25841209292411804\n",
      "Iteration: 273/306, Loss: 0.331175297498703\n",
      "Iteration: 274/306, Loss: 0.2779029607772827\n",
      "Iteration: 275/306, Loss: 0.27366453409194946\n",
      "Iteration: 276/306, Loss: 0.44832754135131836\n",
      "Iteration: 277/306, Loss: 0.5879168510437012\n",
      "Iteration: 278/306, Loss: 0.5350227355957031\n",
      "Iteration: 279/306, Loss: 0.13331517577171326\n",
      "Iteration: 280/306, Loss: 0.602510392665863\n",
      "Iteration: 281/306, Loss: 0.10614242404699326\n",
      "Iteration: 282/306, Loss: 0.03609191253781319\n",
      "Iteration: 283/306, Loss: 0.21627436578273773\n",
      "Iteration: 284/306, Loss: 0.19218486547470093\n",
      "Iteration: 285/306, Loss: 0.3393022119998932\n",
      "Iteration: 286/306, Loss: 0.08646226674318314\n",
      "Iteration: 287/306, Loss: 0.6648141741752625\n",
      "Iteration: 288/306, Loss: 0.15149632096290588\n",
      "Iteration: 289/306, Loss: 0.3016643226146698\n",
      "Iteration: 290/306, Loss: 0.49478578567504883\n",
      "Iteration: 291/306, Loss: 0.1947755217552185\n",
      "Iteration: 292/306, Loss: 0.5664659142494202\n",
      "Iteration: 293/306, Loss: 0.39152196049690247\n",
      "Iteration: 294/306, Loss: 0.16051726043224335\n",
      "Iteration: 295/306, Loss: 0.18167735636234283\n",
      "Iteration: 296/306, Loss: 0.1105324774980545\n",
      "Iteration: 297/306, Loss: 0.21035656332969666\n",
      "Iteration: 298/306, Loss: 0.1369742453098297\n",
      "Iteration: 299/306, Loss: 0.21112793684005737\n",
      "Iteration: 300/306, Loss: 0.5012417435646057\n",
      "Iteration: 301/306, Loss: 0.6150000095367432\n",
      "Iteration: 302/306, Loss: 0.20679178833961487\n",
      "Iteration: 303/306, Loss: 0.14097586274147034\n",
      "Iteration: 304/306, Loss: 0.47828805446624756\n",
      "Iteration: 305/306, Loss: 0.5159766674041748\n",
      "Iteration: 306/306, Loss: 0.3811856806278229\n",
      "Epoch: 5/10\n",
      "Iteration: 1/306, Loss: 0.2822669446468353\n",
      "Iteration: 2/306, Loss: 0.3932759463787079\n",
      "Iteration: 3/306, Loss: 0.2294517606496811\n",
      "Iteration: 4/306, Loss: 0.04429104924201965\n",
      "Iteration: 5/306, Loss: 0.13413679599761963\n",
      "Iteration: 6/306, Loss: 0.03797507658600807\n",
      "Iteration: 7/306, Loss: 0.4874219596385956\n",
      "Iteration: 8/306, Loss: 0.02656494826078415\n",
      "Iteration: 9/306, Loss: 0.15722602605819702\n",
      "Iteration: 10/306, Loss: 0.8194470405578613\n",
      "Iteration: 11/306, Loss: 0.3127835988998413\n",
      "Iteration: 12/306, Loss: 0.31169867515563965\n",
      "Iteration: 13/306, Loss: 0.395020991563797\n",
      "Iteration: 14/306, Loss: 0.19272224605083466\n",
      "Iteration: 15/306, Loss: 0.42394137382507324\n",
      "Iteration: 16/306, Loss: 0.24945031106472015\n",
      "Iteration: 17/306, Loss: 0.19002608954906464\n",
      "Iteration: 18/306, Loss: 0.38173431158065796\n",
      "Iteration: 19/306, Loss: 0.290011465549469\n",
      "Iteration: 20/306, Loss: 0.14154118299484253\n",
      "Iteration: 21/306, Loss: 0.632247269153595\n",
      "Iteration: 22/306, Loss: 0.24810956418514252\n",
      "Iteration: 23/306, Loss: 0.17820046842098236\n",
      "Iteration: 24/306, Loss: 0.9701735377311707\n",
      "Iteration: 25/306, Loss: 0.5211168527603149\n",
      "Iteration: 26/306, Loss: 0.16756869852542877\n",
      "Iteration: 27/306, Loss: 0.3552810549736023\n",
      "Iteration: 28/306, Loss: 0.17980097234249115\n",
      "Iteration: 29/306, Loss: 0.39938023686408997\n",
      "Iteration: 30/306, Loss: 0.42813655734062195\n",
      "Iteration: 31/306, Loss: 0.19721108675003052\n",
      "Iteration: 32/306, Loss: 0.11893989145755768\n",
      "Iteration: 33/306, Loss: 0.35363349318504333\n",
      "Iteration: 34/306, Loss: 0.968512773513794\n",
      "Iteration: 35/306, Loss: 0.49821344017982483\n",
      "Iteration: 36/306, Loss: 0.18297170102596283\n",
      "Iteration: 37/306, Loss: 0.22281426191329956\n",
      "Iteration: 38/306, Loss: 0.14931629598140717\n",
      "Iteration: 39/306, Loss: 0.29751071333885193\n",
      "Iteration: 40/306, Loss: 0.4365955889225006\n",
      "Iteration: 41/306, Loss: 0.28694191575050354\n",
      "Iteration: 42/306, Loss: 0.15945230424404144\n",
      "Iteration: 43/306, Loss: 0.5221661329269409\n",
      "Iteration: 44/306, Loss: 0.08916288614273071\n",
      "Iteration: 45/306, Loss: 0.08025755733251572\n",
      "Iteration: 46/306, Loss: 0.11909632384777069\n",
      "Iteration: 47/306, Loss: 0.18669405579566956\n",
      "Iteration: 48/306, Loss: 0.14482460916042328\n",
      "Iteration: 49/306, Loss: 0.023686997592449188\n",
      "Iteration: 50/306, Loss: 0.44323641061782837\n",
      "Iteration: 51/306, Loss: 0.3005096912384033\n",
      "Iteration: 52/306, Loss: 0.3412749767303467\n",
      "Iteration: 53/306, Loss: 0.1824837625026703\n",
      "Iteration: 54/306, Loss: 0.04200543463230133\n",
      "Iteration: 55/306, Loss: 0.7193215489387512\n",
      "Iteration: 56/306, Loss: 0.2987003028392792\n",
      "Iteration: 57/306, Loss: 0.11569692939519882\n",
      "Iteration: 58/306, Loss: 0.24914367496967316\n",
      "Iteration: 59/306, Loss: 0.19825837016105652\n",
      "Iteration: 60/306, Loss: 0.5023065209388733\n",
      "Iteration: 61/306, Loss: 0.372577965259552\n",
      "Iteration: 62/306, Loss: 0.15730810165405273\n",
      "Iteration: 63/306, Loss: 0.4344344139099121\n",
      "Iteration: 64/306, Loss: 0.3881831467151642\n",
      "Iteration: 65/306, Loss: 0.38951167464256287\n",
      "Iteration: 66/306, Loss: 0.15664906799793243\n",
      "Iteration: 67/306, Loss: 0.6285295486450195\n",
      "Iteration: 68/306, Loss: 0.10912108421325684\n",
      "Iteration: 69/306, Loss: 0.16427575051784515\n",
      "Iteration: 70/306, Loss: 0.2324538379907608\n",
      "Iteration: 71/306, Loss: 0.3025074303150177\n",
      "Iteration: 72/306, Loss: 0.17372752726078033\n",
      "Iteration: 73/306, Loss: 0.21205894649028778\n",
      "Iteration: 74/306, Loss: 0.5653610825538635\n",
      "Iteration: 75/306, Loss: 0.3972025215625763\n",
      "Iteration: 76/306, Loss: 0.1326756626367569\n",
      "Iteration: 77/306, Loss: 0.6816840171813965\n",
      "Iteration: 78/306, Loss: 0.18837915360927582\n",
      "Iteration: 79/306, Loss: 0.652391791343689\n",
      "Iteration: 80/306, Loss: 0.4725117087364197\n",
      "Iteration: 81/306, Loss: 0.5543935894966125\n",
      "Iteration: 82/306, Loss: 0.43370455503463745\n",
      "Iteration: 83/306, Loss: 0.3257899284362793\n",
      "Iteration: 84/306, Loss: 0.7759235501289368\n",
      "Iteration: 85/306, Loss: 0.09778931736946106\n",
      "Iteration: 86/306, Loss: 0.1747940182685852\n",
      "Iteration: 87/306, Loss: 0.18648560345172882\n",
      "Iteration: 88/306, Loss: 0.6390708684921265\n",
      "Iteration: 89/306, Loss: 0.21883995831012726\n",
      "Iteration: 90/306, Loss: 0.0987338051199913\n",
      "Iteration: 91/306, Loss: 0.980103611946106\n",
      "Iteration: 92/306, Loss: 0.1772509068250656\n",
      "Iteration: 93/306, Loss: 0.1984301060438156\n",
      "Iteration: 94/306, Loss: 0.2976820468902588\n",
      "Iteration: 95/306, Loss: 0.07319722324609756\n",
      "Iteration: 96/306, Loss: 0.21977590024471283\n",
      "Iteration: 97/306, Loss: 0.19708940386772156\n",
      "Iteration: 98/306, Loss: 0.22807319462299347\n",
      "Iteration: 99/306, Loss: 0.40186771750450134\n",
      "Iteration: 100/306, Loss: 0.22526156902313232\n",
      "Iteration: 101/306, Loss: 0.13016055524349213\n",
      "Iteration: 102/306, Loss: 1.1504971981048584\n",
      "Iteration: 103/306, Loss: 0.24055682122707367\n",
      "Iteration: 104/306, Loss: 0.1899605095386505\n",
      "Iteration: 105/306, Loss: 0.4599348306655884\n",
      "Iteration: 106/306, Loss: 0.21185897290706635\n",
      "Iteration: 107/306, Loss: 0.21891869604587555\n",
      "Iteration: 108/306, Loss: 0.3187715411186218\n",
      "Iteration: 109/306, Loss: 0.07217897474765778\n",
      "Iteration: 110/306, Loss: 0.1636408269405365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 111/306, Loss: 0.26873764395713806\n",
      "Iteration: 112/306, Loss: 0.3014206290245056\n",
      "Iteration: 113/306, Loss: 0.49599897861480713\n",
      "Iteration: 114/306, Loss: 0.5484827756881714\n",
      "Iteration: 115/306, Loss: 0.32791867852211\n",
      "Iteration: 116/306, Loss: 0.16871607303619385\n",
      "Iteration: 117/306, Loss: 0.7077460885047913\n",
      "Iteration: 118/306, Loss: 0.3096110224723816\n",
      "Iteration: 119/306, Loss: 0.08592761307954788\n",
      "Iteration: 120/306, Loss: 0.3816768527030945\n",
      "Iteration: 121/306, Loss: 0.4136926233768463\n",
      "Iteration: 122/306, Loss: 0.41761016845703125\n",
      "Iteration: 123/306, Loss: 0.4277631342411041\n",
      "Iteration: 124/306, Loss: 0.31821349263191223\n",
      "Iteration: 125/306, Loss: 0.14715126156806946\n",
      "Iteration: 126/306, Loss: 0.3185219168663025\n",
      "Iteration: 127/306, Loss: 0.1694115251302719\n",
      "Iteration: 128/306, Loss: 0.140303835272789\n",
      "Iteration: 129/306, Loss: 0.08187862485647202\n",
      "Iteration: 130/306, Loss: 0.6575456857681274\n",
      "Iteration: 131/306, Loss: 0.2898211181163788\n",
      "Iteration: 132/306, Loss: 0.21338604390621185\n",
      "Iteration: 133/306, Loss: 0.5181184411048889\n",
      "Iteration: 134/306, Loss: 0.6115341186523438\n",
      "Iteration: 135/306, Loss: 0.47121647000312805\n",
      "Iteration: 136/306, Loss: 0.4924894869327545\n",
      "Iteration: 137/306, Loss: 0.17182967066764832\n",
      "Iteration: 138/306, Loss: 0.06525200605392456\n",
      "Iteration: 139/306, Loss: 0.2501533627510071\n",
      "Iteration: 140/306, Loss: 0.5948925018310547\n",
      "Iteration: 141/306, Loss: 0.2766839861869812\n",
      "Iteration: 142/306, Loss: 0.1979694813489914\n",
      "Iteration: 143/306, Loss: 0.20219279825687408\n",
      "Iteration: 144/306, Loss: 0.5899549722671509\n",
      "Iteration: 145/306, Loss: 0.37698566913604736\n",
      "Iteration: 146/306, Loss: 0.20151706039905548\n",
      "Iteration: 147/306, Loss: 0.2108425348997116\n",
      "Iteration: 148/306, Loss: 0.5852247476577759\n",
      "Iteration: 149/306, Loss: 0.3390273451805115\n",
      "Iteration: 150/306, Loss: 1.1354968547821045\n",
      "Iteration: 151/306, Loss: 0.21355727314949036\n",
      "Iteration: 152/306, Loss: 0.3204226791858673\n",
      "Iteration: 153/306, Loss: 0.3756079375743866\n",
      "Iteration: 154/306, Loss: 0.06641498953104019\n",
      "Iteration: 155/306, Loss: 0.2278347909450531\n",
      "Iteration: 156/306, Loss: 0.19413261115550995\n",
      "Iteration: 157/306, Loss: 0.3200528025627136\n",
      "Iteration: 158/306, Loss: 0.15795573592185974\n",
      "Iteration: 159/306, Loss: 0.5400323867797852\n",
      "Iteration: 160/306, Loss: 0.17171534895896912\n",
      "Iteration: 161/306, Loss: 0.20598727464675903\n",
      "Iteration: 162/306, Loss: 0.30829891562461853\n",
      "Iteration: 163/306, Loss: 0.6678031086921692\n",
      "Iteration: 164/306, Loss: 0.1628628820180893\n",
      "Iteration: 165/306, Loss: 0.2428520917892456\n",
      "Iteration: 166/306, Loss: 0.40326884388923645\n",
      "Iteration: 167/306, Loss: 0.18086257576942444\n",
      "Iteration: 168/306, Loss: 0.19465656578540802\n",
      "Iteration: 169/306, Loss: 0.11654854565858841\n",
      "Iteration: 170/306, Loss: 0.12381459772586823\n",
      "Iteration: 171/306, Loss: 0.1279982328414917\n",
      "Iteration: 172/306, Loss: 0.1521882563829422\n",
      "Iteration: 173/306, Loss: 0.17088840901851654\n",
      "Iteration: 174/306, Loss: 0.31262603402137756\n",
      "Iteration: 175/306, Loss: 0.3817363977432251\n",
      "Iteration: 176/306, Loss: 0.2941966652870178\n",
      "Iteration: 177/306, Loss: 0.2298295795917511\n",
      "Iteration: 178/306, Loss: 0.19141337275505066\n",
      "Iteration: 179/306, Loss: 0.3133701980113983\n",
      "Iteration: 180/306, Loss: 0.11696983128786087\n",
      "Iteration: 181/306, Loss: 0.505142331123352\n",
      "Iteration: 182/306, Loss: 0.1918221414089203\n",
      "Iteration: 183/306, Loss: 0.40871766209602356\n",
      "Iteration: 184/306, Loss: 0.295427531003952\n",
      "Iteration: 185/306, Loss: 0.10391345620155334\n",
      "Iteration: 186/306, Loss: 0.8334634304046631\n",
      "Iteration: 187/306, Loss: 0.1708708554506302\n",
      "Iteration: 188/306, Loss: 0.17404627799987793\n",
      "Iteration: 189/306, Loss: 0.1246723160147667\n",
      "Iteration: 190/306, Loss: 0.2865484356880188\n",
      "Iteration: 191/306, Loss: 0.1999494582414627\n",
      "Iteration: 192/306, Loss: 0.5806279182434082\n",
      "Iteration: 193/306, Loss: 0.30129116773605347\n",
      "Iteration: 194/306, Loss: 0.49482569098472595\n",
      "Iteration: 195/306, Loss: 0.05968337506055832\n",
      "Iteration: 196/306, Loss: 0.04925394803285599\n",
      "Iteration: 197/306, Loss: 0.23398315906524658\n",
      "Iteration: 198/306, Loss: 0.6373236179351807\n",
      "Iteration: 199/306, Loss: 0.5087641477584839\n",
      "Iteration: 200/306, Loss: 0.5953720808029175\n",
      "Iteration: 201/306, Loss: 0.41473498940467834\n",
      "Iteration: 202/306, Loss: 0.35513532161712646\n",
      "Iteration: 203/306, Loss: 0.5098568797111511\n",
      "Iteration: 204/306, Loss: 0.2772720754146576\n",
      "Iteration: 205/306, Loss: 0.050935663282871246\n",
      "Iteration: 206/306, Loss: 0.21997100114822388\n",
      "Iteration: 207/306, Loss: 0.2116212397813797\n",
      "Iteration: 208/306, Loss: 0.12156529724597931\n",
      "Iteration: 209/306, Loss: 0.6149125099182129\n",
      "Iteration: 210/306, Loss: 0.2988417446613312\n",
      "Iteration: 211/306, Loss: 0.6195816993713379\n",
      "Iteration: 212/306, Loss: 0.08183731138706207\n",
      "Iteration: 213/306, Loss: 0.21274110674858093\n",
      "Iteration: 214/306, Loss: 0.21015317738056183\n",
      "Iteration: 215/306, Loss: 0.23263730108737946\n",
      "Iteration: 216/306, Loss: 0.2610611915588379\n",
      "Iteration: 217/306, Loss: 0.5183562636375427\n",
      "Iteration: 218/306, Loss: 0.5028892755508423\n",
      "Iteration: 219/306, Loss: 0.32222267985343933\n",
      "Iteration: 220/306, Loss: 0.05808364599943161\n",
      "Iteration: 221/306, Loss: 0.13763126730918884\n",
      "Iteration: 222/306, Loss: 0.35849153995513916\n",
      "Iteration: 223/306, Loss: 0.7007406949996948\n",
      "Iteration: 224/306, Loss: 0.3727150559425354\n",
      "Iteration: 225/306, Loss: 0.3147125542163849\n",
      "Iteration: 226/306, Loss: 0.2892019748687744\n",
      "Iteration: 227/306, Loss: 0.887814998626709\n",
      "Iteration: 228/306, Loss: 0.15972356498241425\n",
      "Iteration: 229/306, Loss: 0.3916288912296295\n",
      "Iteration: 230/306, Loss: 0.17499469220638275\n",
      "Iteration: 231/306, Loss: 0.05378270521759987\n",
      "Iteration: 232/306, Loss: 0.07225699722766876\n",
      "Iteration: 233/306, Loss: 0.18032287061214447\n",
      "Iteration: 234/306, Loss: 0.15109361708164215\n",
      "Iteration: 235/306, Loss: 0.1464051753282547\n",
      "Iteration: 236/306, Loss: 0.43007245659828186\n",
      "Iteration: 237/306, Loss: 0.2318049967288971\n",
      "Iteration: 238/306, Loss: 0.024227820336818695\n",
      "Iteration: 239/306, Loss: 0.19818100333213806\n",
      "Iteration: 240/306, Loss: 0.22978925704956055\n",
      "Iteration: 241/306, Loss: 0.36327868700027466\n",
      "Iteration: 242/306, Loss: 0.18840235471725464\n",
      "Iteration: 243/306, Loss: 0.6368578672409058\n",
      "Iteration: 244/306, Loss: 0.18725401163101196\n",
      "Iteration: 245/306, Loss: 0.2711949348449707\n",
      "Iteration: 246/306, Loss: 0.5421032905578613\n",
      "Iteration: 247/306, Loss: 0.18201476335525513\n",
      "Iteration: 248/306, Loss: 0.3886507451534271\n",
      "Iteration: 249/306, Loss: 0.15293829143047333\n",
      "Iteration: 250/306, Loss: 0.19536422193050385\n",
      "Iteration: 251/306, Loss: 0.06710723787546158\n",
      "Iteration: 252/306, Loss: 0.05569734796881676\n",
      "Iteration: 253/306, Loss: 0.5914294123649597\n",
      "Iteration: 254/306, Loss: 0.2854074537754059\n",
      "Iteration: 255/306, Loss: 0.15281863510608673\n",
      "Iteration: 256/306, Loss: 0.31452494859695435\n",
      "Iteration: 257/306, Loss: 0.015875764191150665\n",
      "Iteration: 258/306, Loss: 0.3861085772514343\n",
      "Iteration: 259/306, Loss: 0.12437738478183746\n",
      "Iteration: 260/306, Loss: 0.40486621856689453\n",
      "Iteration: 261/306, Loss: 0.21047402918338776\n",
      "Iteration: 262/306, Loss: 0.4283486008644104\n",
      "Iteration: 263/306, Loss: 0.21291951835155487\n",
      "Iteration: 264/306, Loss: 0.35059717297554016\n",
      "Iteration: 265/306, Loss: 0.733967125415802\n",
      "Iteration: 266/306, Loss: 0.11607638746500015\n",
      "Iteration: 267/306, Loss: 0.7119300961494446\n",
      "Iteration: 268/306, Loss: 0.21466168761253357\n",
      "Iteration: 269/306, Loss: 0.5438039302825928\n",
      "Iteration: 270/306, Loss: 0.3033193349838257\n",
      "Iteration: 271/306, Loss: 0.40229207277297974\n",
      "Iteration: 272/306, Loss: 0.6579161882400513\n",
      "Iteration: 273/306, Loss: 0.4594768285751343\n",
      "Iteration: 274/306, Loss: 0.9948036670684814\n",
      "Iteration: 275/306, Loss: 0.30617326498031616\n",
      "Iteration: 276/306, Loss: 0.029999475926160812\n",
      "Iteration: 277/306, Loss: 1.1159337759017944\n",
      "Iteration: 278/306, Loss: 0.22771254181861877\n",
      "Iteration: 279/306, Loss: 0.16731181740760803\n",
      "Iteration: 280/306, Loss: 0.2120678573846817\n",
      "Iteration: 281/306, Loss: 0.2774094045162201\n",
      "Iteration: 282/306, Loss: 0.1798272579908371\n",
      "Iteration: 283/306, Loss: 0.2245834916830063\n",
      "Iteration: 284/306, Loss: 0.1849491000175476\n",
      "Iteration: 285/306, Loss: 0.05902320146560669\n",
      "Iteration: 286/306, Loss: 0.26439881324768066\n",
      "Iteration: 287/306, Loss: 0.3065212666988373\n",
      "Iteration: 288/306, Loss: 0.7926599979400635\n",
      "Iteration: 289/306, Loss: 0.12732744216918945\n",
      "Iteration: 290/306, Loss: 0.19988511502742767\n",
      "Iteration: 291/306, Loss: 0.2279699593782425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 292/306, Loss: 0.5659979581832886\n",
      "Iteration: 293/306, Loss: 0.5575452446937561\n",
      "Iteration: 294/306, Loss: 0.029997287318110466\n",
      "Iteration: 295/306, Loss: 0.1994875967502594\n",
      "Iteration: 296/306, Loss: 0.5560373067855835\n",
      "Iteration: 297/306, Loss: 0.3888455629348755\n",
      "Iteration: 298/306, Loss: 0.14321935176849365\n",
      "Iteration: 299/306, Loss: 0.40561968088150024\n",
      "Iteration: 300/306, Loss: 0.5894814729690552\n",
      "Iteration: 301/306, Loss: 0.28851714730262756\n",
      "Iteration: 302/306, Loss: 0.16182398796081543\n",
      "Iteration: 303/306, Loss: 0.23134969174861908\n",
      "Iteration: 304/306, Loss: 0.28917449712753296\n",
      "Iteration: 305/306, Loss: 0.3778698444366455\n",
      "Iteration: 306/306, Loss: 0.1439584493637085\n",
      "Epoch: 6/10\n",
      "Iteration: 1/306, Loss: 0.5292888283729553\n",
      "Iteration: 2/306, Loss: 0.32896801829338074\n",
      "Iteration: 3/306, Loss: 0.17160050570964813\n",
      "Iteration: 4/306, Loss: 0.19621321558952332\n",
      "Iteration: 5/306, Loss: 0.1328372210264206\n",
      "Iteration: 6/306, Loss: 0.4636375308036804\n",
      "Iteration: 7/306, Loss: 0.11374641954898834\n",
      "Iteration: 8/306, Loss: 0.3080653250217438\n",
      "Iteration: 9/306, Loss: 0.1296113282442093\n",
      "Iteration: 10/306, Loss: 0.2103603035211563\n",
      "Iteration: 11/306, Loss: 0.3683776259422302\n",
      "Iteration: 12/306, Loss: 0.06241654232144356\n",
      "Iteration: 13/306, Loss: 0.25081273913383484\n",
      "Iteration: 14/306, Loss: 0.471288800239563\n",
      "Iteration: 15/306, Loss: 0.3673289716243744\n",
      "Iteration: 16/306, Loss: 0.22009021043777466\n",
      "Iteration: 17/306, Loss: 0.1467055231332779\n",
      "Iteration: 18/306, Loss: 0.5129553079605103\n",
      "Iteration: 19/306, Loss: 0.2913217842578888\n",
      "Iteration: 20/306, Loss: 0.3795657455921173\n",
      "Iteration: 21/306, Loss: 0.21071679890155792\n",
      "Iteration: 22/306, Loss: 0.11888443678617477\n",
      "Iteration: 23/306, Loss: 0.0812789723277092\n",
      "Iteration: 24/306, Loss: 0.36517617106437683\n",
      "Iteration: 25/306, Loss: 0.21217431128025055\n",
      "Iteration: 26/306, Loss: 0.15065525472164154\n",
      "Iteration: 27/306, Loss: 0.03337785229086876\n",
      "Iteration: 28/306, Loss: 0.03039124794304371\n",
      "Iteration: 29/306, Loss: 0.14582420885562897\n",
      "Iteration: 30/306, Loss: 0.19170448184013367\n",
      "Iteration: 31/306, Loss: 0.0895489901304245\n",
      "Iteration: 32/306, Loss: 0.4842384457588196\n",
      "Iteration: 33/306, Loss: 0.48749738931655884\n",
      "Iteration: 34/306, Loss: 0.2864345908164978\n",
      "Iteration: 35/306, Loss: 0.11252880841493607\n",
      "Iteration: 36/306, Loss: 0.20476548373699188\n",
      "Iteration: 37/306, Loss: 0.754609227180481\n",
      "Iteration: 38/306, Loss: 0.33684399724006653\n",
      "Iteration: 39/306, Loss: 0.03558748960494995\n",
      "Iteration: 40/306, Loss: 0.24934697151184082\n",
      "Iteration: 41/306, Loss: 0.5637599229812622\n",
      "Iteration: 42/306, Loss: 0.10511287301778793\n",
      "Iteration: 43/306, Loss: 0.5167961716651917\n",
      "Iteration: 44/306, Loss: 0.4316701292991638\n",
      "Iteration: 45/306, Loss: 0.014658171683549881\n",
      "Iteration: 46/306, Loss: 0.4997654855251312\n",
      "Iteration: 47/306, Loss: 0.1870761662721634\n",
      "Iteration: 48/306, Loss: 0.15050242841243744\n",
      "Iteration: 49/306, Loss: 0.09045945852994919\n",
      "Iteration: 50/306, Loss: 0.3429582118988037\n",
      "Iteration: 51/306, Loss: 0.38677749037742615\n",
      "Iteration: 52/306, Loss: 0.21995380520820618\n",
      "Iteration: 53/306, Loss: 0.255828857421875\n",
      "Iteration: 54/306, Loss: 0.3118891716003418\n",
      "Iteration: 55/306, Loss: 0.22494588792324066\n",
      "Iteration: 56/306, Loss: 0.25787997245788574\n",
      "Iteration: 57/306, Loss: 0.2536512017250061\n",
      "Iteration: 58/306, Loss: 0.08817288279533386\n",
      "Iteration: 59/306, Loss: 0.17490699887275696\n",
      "Iteration: 60/306, Loss: 0.8225067257881165\n",
      "Iteration: 61/306, Loss: 0.22317281365394592\n",
      "Iteration: 62/306, Loss: 0.19435377418994904\n",
      "Iteration: 63/306, Loss: 0.6728037595748901\n",
      "Iteration: 64/306, Loss: 0.07053664326667786\n",
      "Iteration: 65/306, Loss: 0.1825007200241089\n",
      "Iteration: 66/306, Loss: 0.17812393605709076\n",
      "Iteration: 67/306, Loss: 0.22117269039154053\n",
      "Iteration: 68/306, Loss: 0.77961266040802\n",
      "Iteration: 69/306, Loss: 0.20283877849578857\n",
      "Iteration: 70/306, Loss: 0.19262081384658813\n",
      "Iteration: 71/306, Loss: 0.3989183306694031\n",
      "Iteration: 72/306, Loss: 0.1191539391875267\n",
      "Iteration: 73/306, Loss: 0.14080461859703064\n",
      "Iteration: 74/306, Loss: 0.2142958641052246\n",
      "Iteration: 75/306, Loss: 0.4016920030117035\n",
      "Iteration: 76/306, Loss: 0.0746854767203331\n",
      "Iteration: 77/306, Loss: 0.4580530822277069\n",
      "Iteration: 78/306, Loss: 0.3178936541080475\n",
      "Iteration: 79/306, Loss: 0.4412541389465332\n",
      "Iteration: 80/306, Loss: 0.27511054277420044\n",
      "Iteration: 81/306, Loss: 0.26986899971961975\n",
      "Iteration: 82/306, Loss: 0.6358266472816467\n",
      "Iteration: 83/306, Loss: 0.28147417306900024\n",
      "Iteration: 84/306, Loss: 0.6643497347831726\n",
      "Iteration: 85/306, Loss: 0.35617175698280334\n",
      "Iteration: 86/306, Loss: 0.5038395524024963\n",
      "Iteration: 87/306, Loss: 0.21448248624801636\n",
      "Iteration: 88/306, Loss: 0.486444354057312\n",
      "Iteration: 89/306, Loss: 0.1972511112689972\n",
      "Iteration: 90/306, Loss: 0.08423512428998947\n",
      "Iteration: 91/306, Loss: 0.22280260920524597\n",
      "Iteration: 92/306, Loss: 0.18053704500198364\n",
      "Iteration: 93/306, Loss: 0.25923556089401245\n",
      "Iteration: 94/306, Loss: 0.18914900720119476\n",
      "Iteration: 95/306, Loss: 0.09068100899457932\n",
      "Iteration: 96/306, Loss: 0.2633584141731262\n",
      "Iteration: 97/306, Loss: 0.18569745123386383\n",
      "Iteration: 98/306, Loss: 0.14592379331588745\n",
      "Iteration: 99/306, Loss: 1.0787146091461182\n",
      "Iteration: 100/306, Loss: 0.4997418224811554\n",
      "Iteration: 101/306, Loss: 0.22232015430927277\n",
      "Iteration: 102/306, Loss: 0.25954270362854004\n",
      "Iteration: 103/306, Loss: 0.34419873356819153\n",
      "Iteration: 104/306, Loss: 0.7994393706321716\n",
      "Iteration: 105/306, Loss: 0.20786155760288239\n",
      "Iteration: 106/306, Loss: 0.1346287578344345\n",
      "Iteration: 107/306, Loss: 0.5528072118759155\n",
      "Iteration: 108/306, Loss: 0.75126713514328\n",
      "Iteration: 109/306, Loss: 0.664816677570343\n",
      "Iteration: 110/306, Loss: 0.1597231775522232\n",
      "Iteration: 111/306, Loss: 0.2473556101322174\n",
      "Iteration: 112/306, Loss: 0.33323583006858826\n",
      "Iteration: 113/306, Loss: 0.26749739050865173\n",
      "Iteration: 114/306, Loss: 0.545535147190094\n",
      "Iteration: 115/306, Loss: 0.23118704557418823\n",
      "Iteration: 116/306, Loss: 0.3099380135536194\n",
      "Iteration: 117/306, Loss: 0.43611711263656616\n",
      "Iteration: 118/306, Loss: 0.16364271938800812\n",
      "Iteration: 119/306, Loss: 0.15392322838306427\n",
      "Iteration: 120/306, Loss: 0.257332444190979\n",
      "Iteration: 121/306, Loss: 0.2296706885099411\n",
      "Iteration: 122/306, Loss: 0.16682995855808258\n",
      "Iteration: 123/306, Loss: 0.18995627760887146\n",
      "Iteration: 124/306, Loss: 0.3009394705295563\n",
      "Iteration: 125/306, Loss: 0.21427057683467865\n",
      "Iteration: 126/306, Loss: 0.18024303019046783\n",
      "Iteration: 127/306, Loss: 0.21156592667102814\n",
      "Iteration: 128/306, Loss: 0.20323137938976288\n",
      "Iteration: 129/306, Loss: 0.28093206882476807\n",
      "Iteration: 130/306, Loss: 0.39283040165901184\n",
      "Iteration: 131/306, Loss: 0.619011402130127\n",
      "Iteration: 132/306, Loss: 0.17512622475624084\n",
      "Iteration: 133/306, Loss: 0.3544383943080902\n",
      "Iteration: 134/306, Loss: 0.19055327773094177\n",
      "Iteration: 135/306, Loss: 0.7110052108764648\n",
      "Iteration: 136/306, Loss: 0.28011929988861084\n",
      "Iteration: 137/306, Loss: 0.40283674001693726\n",
      "Iteration: 138/306, Loss: 0.8354586958885193\n",
      "Iteration: 139/306, Loss: 0.24383944272994995\n",
      "Iteration: 140/306, Loss: 0.4892676770687103\n",
      "Iteration: 141/306, Loss: 0.052766017615795135\n",
      "Iteration: 142/306, Loss: 0.516319751739502\n",
      "Iteration: 143/306, Loss: 0.14121326804161072\n",
      "Iteration: 144/306, Loss: 0.18354274332523346\n",
      "Iteration: 145/306, Loss: 0.4820883572101593\n",
      "Iteration: 146/306, Loss: 1.0939521789550781\n",
      "Iteration: 147/306, Loss: 0.17285043001174927\n",
      "Iteration: 148/306, Loss: 0.3134605288505554\n",
      "Iteration: 149/306, Loss: 0.550159752368927\n",
      "Iteration: 150/306, Loss: 0.038462668657302856\n",
      "Iteration: 151/306, Loss: 0.49311572313308716\n",
      "Iteration: 152/306, Loss: 0.18436843156814575\n",
      "Iteration: 153/306, Loss: 0.23201529681682587\n",
      "Iteration: 154/306, Loss: 0.13370704650878906\n",
      "Iteration: 155/306, Loss: 0.05198226869106293\n",
      "Iteration: 156/306, Loss: 0.07712600380182266\n",
      "Iteration: 157/306, Loss: 0.2021448016166687\n",
      "Iteration: 158/306, Loss: 0.8549394607543945\n",
      "Iteration: 159/306, Loss: 1.2454503774642944\n",
      "Iteration: 160/306, Loss: 0.1328723430633545\n",
      "Iteration: 161/306, Loss: 0.23724263906478882\n",
      "Iteration: 162/306, Loss: 0.2557932734489441\n",
      "Iteration: 163/306, Loss: 0.1302720159292221\n",
      "Iteration: 164/306, Loss: 0.44605886936187744\n",
      "Iteration: 165/306, Loss: 0.5726832151412964\n",
      "Iteration: 166/306, Loss: 0.21875223517417908\n",
      "Iteration: 167/306, Loss: 0.5344423055648804\n",
      "Iteration: 168/306, Loss: 0.35118788480758667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 169/306, Loss: 0.08253372460603714\n",
      "Iteration: 170/306, Loss: 0.14907556772232056\n",
      "Iteration: 171/306, Loss: 0.3283199667930603\n",
      "Iteration: 172/306, Loss: 0.2069026529788971\n",
      "Iteration: 173/306, Loss: 0.35091036558151245\n",
      "Iteration: 174/306, Loss: 0.6263079643249512\n",
      "Iteration: 175/306, Loss: 0.4029114544391632\n",
      "Iteration: 176/306, Loss: 0.2531198561191559\n",
      "Iteration: 177/306, Loss: 0.18555352091789246\n",
      "Iteration: 178/306, Loss: 0.18852877616882324\n",
      "Iteration: 179/306, Loss: 0.3889455795288086\n",
      "Iteration: 180/306, Loss: 0.1918405443429947\n",
      "Iteration: 181/306, Loss: 0.1706710159778595\n",
      "Iteration: 182/306, Loss: 0.020644227042794228\n",
      "Iteration: 183/306, Loss: 0.5278831124305725\n",
      "Iteration: 184/306, Loss: 1.0496273040771484\n",
      "Iteration: 185/306, Loss: 0.8301814198493958\n",
      "Iteration: 186/306, Loss: 0.13949474692344666\n",
      "Iteration: 187/306, Loss: 0.2317393720149994\n",
      "Iteration: 188/306, Loss: 0.6678621768951416\n",
      "Iteration: 189/306, Loss: 0.3993018567562103\n",
      "Iteration: 190/306, Loss: 0.18542522192001343\n",
      "Iteration: 191/306, Loss: 0.28030019998550415\n",
      "Iteration: 192/306, Loss: 0.17681388556957245\n",
      "Iteration: 193/306, Loss: 0.13421466946601868\n",
      "Iteration: 194/306, Loss: 0.2518622577190399\n",
      "Iteration: 195/306, Loss: 0.6274479627609253\n",
      "Iteration: 196/306, Loss: 0.2146274298429489\n",
      "Iteration: 197/306, Loss: 0.05765751004219055\n",
      "Iteration: 198/306, Loss: 0.18065179884433746\n",
      "Iteration: 199/306, Loss: 0.3671818971633911\n",
      "Iteration: 200/306, Loss: 0.05002851039171219\n",
      "Iteration: 201/306, Loss: 0.7432533502578735\n",
      "Iteration: 202/306, Loss: 0.159135103225708\n",
      "Iteration: 203/306, Loss: 0.0620681494474411\n",
      "Iteration: 204/306, Loss: 0.373015820980072\n",
      "Iteration: 205/306, Loss: 0.04569004848599434\n",
      "Iteration: 206/306, Loss: 0.5667206048965454\n",
      "Iteration: 207/306, Loss: 0.6407520771026611\n",
      "Iteration: 208/306, Loss: 0.2727203369140625\n",
      "Iteration: 209/306, Loss: 0.10804086923599243\n",
      "Iteration: 210/306, Loss: 0.11274904012680054\n",
      "Iteration: 211/306, Loss: 0.1613018810749054\n",
      "Iteration: 212/306, Loss: 0.6490576863288879\n",
      "Iteration: 213/306, Loss: 0.37955737113952637\n",
      "Iteration: 214/306, Loss: 0.15191121399402618\n",
      "Iteration: 215/306, Loss: 0.20018252730369568\n",
      "Iteration: 216/306, Loss: 0.07422589510679245\n",
      "Iteration: 217/306, Loss: 0.45368579030036926\n",
      "Iteration: 218/306, Loss: 0.39505892992019653\n",
      "Iteration: 219/306, Loss: 0.15851275622844696\n",
      "Iteration: 220/306, Loss: 0.5353831648826599\n",
      "Iteration: 221/306, Loss: 0.13431675732135773\n",
      "Iteration: 222/306, Loss: 0.30301690101623535\n",
      "Iteration: 223/306, Loss: 0.2281552255153656\n",
      "Iteration: 224/306, Loss: 0.43117576837539673\n",
      "Iteration: 225/306, Loss: 0.30296990275382996\n",
      "Iteration: 226/306, Loss: 0.22811192274093628\n",
      "Iteration: 227/306, Loss: 0.251543253660202\n",
      "Iteration: 228/306, Loss: 0.16588453948497772\n",
      "Iteration: 229/306, Loss: 0.7916109561920166\n",
      "Iteration: 230/306, Loss: 0.19598791003227234\n",
      "Iteration: 231/306, Loss: 0.3582160770893097\n",
      "Iteration: 232/306, Loss: 0.49218565225601196\n",
      "Iteration: 233/306, Loss: 0.5570493340492249\n",
      "Iteration: 234/306, Loss: 0.5705859661102295\n",
      "Iteration: 235/306, Loss: 0.2627948224544525\n",
      "Iteration: 236/306, Loss: 0.1401304453611374\n",
      "Iteration: 237/306, Loss: 0.04351140558719635\n",
      "Iteration: 238/306, Loss: 0.18026287853717804\n",
      "Iteration: 239/306, Loss: 0.1078488677740097\n",
      "Iteration: 240/306, Loss: 0.4571671485900879\n",
      "Iteration: 241/306, Loss: 0.16850103437900543\n",
      "Iteration: 242/306, Loss: 0.24208524823188782\n",
      "Iteration: 243/306, Loss: 0.21103928983211517\n",
      "Iteration: 244/306, Loss: 0.1784779131412506\n",
      "Iteration: 245/306, Loss: 0.5157557129859924\n",
      "Iteration: 246/306, Loss: 0.29075682163238525\n",
      "Iteration: 247/306, Loss: 0.22827206552028656\n",
      "Iteration: 248/306, Loss: 0.36989641189575195\n",
      "Iteration: 249/306, Loss: 0.2632344365119934\n",
      "Iteration: 250/306, Loss: 0.5818543434143066\n",
      "Iteration: 251/306, Loss: 0.21825623512268066\n",
      "Iteration: 252/306, Loss: 1.014320969581604\n",
      "Iteration: 253/306, Loss: 0.4934353828430176\n",
      "Iteration: 254/306, Loss: 0.13458868861198425\n",
      "Iteration: 255/306, Loss: 0.107142373919487\n",
      "Iteration: 256/306, Loss: 0.24998147785663605\n",
      "Iteration: 257/306, Loss: 0.4087500274181366\n",
      "Iteration: 258/306, Loss: 0.2794768512248993\n",
      "Iteration: 259/306, Loss: 0.807610809803009\n",
      "Iteration: 260/306, Loss: 0.28255924582481384\n",
      "Iteration: 261/306, Loss: 0.13970112800598145\n",
      "Iteration: 262/306, Loss: 0.5614875555038452\n",
      "Iteration: 263/306, Loss: 0.06264408677816391\n",
      "Iteration: 264/306, Loss: 0.31638118624687195\n",
      "Iteration: 265/306, Loss: 0.20684200525283813\n",
      "Iteration: 266/306, Loss: 0.062328409403562546\n",
      "Iteration: 267/306, Loss: 0.1168438270688057\n",
      "Iteration: 268/306, Loss: 0.22729283571243286\n",
      "Iteration: 269/306, Loss: 0.4324752390384674\n",
      "Iteration: 270/306, Loss: 0.3464241623878479\n",
      "Iteration: 271/306, Loss: 0.2808063328266144\n",
      "Iteration: 272/306, Loss: 0.7044861912727356\n",
      "Iteration: 273/306, Loss: 0.2502038776874542\n",
      "Iteration: 274/306, Loss: 0.23820652067661285\n",
      "Iteration: 275/306, Loss: 0.38642704486846924\n",
      "Iteration: 276/306, Loss: 0.238451287150383\n",
      "Iteration: 277/306, Loss: 0.2744745910167694\n",
      "Iteration: 278/306, Loss: 0.05373546853661537\n",
      "Iteration: 279/306, Loss: 0.21671563386917114\n",
      "Iteration: 280/306, Loss: 0.5330360531806946\n",
      "Iteration: 281/306, Loss: 0.2900056838989258\n",
      "Iteration: 282/306, Loss: 0.1838618367910385\n",
      "Iteration: 283/306, Loss: 1.040952205657959\n",
      "Iteration: 284/306, Loss: 0.11920798569917679\n",
      "Iteration: 285/306, Loss: 0.3819860816001892\n",
      "Iteration: 286/306, Loss: 0.1576501429080963\n",
      "Iteration: 287/306, Loss: 0.43293023109436035\n",
      "Iteration: 288/306, Loss: 0.2698209285736084\n",
      "Iteration: 289/306, Loss: 0.17924991250038147\n",
      "Iteration: 290/306, Loss: 0.19879509508609772\n",
      "Iteration: 291/306, Loss: 0.5775542855262756\n",
      "Iteration: 292/306, Loss: 0.5925328135490417\n",
      "Iteration: 293/306, Loss: 0.8391595482826233\n",
      "Iteration: 294/306, Loss: 0.18857547640800476\n",
      "Iteration: 295/306, Loss: 0.26759427785873413\n",
      "Iteration: 296/306, Loss: 0.47600045800209045\n",
      "Iteration: 297/306, Loss: 0.08830057829618454\n",
      "Iteration: 298/306, Loss: 0.2380676418542862\n",
      "Iteration: 299/306, Loss: 0.13643419742584229\n",
      "Iteration: 300/306, Loss: 0.2538004517555237\n",
      "Iteration: 301/306, Loss: 0.3675227761268616\n",
      "Iteration: 302/306, Loss: 0.15085217356681824\n",
      "Iteration: 303/306, Loss: 0.16025884449481964\n",
      "Iteration: 304/306, Loss: 0.21133598685264587\n",
      "Iteration: 305/306, Loss: 0.13866496086120605\n",
      "Iteration: 306/306, Loss: 1.0898786783218384\n",
      "Epoch: 7/10\n",
      "Iteration: 1/306, Loss: 0.27928146719932556\n",
      "Iteration: 2/306, Loss: 0.20249347388744354\n",
      "Iteration: 3/306, Loss: 0.12625131011009216\n",
      "Iteration: 4/306, Loss: 0.10884079337120056\n",
      "Iteration: 5/306, Loss: 0.3517116606235504\n",
      "Iteration: 6/306, Loss: 0.4191136658191681\n",
      "Iteration: 7/306, Loss: 0.040469951927661896\n",
      "Iteration: 8/306, Loss: 0.1431812345981598\n",
      "Iteration: 9/306, Loss: 0.3314158022403717\n",
      "Iteration: 10/306, Loss: 0.17664813995361328\n",
      "Iteration: 11/306, Loss: 0.8637125492095947\n",
      "Iteration: 12/306, Loss: 0.23066549003124237\n",
      "Iteration: 13/306, Loss: 0.25084444880485535\n",
      "Iteration: 14/306, Loss: 0.21668754518032074\n",
      "Iteration: 15/306, Loss: 0.43307560682296753\n",
      "Iteration: 16/306, Loss: 0.2834537625312805\n",
      "Iteration: 17/306, Loss: 0.5146626234054565\n",
      "Iteration: 18/306, Loss: 0.1866171509027481\n",
      "Iteration: 19/306, Loss: 0.13995349407196045\n",
      "Iteration: 20/306, Loss: 0.4360460042953491\n",
      "Iteration: 21/306, Loss: 0.23005791008472443\n",
      "Iteration: 22/306, Loss: 0.2950853407382965\n",
      "Iteration: 23/306, Loss: 0.20909957587718964\n",
      "Iteration: 24/306, Loss: 0.15831948816776276\n",
      "Iteration: 25/306, Loss: 0.16698190569877625\n",
      "Iteration: 26/306, Loss: 0.41028398275375366\n",
      "Iteration: 27/306, Loss: 0.5803563594818115\n",
      "Iteration: 28/306, Loss: 0.22684131562709808\n",
      "Iteration: 29/306, Loss: 0.2147551029920578\n",
      "Iteration: 30/306, Loss: 0.031885694712400436\n",
      "Iteration: 31/306, Loss: 0.5125181078910828\n",
      "Iteration: 32/306, Loss: 0.1396171599626541\n",
      "Iteration: 33/306, Loss: 0.1438242793083191\n",
      "Iteration: 34/306, Loss: 0.24894565343856812\n",
      "Iteration: 35/306, Loss: 0.26915910840034485\n",
      "Iteration: 36/306, Loss: 0.06480345875024796\n",
      "Iteration: 37/306, Loss: 0.2878503203392029\n",
      "Iteration: 38/306, Loss: 0.07554810494184494\n",
      "Iteration: 39/306, Loss: 0.24008820950984955\n",
      "Iteration: 40/306, Loss: 0.3009399473667145\n",
      "Iteration: 41/306, Loss: 0.24470089375972748\n",
      "Iteration: 42/306, Loss: 0.9732468128204346\n",
      "Iteration: 43/306, Loss: 0.19396962225437164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 44/306, Loss: 0.44384562969207764\n",
      "Iteration: 45/306, Loss: 0.20793378353118896\n",
      "Iteration: 46/306, Loss: 0.1405142843723297\n",
      "Iteration: 47/306, Loss: 0.24411319196224213\n",
      "Iteration: 48/306, Loss: 0.3842361271381378\n",
      "Iteration: 49/306, Loss: 0.07079295814037323\n",
      "Iteration: 50/306, Loss: 0.07486997544765472\n",
      "Iteration: 51/306, Loss: 0.47614067792892456\n",
      "Iteration: 52/306, Loss: 0.3623424172401428\n",
      "Iteration: 53/306, Loss: 0.9985923171043396\n",
      "Iteration: 54/306, Loss: 0.052922360599040985\n",
      "Iteration: 55/306, Loss: 0.08527572453022003\n",
      "Iteration: 56/306, Loss: 0.15755164623260498\n",
      "Iteration: 57/306, Loss: 0.12749643623828888\n",
      "Iteration: 58/306, Loss: 0.0950857549905777\n",
      "Iteration: 59/306, Loss: 0.4631500244140625\n",
      "Iteration: 60/306, Loss: 0.3670231103897095\n",
      "Iteration: 61/306, Loss: 0.3475513458251953\n",
      "Iteration: 62/306, Loss: 0.04874785989522934\n",
      "Iteration: 63/306, Loss: 0.07519909739494324\n",
      "Iteration: 64/306, Loss: 0.24172689020633698\n",
      "Iteration: 65/306, Loss: 0.11947055160999298\n",
      "Iteration: 66/306, Loss: 0.5299612283706665\n",
      "Iteration: 67/306, Loss: 0.30602550506591797\n",
      "Iteration: 68/306, Loss: 0.06667085736989975\n",
      "Iteration: 69/306, Loss: 0.20475520193576813\n",
      "Iteration: 70/306, Loss: 0.5524558424949646\n",
      "Iteration: 71/306, Loss: 0.5390864610671997\n",
      "Iteration: 72/306, Loss: 0.2439732551574707\n",
      "Iteration: 73/306, Loss: 0.30226829648017883\n",
      "Iteration: 74/306, Loss: 0.611944317817688\n",
      "Iteration: 75/306, Loss: 0.28408247232437134\n",
      "Iteration: 76/306, Loss: 0.2232702225446701\n",
      "Iteration: 77/306, Loss: 0.24577142298221588\n",
      "Iteration: 78/306, Loss: 0.7913141250610352\n",
      "Iteration: 79/306, Loss: 0.7898103594779968\n",
      "Iteration: 80/306, Loss: 0.19097423553466797\n",
      "Iteration: 81/306, Loss: 0.0916820764541626\n",
      "Iteration: 82/306, Loss: 0.5883267521858215\n",
      "Iteration: 83/306, Loss: 0.29463186860084534\n",
      "Iteration: 84/306, Loss: 0.26217201352119446\n",
      "Iteration: 85/306, Loss: 1.2396217584609985\n",
      "Iteration: 86/306, Loss: 0.4538024067878723\n",
      "Iteration: 87/306, Loss: 0.27381452918052673\n",
      "Iteration: 88/306, Loss: 0.6594939231872559\n",
      "Iteration: 89/306, Loss: 0.59635329246521\n",
      "Iteration: 90/306, Loss: 0.28223857283592224\n",
      "Iteration: 91/306, Loss: 0.4913043975830078\n",
      "Iteration: 92/306, Loss: 0.02049543336033821\n",
      "Iteration: 93/306, Loss: 0.1490958333015442\n",
      "Iteration: 94/306, Loss: 0.11441943794488907\n",
      "Iteration: 95/306, Loss: 0.4035097062587738\n",
      "Iteration: 96/306, Loss: 1.161123514175415\n",
      "Iteration: 97/306, Loss: 0.3372800648212433\n",
      "Iteration: 98/306, Loss: 0.48649752140045166\n",
      "Iteration: 99/306, Loss: 0.20189505815505981\n",
      "Iteration: 100/306, Loss: 0.383834570646286\n",
      "Iteration: 101/306, Loss: 0.43357592821121216\n",
      "Iteration: 102/306, Loss: 0.1262316256761551\n",
      "Iteration: 103/306, Loss: 0.32270798087120056\n",
      "Iteration: 104/306, Loss: 0.17427358031272888\n",
      "Iteration: 105/306, Loss: 0.17124754190444946\n",
      "Iteration: 106/306, Loss: 0.5166196227073669\n",
      "Iteration: 107/306, Loss: 0.1164063811302185\n",
      "Iteration: 108/306, Loss: 0.22421365976333618\n",
      "Iteration: 109/306, Loss: 0.2479485124349594\n",
      "Iteration: 110/306, Loss: 0.21259237825870514\n",
      "Iteration: 111/306, Loss: 0.2789149582386017\n",
      "Iteration: 112/306, Loss: 0.3393053114414215\n",
      "Iteration: 113/306, Loss: 0.06143471598625183\n",
      "Iteration: 114/306, Loss: 0.377671480178833\n",
      "Iteration: 115/306, Loss: 0.5925822257995605\n",
      "Iteration: 116/306, Loss: 0.02740505151450634\n",
      "Iteration: 117/306, Loss: 0.24258628487586975\n",
      "Iteration: 118/306, Loss: 0.5534105896949768\n",
      "Iteration: 119/306, Loss: 0.6789319515228271\n",
      "Iteration: 120/306, Loss: 0.1643158346414566\n",
      "Iteration: 121/306, Loss: 0.3077225983142853\n",
      "Iteration: 122/306, Loss: 0.3935173749923706\n",
      "Iteration: 123/306, Loss: 0.5606688261032104\n",
      "Iteration: 124/306, Loss: 0.2523808479309082\n",
      "Iteration: 125/306, Loss: 0.49605780839920044\n",
      "Iteration: 126/306, Loss: 0.5439721941947937\n",
      "Iteration: 127/306, Loss: 0.35150814056396484\n",
      "Iteration: 128/306, Loss: 0.9510926008224487\n",
      "Iteration: 129/306, Loss: 0.22785811126232147\n",
      "Iteration: 130/306, Loss: 0.29558777809143066\n",
      "Iteration: 131/306, Loss: 0.8046863675117493\n",
      "Iteration: 132/306, Loss: 0.3648439943790436\n",
      "Iteration: 133/306, Loss: 0.5402616262435913\n",
      "Iteration: 134/306, Loss: 0.1742262989282608\n",
      "Iteration: 135/306, Loss: 0.1197502613067627\n",
      "Iteration: 136/306, Loss: 0.037777651101350784\n",
      "Iteration: 137/306, Loss: 0.5175648927688599\n",
      "Iteration: 138/306, Loss: 0.5567468404769897\n",
      "Iteration: 139/306, Loss: 0.22613710165023804\n",
      "Iteration: 140/306, Loss: 0.7268990278244019\n",
      "Iteration: 141/306, Loss: 0.3668644428253174\n",
      "Iteration: 142/306, Loss: 0.45630595088005066\n",
      "Iteration: 143/306, Loss: 0.19729934632778168\n",
      "Iteration: 144/306, Loss: 0.1398758590221405\n",
      "Iteration: 145/306, Loss: 0.33032727241516113\n",
      "Iteration: 146/306, Loss: 0.25864821672439575\n",
      "Iteration: 147/306, Loss: 0.3196496367454529\n",
      "Iteration: 148/306, Loss: 0.2798254191875458\n",
      "Iteration: 149/306, Loss: 0.24447064101696014\n",
      "Iteration: 150/306, Loss: 0.20317742228507996\n",
      "Iteration: 151/306, Loss: 0.21406956017017365\n",
      "Iteration: 152/306, Loss: 0.28236663341522217\n",
      "Iteration: 153/306, Loss: 0.19942770898342133\n",
      "Iteration: 154/306, Loss: 0.6168541312217712\n",
      "Iteration: 155/306, Loss: 0.17888009548187256\n",
      "Iteration: 156/306, Loss: 0.40987682342529297\n",
      "Iteration: 157/306, Loss: 0.12747688591480255\n",
      "Iteration: 158/306, Loss: 0.4731748402118683\n",
      "Iteration: 159/306, Loss: 0.18464162945747375\n",
      "Iteration: 160/306, Loss: 0.21208582818508148\n",
      "Iteration: 161/306, Loss: 0.2694670259952545\n",
      "Iteration: 162/306, Loss: 0.3930571675300598\n",
      "Iteration: 163/306, Loss: 0.8350449800491333\n",
      "Iteration: 164/306, Loss: 0.10155532509088516\n",
      "Iteration: 165/306, Loss: 1.0717896223068237\n",
      "Iteration: 166/306, Loss: 0.4187074303627014\n",
      "Iteration: 167/306, Loss: 1.1035873889923096\n",
      "Iteration: 168/306, Loss: 0.12783282995224\n",
      "Iteration: 169/306, Loss: 0.4012318551540375\n",
      "Iteration: 170/306, Loss: 0.21798735857009888\n",
      "Iteration: 171/306, Loss: 0.42351818084716797\n",
      "Iteration: 172/306, Loss: 0.2887328565120697\n",
      "Iteration: 173/306, Loss: 0.209228053689003\n",
      "Iteration: 174/306, Loss: 0.46698111295700073\n",
      "Iteration: 175/306, Loss: 0.39584362506866455\n",
      "Iteration: 176/306, Loss: 0.17939487099647522\n",
      "Iteration: 177/306, Loss: 0.4733094871044159\n",
      "Iteration: 178/306, Loss: 0.5522799491882324\n",
      "Iteration: 179/306, Loss: 0.33589595556259155\n",
      "Iteration: 180/306, Loss: 0.3429754078388214\n",
      "Iteration: 181/306, Loss: 0.4869410991668701\n",
      "Iteration: 182/306, Loss: 0.20346246659755707\n",
      "Iteration: 183/306, Loss: 0.08495312929153442\n",
      "Iteration: 184/306, Loss: 0.15698827803134918\n",
      "Iteration: 185/306, Loss: 0.17821799218654633\n",
      "Iteration: 186/306, Loss: 0.2997768819332123\n",
      "Iteration: 187/306, Loss: 0.5647328495979309\n",
      "Iteration: 188/306, Loss: 0.2674527168273926\n",
      "Iteration: 189/306, Loss: 0.1693652868270874\n",
      "Iteration: 190/306, Loss: 0.4323893189430237\n",
      "Iteration: 191/306, Loss: 0.16126038134098053\n",
      "Iteration: 192/306, Loss: 0.16446177661418915\n",
      "Iteration: 193/306, Loss: 0.49483078718185425\n",
      "Iteration: 194/306, Loss: 0.20038510859012604\n",
      "Iteration: 195/306, Loss: 0.1729762703180313\n",
      "Iteration: 196/306, Loss: 0.3482586443424225\n",
      "Iteration: 197/306, Loss: 0.1324537843465805\n",
      "Iteration: 198/306, Loss: 0.26087072491645813\n",
      "Iteration: 199/306, Loss: 0.515167772769928\n",
      "Iteration: 200/306, Loss: 0.4954380989074707\n",
      "Iteration: 201/306, Loss: 0.6221129298210144\n",
      "Iteration: 202/306, Loss: 0.2695004343986511\n",
      "Iteration: 203/306, Loss: 0.48870348930358887\n",
      "Iteration: 204/306, Loss: 0.7499226331710815\n",
      "Iteration: 205/306, Loss: 0.3554079830646515\n",
      "Iteration: 206/306, Loss: 0.5617337226867676\n",
      "Iteration: 207/306, Loss: 0.3093922436237335\n",
      "Iteration: 208/306, Loss: 0.2270183265209198\n",
      "Iteration: 209/306, Loss: 0.16558104753494263\n",
      "Iteration: 210/306, Loss: 0.1651739776134491\n",
      "Iteration: 211/306, Loss: 0.09098327159881592\n",
      "Iteration: 212/306, Loss: 0.13869091868400574\n",
      "Iteration: 213/306, Loss: 0.1806168556213379\n",
      "Iteration: 214/306, Loss: 0.4479821026325226\n",
      "Iteration: 215/306, Loss: 0.3565561771392822\n",
      "Iteration: 216/306, Loss: 0.16495247185230255\n",
      "Iteration: 217/306, Loss: 0.29126349091529846\n",
      "Iteration: 218/306, Loss: 0.6396344304084778\n",
      "Iteration: 219/306, Loss: 0.2791309356689453\n",
      "Iteration: 220/306, Loss: 0.23144546151161194\n",
      "Iteration: 221/306, Loss: 0.23460106551647186\n",
      "Iteration: 222/306, Loss: 0.297461599111557\n",
      "Iteration: 223/306, Loss: 0.217555969953537\n",
      "Iteration: 224/306, Loss: 0.3176569938659668\n",
      "Iteration: 225/306, Loss: 0.09232057631015778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 226/306, Loss: 0.6303039789199829\n",
      "Iteration: 227/306, Loss: 0.266403466463089\n",
      "Iteration: 228/306, Loss: 0.8777534365653992\n",
      "Iteration: 229/306, Loss: 0.2829878628253937\n",
      "Iteration: 230/306, Loss: 0.3968963027000427\n",
      "Iteration: 231/306, Loss: 0.5838194489479065\n",
      "Iteration: 232/306, Loss: 0.28906527161598206\n",
      "Iteration: 233/306, Loss: 0.22038839757442474\n",
      "Iteration: 234/306, Loss: 0.19461725652217865\n",
      "Iteration: 235/306, Loss: 0.30312979221343994\n",
      "Iteration: 236/306, Loss: 1.0023245811462402\n",
      "Iteration: 237/306, Loss: 0.5923013687133789\n",
      "Iteration: 238/306, Loss: 0.18481867015361786\n",
      "Iteration: 239/306, Loss: 0.17394402623176575\n",
      "Iteration: 240/306, Loss: 0.16355064511299133\n",
      "Iteration: 241/306, Loss: 0.19788791239261627\n",
      "Iteration: 242/306, Loss: 0.341844767332077\n",
      "Iteration: 243/306, Loss: 0.23039934039115906\n",
      "Iteration: 244/306, Loss: 0.2798570394515991\n",
      "Iteration: 245/306, Loss: 0.1343916803598404\n",
      "Iteration: 246/306, Loss: 0.012730647809803486\n",
      "Iteration: 247/306, Loss: 0.0564860962331295\n",
      "Iteration: 248/306, Loss: 0.22231607139110565\n",
      "Iteration: 249/306, Loss: 0.479018896818161\n",
      "Iteration: 250/306, Loss: 0.5235505700111389\n",
      "Iteration: 251/306, Loss: 0.096388079226017\n",
      "Iteration: 252/306, Loss: 0.2679453492164612\n",
      "Iteration: 253/306, Loss: 0.1926717460155487\n",
      "Iteration: 254/306, Loss: 0.3606208562850952\n",
      "Iteration: 255/306, Loss: 0.21013149619102478\n",
      "Iteration: 256/306, Loss: 0.1002531349658966\n",
      "Iteration: 257/306, Loss: 0.14884383976459503\n",
      "Iteration: 258/306, Loss: 0.6555867791175842\n",
      "Iteration: 259/306, Loss: 0.44537416100502014\n",
      "Iteration: 260/306, Loss: 0.24000881612300873\n",
      "Iteration: 261/306, Loss: 0.3910132348537445\n",
      "Iteration: 262/306, Loss: 0.4265603721141815\n",
      "Iteration: 263/306, Loss: 0.2405211180448532\n",
      "Iteration: 264/306, Loss: 0.3976699709892273\n",
      "Iteration: 265/306, Loss: 0.39733585715293884\n",
      "Iteration: 266/306, Loss: 0.1838739663362503\n",
      "Iteration: 267/306, Loss: 0.1958240121603012\n",
      "Iteration: 268/306, Loss: 0.07129555195569992\n",
      "Iteration: 269/306, Loss: 0.13983961939811707\n",
      "Iteration: 270/306, Loss: 0.3758513629436493\n",
      "Iteration: 271/306, Loss: 0.23811407387256622\n",
      "Iteration: 272/306, Loss: 0.27612587809562683\n",
      "Iteration: 273/306, Loss: 0.06222568079829216\n",
      "Iteration: 274/306, Loss: 0.07968791574239731\n",
      "Iteration: 275/306, Loss: 0.43508750200271606\n",
      "Iteration: 276/306, Loss: 0.28139349818229675\n",
      "Iteration: 277/306, Loss: 0.20172250270843506\n",
      "Iteration: 278/306, Loss: 0.29280754923820496\n",
      "Iteration: 279/306, Loss: 0.9634196758270264\n",
      "Iteration: 280/306, Loss: 0.16123823821544647\n",
      "Iteration: 281/306, Loss: 0.29211926460266113\n",
      "Iteration: 282/306, Loss: 0.19184072315692902\n",
      "Iteration: 283/306, Loss: 0.2598666250705719\n",
      "Iteration: 284/306, Loss: 0.35111063718795776\n",
      "Iteration: 285/306, Loss: 0.1514142006635666\n",
      "Iteration: 286/306, Loss: 0.07887015491724014\n",
      "Iteration: 287/306, Loss: 0.20400077104568481\n",
      "Iteration: 288/306, Loss: 0.2164885401725769\n",
      "Iteration: 289/306, Loss: 0.39387232065200806\n",
      "Iteration: 290/306, Loss: 0.42384397983551025\n",
      "Iteration: 291/306, Loss: 0.1467473953962326\n",
      "Iteration: 292/306, Loss: 0.14606162905693054\n",
      "Iteration: 293/306, Loss: 0.08540346473455429\n",
      "Iteration: 294/306, Loss: 0.8455445766448975\n",
      "Iteration: 295/306, Loss: 0.13241930305957794\n",
      "Iteration: 296/306, Loss: 0.1663951873779297\n",
      "Iteration: 297/306, Loss: 0.3383907079696655\n",
      "Iteration: 298/306, Loss: 0.6615929007530212\n",
      "Iteration: 299/306, Loss: 0.2576172649860382\n",
      "Iteration: 300/306, Loss: 0.04866765812039375\n",
      "Iteration: 301/306, Loss: 0.190462127327919\n",
      "Iteration: 302/306, Loss: 0.03551754727959633\n",
      "Iteration: 303/306, Loss: 0.1123628094792366\n",
      "Iteration: 304/306, Loss: 0.39418676495552063\n",
      "Iteration: 305/306, Loss: 0.22048377990722656\n",
      "Iteration: 306/306, Loss: 0.611443042755127\n",
      "Epoch: 8/10\n",
      "Iteration: 1/306, Loss: 0.19505947828292847\n",
      "Iteration: 2/306, Loss: 0.24808244407176971\n",
      "Iteration: 3/306, Loss: 0.6436829566955566\n",
      "Iteration: 4/306, Loss: 0.21952292323112488\n",
      "Iteration: 5/306, Loss: 0.3255463242530823\n",
      "Iteration: 6/306, Loss: 0.15366366505622864\n",
      "Iteration: 7/306, Loss: 0.1595943123102188\n",
      "Iteration: 8/306, Loss: 0.1694660633802414\n",
      "Iteration: 9/306, Loss: 0.20607949793338776\n",
      "Iteration: 10/306, Loss: 0.2996974289417267\n",
      "Iteration: 11/306, Loss: 0.0899890884757042\n",
      "Iteration: 12/306, Loss: 0.26936835050582886\n",
      "Iteration: 13/306, Loss: 0.3838924467563629\n",
      "Iteration: 14/306, Loss: 0.14076347649097443\n",
      "Iteration: 15/306, Loss: 0.05090123787522316\n",
      "Iteration: 16/306, Loss: 1.301619291305542\n",
      "Iteration: 17/306, Loss: 0.3083631098270416\n",
      "Iteration: 18/306, Loss: 0.053040582686662674\n",
      "Iteration: 19/306, Loss: 0.1917286068201065\n",
      "Iteration: 20/306, Loss: 0.4081965386867523\n",
      "Iteration: 21/306, Loss: 0.6592804789543152\n",
      "Iteration: 22/306, Loss: 0.603597104549408\n",
      "Iteration: 23/306, Loss: 0.10545287281274796\n",
      "Iteration: 24/306, Loss: 0.26562726497650146\n",
      "Iteration: 25/306, Loss: 0.5727077722549438\n",
      "Iteration: 26/306, Loss: 0.27306437492370605\n",
      "Iteration: 27/306, Loss: 0.377069890499115\n",
      "Iteration: 28/306, Loss: 0.47891372442245483\n",
      "Iteration: 29/306, Loss: 0.37134894728660583\n",
      "Iteration: 30/306, Loss: 0.5341745615005493\n",
      "Iteration: 31/306, Loss: 0.5541241765022278\n",
      "Iteration: 32/306, Loss: 0.23292365670204163\n",
      "Iteration: 33/306, Loss: 0.3193454146385193\n",
      "Iteration: 34/306, Loss: 0.20248043537139893\n",
      "Iteration: 35/306, Loss: 0.3534935712814331\n",
      "Iteration: 36/306, Loss: 0.41288813948631287\n",
      "Iteration: 37/306, Loss: 0.5505727529525757\n",
      "Iteration: 38/306, Loss: 0.4599858522415161\n",
      "Iteration: 39/306, Loss: 0.3795705735683441\n",
      "Iteration: 40/306, Loss: 0.14480894804000854\n",
      "Iteration: 41/306, Loss: 0.23669199645519257\n",
      "Iteration: 42/306, Loss: 0.16148222982883453\n",
      "Iteration: 43/306, Loss: 0.11162425577640533\n",
      "Iteration: 44/306, Loss: 0.029968559741973877\n",
      "Iteration: 45/306, Loss: 0.17065031826496124\n",
      "Iteration: 46/306, Loss: 0.16433881223201752\n",
      "Iteration: 47/306, Loss: 0.35772669315338135\n",
      "Iteration: 48/306, Loss: 0.2663232982158661\n",
      "Iteration: 49/306, Loss: 0.3568021059036255\n",
      "Iteration: 50/306, Loss: 0.32085657119750977\n",
      "Iteration: 51/306, Loss: 0.19265195727348328\n",
      "Iteration: 52/306, Loss: 0.14195124804973602\n",
      "Iteration: 53/306, Loss: 0.08372306078672409\n",
      "Iteration: 54/306, Loss: 0.20078697800636292\n",
      "Iteration: 55/306, Loss: 0.18543624877929688\n",
      "Iteration: 56/306, Loss: 0.5563849806785583\n",
      "Iteration: 57/306, Loss: 0.2497909516096115\n",
      "Iteration: 58/306, Loss: 0.3790760040283203\n",
      "Iteration: 59/306, Loss: 0.3807428181171417\n",
      "Iteration: 60/306, Loss: 0.38148871064186096\n",
      "Iteration: 61/306, Loss: 0.2529274523258209\n",
      "Iteration: 62/306, Loss: 0.2151968777179718\n",
      "Iteration: 63/306, Loss: 0.23038800060749054\n",
      "Iteration: 64/306, Loss: 0.28811123967170715\n",
      "Iteration: 65/306, Loss: 0.11794894933700562\n",
      "Iteration: 66/306, Loss: 0.39366060495376587\n",
      "Iteration: 67/306, Loss: 0.646378219127655\n",
      "Iteration: 68/306, Loss: 0.16607409715652466\n",
      "Iteration: 69/306, Loss: 0.16797780990600586\n",
      "Iteration: 70/306, Loss: 0.15660716593265533\n",
      "Iteration: 71/306, Loss: 0.03178851678967476\n",
      "Iteration: 72/306, Loss: 0.5522856712341309\n",
      "Iteration: 73/306, Loss: 0.607462465763092\n",
      "Iteration: 74/306, Loss: 0.29094231128692627\n",
      "Iteration: 75/306, Loss: 0.2506504952907562\n",
      "Iteration: 76/306, Loss: 0.23744569718837738\n",
      "Iteration: 77/306, Loss: 0.5325530171394348\n",
      "Iteration: 78/306, Loss: 0.2058885097503662\n",
      "Iteration: 79/306, Loss: 0.5960267782211304\n",
      "Iteration: 80/306, Loss: 0.5153069496154785\n",
      "Iteration: 81/306, Loss: 0.38362136483192444\n",
      "Iteration: 82/306, Loss: 0.06745221465826035\n",
      "Iteration: 83/306, Loss: 0.2469431310892105\n",
      "Iteration: 84/306, Loss: 0.016889791935682297\n",
      "Iteration: 85/306, Loss: 0.1491529643535614\n",
      "Iteration: 86/306, Loss: 0.1857367753982544\n",
      "Iteration: 87/306, Loss: 0.4760497808456421\n",
      "Iteration: 88/306, Loss: 0.6640679240226746\n",
      "Iteration: 89/306, Loss: 0.059196677058935165\n",
      "Iteration: 90/306, Loss: 0.4027692675590515\n",
      "Iteration: 91/306, Loss: 0.2020532488822937\n",
      "Iteration: 92/306, Loss: 0.05393581837415695\n",
      "Iteration: 93/306, Loss: 0.12572184205055237\n",
      "Iteration: 94/306, Loss: 0.651919424533844\n",
      "Iteration: 95/306, Loss: 0.37261679768562317\n",
      "Iteration: 96/306, Loss: 0.05382413789629936\n",
      "Iteration: 97/306, Loss: 0.20136958360671997\n",
      "Iteration: 98/306, Loss: 0.2819620966911316\n",
      "Iteration: 99/306, Loss: 0.025096070021390915\n",
      "Iteration: 100/306, Loss: 0.06401537358760834\n",
      "Iteration: 101/306, Loss: 0.20965126156806946\n",
      "Iteration: 102/306, Loss: 0.24424217641353607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 103/306, Loss: 0.5699602961540222\n",
      "Iteration: 104/306, Loss: 0.2122509777545929\n",
      "Iteration: 105/306, Loss: 0.15563459694385529\n",
      "Iteration: 106/306, Loss: 0.10743927955627441\n",
      "Iteration: 107/306, Loss: 0.9053819179534912\n",
      "Iteration: 108/306, Loss: 0.14967679977416992\n",
      "Iteration: 109/306, Loss: 0.12277568131685257\n",
      "Iteration: 110/306, Loss: 0.4598568379878998\n",
      "Iteration: 111/306, Loss: 0.19253472983837128\n",
      "Iteration: 112/306, Loss: 0.16669109463691711\n",
      "Iteration: 113/306, Loss: 0.09232039004564285\n",
      "Iteration: 114/306, Loss: 0.7769006490707397\n",
      "Iteration: 115/306, Loss: 0.20090289413928986\n",
      "Iteration: 116/306, Loss: 0.3361425995826721\n",
      "Iteration: 117/306, Loss: 0.36127769947052\n",
      "Iteration: 118/306, Loss: 0.36424174904823303\n",
      "Iteration: 119/306, Loss: 0.5355062484741211\n",
      "Iteration: 120/306, Loss: 0.211943119764328\n",
      "Iteration: 121/306, Loss: 0.1618557572364807\n",
      "Iteration: 122/306, Loss: 0.10393545776605606\n",
      "Iteration: 123/306, Loss: 0.15912124514579773\n",
      "Iteration: 124/306, Loss: 0.04033622890710831\n",
      "Iteration: 125/306, Loss: 0.7973904013633728\n",
      "Iteration: 126/306, Loss: 0.20244623720645905\n",
      "Iteration: 127/306, Loss: 0.2659721374511719\n",
      "Iteration: 128/306, Loss: 0.35434404015541077\n",
      "Iteration: 129/306, Loss: 0.6023480892181396\n",
      "Iteration: 130/306, Loss: 0.12607163190841675\n",
      "Iteration: 131/306, Loss: 0.520470142364502\n",
      "Iteration: 132/306, Loss: 0.18381372094154358\n",
      "Iteration: 133/306, Loss: 0.12900497019290924\n",
      "Iteration: 134/306, Loss: 0.4592348635196686\n",
      "Iteration: 135/306, Loss: 0.36739012598991394\n",
      "Iteration: 136/306, Loss: 0.13144603371620178\n",
      "Iteration: 137/306, Loss: 0.3979721665382385\n",
      "Iteration: 138/306, Loss: 0.27719712257385254\n",
      "Iteration: 139/306, Loss: 0.024813231080770493\n",
      "Iteration: 140/306, Loss: 0.6900744438171387\n",
      "Iteration: 141/306, Loss: 0.1606966257095337\n",
      "Iteration: 142/306, Loss: 0.2050933688879013\n",
      "Iteration: 143/306, Loss: 0.06758131831884384\n",
      "Iteration: 144/306, Loss: 0.13842660188674927\n",
      "Iteration: 145/306, Loss: 0.3573533892631531\n",
      "Iteration: 146/306, Loss: 0.25544479489326477\n",
      "Iteration: 147/306, Loss: 0.31075358390808105\n",
      "Iteration: 148/306, Loss: 0.36180293560028076\n",
      "Iteration: 149/306, Loss: 0.15134727954864502\n",
      "Iteration: 150/306, Loss: 1.12538480758667\n",
      "Iteration: 151/306, Loss: 0.15634532272815704\n",
      "Iteration: 152/306, Loss: 0.10985158383846283\n",
      "Iteration: 153/306, Loss: 0.3186578154563904\n",
      "Iteration: 154/306, Loss: 0.6804578900337219\n",
      "Iteration: 155/306, Loss: 0.18427978456020355\n",
      "Iteration: 156/306, Loss: 0.1028878390789032\n",
      "Iteration: 157/306, Loss: 0.62845778465271\n",
      "Iteration: 158/306, Loss: 0.6195316910743713\n",
      "Iteration: 159/306, Loss: 0.4850797653198242\n",
      "Iteration: 160/306, Loss: 0.25225961208343506\n",
      "Iteration: 161/306, Loss: 0.20606297254562378\n",
      "Iteration: 162/306, Loss: 0.2250765711069107\n",
      "Iteration: 163/306, Loss: 0.2539174258708954\n",
      "Iteration: 164/306, Loss: 0.5407780408859253\n",
      "Iteration: 165/306, Loss: 0.2255106270313263\n",
      "Iteration: 166/306, Loss: 0.1673969179391861\n",
      "Iteration: 167/306, Loss: 0.2516513466835022\n",
      "Iteration: 168/306, Loss: 0.1510656625032425\n",
      "Iteration: 169/306, Loss: 0.774315595626831\n",
      "Iteration: 170/306, Loss: 0.19236843287944794\n",
      "Iteration: 171/306, Loss: 0.23494066298007965\n",
      "Iteration: 172/306, Loss: 0.4110214412212372\n",
      "Iteration: 173/306, Loss: 0.3913334012031555\n",
      "Iteration: 174/306, Loss: 0.17145611345767975\n",
      "Iteration: 175/306, Loss: 0.2467528134584427\n",
      "Iteration: 176/306, Loss: 0.19649676978588104\n",
      "Iteration: 177/306, Loss: 0.1961396187543869\n",
      "Iteration: 178/306, Loss: 0.41249027848243713\n",
      "Iteration: 179/306, Loss: 0.19389909505844116\n",
      "Iteration: 180/306, Loss: 1.2399317026138306\n",
      "Iteration: 181/306, Loss: 0.41435813903808594\n",
      "Iteration: 182/306, Loss: 0.5974083542823792\n",
      "Iteration: 183/306, Loss: 0.21122083067893982\n",
      "Iteration: 184/306, Loss: 0.19834262132644653\n",
      "Iteration: 185/306, Loss: 0.2914268672466278\n",
      "Iteration: 186/306, Loss: 1.1279683113098145\n",
      "Iteration: 187/306, Loss: 0.3458578288555145\n",
      "Iteration: 188/306, Loss: 0.3869856894016266\n",
      "Iteration: 189/306, Loss: 0.21470284461975098\n",
      "Iteration: 190/306, Loss: 0.5885422825813293\n",
      "Iteration: 191/306, Loss: 0.38650819659233093\n",
      "Iteration: 192/306, Loss: 0.1781688630580902\n",
      "Iteration: 193/306, Loss: 0.536700963973999\n",
      "Iteration: 194/306, Loss: 0.3910311162471771\n",
      "Iteration: 195/306, Loss: 0.5650198459625244\n",
      "Iteration: 196/306, Loss: 0.26517996191978455\n",
      "Iteration: 197/306, Loss: 0.07258643209934235\n",
      "Iteration: 198/306, Loss: 0.20275957882404327\n",
      "Iteration: 199/306, Loss: 0.21987371146678925\n",
      "Iteration: 200/306, Loss: 0.2027878314256668\n",
      "Iteration: 201/306, Loss: 0.2169792354106903\n",
      "Iteration: 202/306, Loss: 0.6027176976203918\n",
      "Iteration: 203/306, Loss: 0.16592030227184296\n",
      "Iteration: 204/306, Loss: 0.06904294341802597\n",
      "Iteration: 205/306, Loss: 0.40758639574050903\n",
      "Iteration: 206/306, Loss: 0.5967816114425659\n",
      "Iteration: 207/306, Loss: 0.46961066126823425\n",
      "Iteration: 208/306, Loss: 0.14781144261360168\n",
      "Iteration: 209/306, Loss: 0.19871294498443604\n",
      "Iteration: 210/306, Loss: 0.4017687737941742\n",
      "Iteration: 211/306, Loss: 0.3570639193058014\n",
      "Iteration: 212/306, Loss: 0.1718558967113495\n",
      "Iteration: 213/306, Loss: 0.07838425785303116\n",
      "Iteration: 214/306, Loss: 0.14328904449939728\n",
      "Iteration: 215/306, Loss: 0.3685150444507599\n",
      "Iteration: 216/306, Loss: 0.13763213157653809\n",
      "Iteration: 217/306, Loss: 1.3410524129867554\n",
      "Iteration: 218/306, Loss: 0.36533844470977783\n",
      "Iteration: 219/306, Loss: 0.1809200644493103\n",
      "Iteration: 220/306, Loss: 0.2450123131275177\n",
      "Iteration: 221/306, Loss: 0.18018025159835815\n",
      "Iteration: 222/306, Loss: 0.2340853214263916\n",
      "Iteration: 223/306, Loss: 0.19449149072170258\n",
      "Iteration: 224/306, Loss: 0.21229703724384308\n",
      "Iteration: 225/306, Loss: 0.5940512418746948\n",
      "Iteration: 226/306, Loss: 0.2539122700691223\n",
      "Iteration: 227/306, Loss: 0.20711423456668854\n",
      "Iteration: 228/306, Loss: 0.3035769462585449\n",
      "Iteration: 229/306, Loss: 0.14301089942455292\n",
      "Iteration: 230/306, Loss: 0.6554480791091919\n",
      "Iteration: 231/306, Loss: 0.33250099420547485\n",
      "Iteration: 232/306, Loss: 0.18432089686393738\n",
      "Iteration: 233/306, Loss: 0.7344695329666138\n",
      "Iteration: 234/306, Loss: 0.18294042348861694\n",
      "Iteration: 235/306, Loss: 0.2252998650074005\n",
      "Iteration: 236/306, Loss: 0.4300084114074707\n",
      "Iteration: 237/306, Loss: 0.049620773643255234\n",
      "Iteration: 238/306, Loss: 0.1342836618423462\n",
      "Iteration: 239/306, Loss: 0.2940939664840698\n",
      "Iteration: 240/306, Loss: 0.19414840638637543\n",
      "Iteration: 241/306, Loss: 0.15791167318820953\n",
      "Iteration: 242/306, Loss: 0.27492791414260864\n",
      "Iteration: 243/306, Loss: 0.1926439255475998\n",
      "Iteration: 244/306, Loss: 0.5435146689414978\n",
      "Iteration: 245/306, Loss: 0.35048800706863403\n",
      "Iteration: 246/306, Loss: 0.15017150342464447\n",
      "Iteration: 247/306, Loss: 0.1514907032251358\n",
      "Iteration: 248/306, Loss: 0.19227167963981628\n",
      "Iteration: 249/306, Loss: 0.31446415185928345\n",
      "Iteration: 250/306, Loss: 0.3848569393157959\n",
      "Iteration: 251/306, Loss: 0.17606407403945923\n",
      "Iteration: 252/306, Loss: 0.13356143236160278\n",
      "Iteration: 253/306, Loss: 0.9157296419143677\n",
      "Iteration: 254/306, Loss: 0.1937672644853592\n",
      "Iteration: 255/306, Loss: 0.45382747054100037\n",
      "Iteration: 256/306, Loss: 0.268618106842041\n",
      "Iteration: 257/306, Loss: 0.25102320313453674\n",
      "Iteration: 258/306, Loss: 0.23812127113342285\n",
      "Iteration: 259/306, Loss: 0.6663773059844971\n",
      "Iteration: 260/306, Loss: 0.17959856986999512\n",
      "Iteration: 261/306, Loss: 0.34723275899887085\n",
      "Iteration: 262/306, Loss: 0.30402812361717224\n",
      "Iteration: 263/306, Loss: 0.19789361953735352\n",
      "Iteration: 264/306, Loss: 0.27861177921295166\n",
      "Iteration: 265/306, Loss: 0.2067803591489792\n",
      "Iteration: 266/306, Loss: 0.4171503186225891\n",
      "Iteration: 267/306, Loss: 0.17929747700691223\n",
      "Iteration: 268/306, Loss: 0.27025386691093445\n",
      "Iteration: 269/306, Loss: 0.23949474096298218\n",
      "Iteration: 270/306, Loss: 0.03888929262757301\n",
      "Iteration: 271/306, Loss: 0.48556530475616455\n",
      "Iteration: 272/306, Loss: 0.2331586331129074\n",
      "Iteration: 273/306, Loss: 0.021809808909893036\n",
      "Iteration: 274/306, Loss: 0.44067034125328064\n",
      "Iteration: 275/306, Loss: 0.5434970259666443\n",
      "Iteration: 276/306, Loss: 0.23798340559005737\n",
      "Iteration: 277/306, Loss: 0.5246503949165344\n",
      "Iteration: 278/306, Loss: 0.2986302673816681\n",
      "Iteration: 279/306, Loss: 0.19422398507595062\n",
      "Iteration: 280/306, Loss: 0.0655198022723198\n",
      "Iteration: 281/306, Loss: 0.19627396762371063\n",
      "Iteration: 282/306, Loss: 0.16076241433620453\n",
      "Iteration: 283/306, Loss: 0.5030755996704102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 284/306, Loss: 0.14694249629974365\n",
      "Iteration: 285/306, Loss: 0.7846890091896057\n",
      "Iteration: 286/306, Loss: 0.40820249915122986\n",
      "Iteration: 287/306, Loss: 0.10610362887382507\n",
      "Iteration: 288/306, Loss: 0.3716142475605011\n",
      "Iteration: 289/306, Loss: 0.12633134424686432\n",
      "Iteration: 290/306, Loss: 0.16675931215286255\n",
      "Iteration: 291/306, Loss: 0.05529427528381348\n",
      "Iteration: 292/306, Loss: 0.1642695963382721\n",
      "Iteration: 293/306, Loss: 0.5056350231170654\n",
      "Iteration: 294/306, Loss: 0.7660959959030151\n",
      "Iteration: 295/306, Loss: 0.26870161294937134\n",
      "Iteration: 296/306, Loss: 0.466653436422348\n",
      "Iteration: 297/306, Loss: 1.0207377672195435\n",
      "Iteration: 298/306, Loss: 0.26435261964797974\n",
      "Iteration: 299/306, Loss: 0.3078854978084564\n",
      "Iteration: 300/306, Loss: 0.18894393742084503\n",
      "Iteration: 301/306, Loss: 0.2948247492313385\n",
      "Iteration: 302/306, Loss: 0.6463038921356201\n",
      "Iteration: 303/306, Loss: 0.28473764657974243\n",
      "Iteration: 304/306, Loss: 1.1179488897323608\n",
      "Iteration: 305/306, Loss: 0.3789626657962799\n",
      "Iteration: 306/306, Loss: 0.4184851348400116\n",
      "Epoch: 9/10\n",
      "Iteration: 1/306, Loss: 0.21543516218662262\n",
      "Iteration: 2/306, Loss: 0.3997299373149872\n",
      "Iteration: 3/306, Loss: 0.06457246840000153\n",
      "Iteration: 4/306, Loss: 0.4562932848930359\n",
      "Iteration: 5/306, Loss: 0.19710329174995422\n",
      "Iteration: 6/306, Loss: 0.16941986978054047\n",
      "Iteration: 7/306, Loss: 0.448110431432724\n",
      "Iteration: 8/306, Loss: 0.5279379487037659\n",
      "Iteration: 9/306, Loss: 0.4234243631362915\n",
      "Iteration: 10/306, Loss: 0.974191427230835\n",
      "Iteration: 11/306, Loss: 0.2722820043563843\n",
      "Iteration: 12/306, Loss: 0.10388178378343582\n",
      "Iteration: 13/306, Loss: 0.2758215665817261\n",
      "Iteration: 14/306, Loss: 0.6584333181381226\n",
      "Iteration: 15/306, Loss: 1.116837978363037\n",
      "Iteration: 16/306, Loss: 0.23202663660049438\n",
      "Iteration: 17/306, Loss: 0.308133989572525\n",
      "Iteration: 18/306, Loss: 0.5233972072601318\n",
      "Iteration: 19/306, Loss: 1.053168773651123\n",
      "Iteration: 20/306, Loss: 0.14956173300743103\n",
      "Iteration: 21/306, Loss: 0.2946694791316986\n",
      "Iteration: 22/306, Loss: 0.6187238693237305\n",
      "Iteration: 23/306, Loss: 0.3025951385498047\n",
      "Iteration: 24/306, Loss: 0.1940293163061142\n",
      "Iteration: 25/306, Loss: 0.24184660613536835\n",
      "Iteration: 26/306, Loss: 0.11547251045703888\n",
      "Iteration: 27/306, Loss: 0.23794403672218323\n",
      "Iteration: 28/306, Loss: 0.49333858489990234\n",
      "Iteration: 29/306, Loss: 0.11156125366687775\n",
      "Iteration: 30/306, Loss: 0.2087881714105606\n",
      "Iteration: 31/306, Loss: 0.354775607585907\n",
      "Iteration: 32/306, Loss: 1.2573833465576172\n",
      "Iteration: 33/306, Loss: 0.3346969783306122\n",
      "Iteration: 34/306, Loss: 0.46013402938842773\n",
      "Iteration: 35/306, Loss: 0.29426082968711853\n",
      "Iteration: 36/306, Loss: 0.3531932532787323\n",
      "Iteration: 37/306, Loss: 0.20639896392822266\n",
      "Iteration: 38/306, Loss: 0.17426976561546326\n",
      "Iteration: 39/306, Loss: 0.7154356837272644\n",
      "Iteration: 40/306, Loss: 0.38032737374305725\n",
      "Iteration: 41/306, Loss: 0.40308070182800293\n",
      "Iteration: 42/306, Loss: 0.43398240208625793\n",
      "Iteration: 43/306, Loss: 0.2152736783027649\n",
      "Iteration: 44/306, Loss: 0.5054972171783447\n",
      "Iteration: 45/306, Loss: 0.438497930765152\n",
      "Iteration: 46/306, Loss: 0.19178271293640137\n",
      "Iteration: 47/306, Loss: 0.47116518020629883\n",
      "Iteration: 48/306, Loss: 0.16008113324642181\n",
      "Iteration: 49/306, Loss: 0.3581802546977997\n",
      "Iteration: 50/306, Loss: 0.3421265482902527\n",
      "Iteration: 51/306, Loss: 0.24416278302669525\n",
      "Iteration: 52/306, Loss: 0.3235277533531189\n",
      "Iteration: 53/306, Loss: 0.41814252734184265\n",
      "Iteration: 54/306, Loss: 0.6754051446914673\n",
      "Iteration: 55/306, Loss: 0.06323325634002686\n",
      "Iteration: 56/306, Loss: 0.279377818107605\n",
      "Iteration: 57/306, Loss: 0.0712650790810585\n",
      "Iteration: 58/306, Loss: 0.1672135293483734\n",
      "Iteration: 59/306, Loss: 0.16059628129005432\n",
      "Iteration: 60/306, Loss: 0.16697198152542114\n",
      "Iteration: 61/306, Loss: 0.061824724078178406\n",
      "Iteration: 62/306, Loss: 0.2141185998916626\n",
      "Iteration: 63/306, Loss: 0.40832701325416565\n",
      "Iteration: 64/306, Loss: 0.8118965029716492\n",
      "Iteration: 65/306, Loss: 0.1168183907866478\n",
      "Iteration: 66/306, Loss: 0.36574622988700867\n",
      "Iteration: 67/306, Loss: 0.1266261339187622\n",
      "Iteration: 68/306, Loss: 0.13189060986042023\n",
      "Iteration: 69/306, Loss: 0.5592657923698425\n",
      "Iteration: 70/306, Loss: 0.15672601759433746\n",
      "Iteration: 71/306, Loss: 0.1928555816411972\n",
      "Iteration: 72/306, Loss: 0.03550948202610016\n",
      "Iteration: 73/306, Loss: 0.03201552480459213\n",
      "Iteration: 74/306, Loss: 0.1678156852722168\n",
      "Iteration: 75/306, Loss: 0.1471249759197235\n",
      "Iteration: 76/306, Loss: 0.13964854180812836\n",
      "Iteration: 77/306, Loss: 0.3311154246330261\n",
      "Iteration: 78/306, Loss: 0.5214768648147583\n",
      "Iteration: 79/306, Loss: 0.5679737329483032\n",
      "Iteration: 80/306, Loss: 0.19830206036567688\n",
      "Iteration: 81/306, Loss: 0.20260348916053772\n",
      "Iteration: 82/306, Loss: 0.1366654485464096\n",
      "Iteration: 83/306, Loss: 0.1557329148054123\n",
      "Iteration: 84/306, Loss: 0.49002769589424133\n",
      "Iteration: 85/306, Loss: 0.9286935329437256\n",
      "Iteration: 86/306, Loss: 0.06669174134731293\n",
      "Iteration: 87/306, Loss: 0.3838212490081787\n",
      "Iteration: 88/306, Loss: 0.8344395756721497\n",
      "Iteration: 89/306, Loss: 0.2707351744174957\n",
      "Iteration: 90/306, Loss: 0.22977681457996368\n",
      "Iteration: 91/306, Loss: 0.1934213787317276\n",
      "Iteration: 92/306, Loss: 0.12462125718593597\n",
      "Iteration: 93/306, Loss: 0.1646878719329834\n",
      "Iteration: 94/306, Loss: 0.15099230408668518\n",
      "Iteration: 95/306, Loss: 0.16100221872329712\n",
      "Iteration: 96/306, Loss: 0.7179390788078308\n",
      "Iteration: 97/306, Loss: 0.031155088916420937\n",
      "Iteration: 98/306, Loss: 0.37153735756874084\n",
      "Iteration: 99/306, Loss: 0.1806105524301529\n",
      "Iteration: 100/306, Loss: 0.3083435297012329\n",
      "Iteration: 101/306, Loss: 0.13796955347061157\n",
      "Iteration: 102/306, Loss: 0.524179220199585\n",
      "Iteration: 103/306, Loss: 0.3839951157569885\n",
      "Iteration: 104/306, Loss: 0.10165552794933319\n",
      "Iteration: 105/306, Loss: 0.24478194117546082\n",
      "Iteration: 106/306, Loss: 0.6613106727600098\n",
      "Iteration: 107/306, Loss: 0.5349608063697815\n",
      "Iteration: 108/306, Loss: 0.571700930595398\n",
      "Iteration: 109/306, Loss: 0.05317538604140282\n",
      "Iteration: 110/306, Loss: 0.12205611169338226\n",
      "Iteration: 111/306, Loss: 0.18062135577201843\n",
      "Iteration: 112/306, Loss: 0.21327926218509674\n",
      "Iteration: 113/306, Loss: 0.5084854960441589\n",
      "Iteration: 114/306, Loss: 0.20054660737514496\n",
      "Iteration: 115/306, Loss: 0.5723628997802734\n",
      "Iteration: 116/306, Loss: 0.2965761423110962\n",
      "Iteration: 117/306, Loss: 0.204304039478302\n",
      "Iteration: 118/306, Loss: 0.32399511337280273\n",
      "Iteration: 119/306, Loss: 0.2566485106945038\n",
      "Iteration: 120/306, Loss: 0.4350956976413727\n",
      "Iteration: 121/306, Loss: 0.1926928609609604\n",
      "Iteration: 122/306, Loss: 0.09869319200515747\n",
      "Iteration: 123/306, Loss: 0.2191017121076584\n",
      "Iteration: 124/306, Loss: 0.5054004192352295\n",
      "Iteration: 125/306, Loss: 1.1224833726882935\n",
      "Iteration: 126/306, Loss: 0.24766214191913605\n",
      "Iteration: 127/306, Loss: 0.307829886674881\n",
      "Iteration: 128/306, Loss: 0.0911644846200943\n",
      "Iteration: 129/306, Loss: 0.27499303221702576\n",
      "Iteration: 130/306, Loss: 0.3264085054397583\n",
      "Iteration: 131/306, Loss: 0.5871767997741699\n",
      "Iteration: 132/306, Loss: 0.316861093044281\n",
      "Iteration: 133/306, Loss: 0.17953620851039886\n",
      "Iteration: 134/306, Loss: 0.07782618701457977\n",
      "Iteration: 135/306, Loss: 0.38638004660606384\n",
      "Iteration: 136/306, Loss: 0.03093830868601799\n",
      "Iteration: 137/306, Loss: 0.5564704537391663\n",
      "Iteration: 138/306, Loss: 0.2695184648036957\n",
      "Iteration: 139/306, Loss: 0.15997928380966187\n",
      "Iteration: 140/306, Loss: 0.23397928476333618\n",
      "Iteration: 141/306, Loss: 0.24365732073783875\n",
      "Iteration: 142/306, Loss: 0.18167316913604736\n",
      "Iteration: 143/306, Loss: 0.45577383041381836\n",
      "Iteration: 144/306, Loss: 0.32162612676620483\n",
      "Iteration: 145/306, Loss: 0.1757611334323883\n",
      "Iteration: 146/306, Loss: 0.2535909116268158\n",
      "Iteration: 147/306, Loss: 0.16145886480808258\n",
      "Iteration: 148/306, Loss: 0.11980656534433365\n",
      "Iteration: 149/306, Loss: 0.15167136490345\n",
      "Iteration: 150/306, Loss: 0.5862300992012024\n",
      "Iteration: 151/306, Loss: 0.3664172887802124\n",
      "Iteration: 152/306, Loss: 0.23523947596549988\n",
      "Iteration: 153/306, Loss: 0.283023476600647\n",
      "Iteration: 154/306, Loss: 0.2092195600271225\n",
      "Iteration: 155/306, Loss: 0.031597282737493515\n",
      "Iteration: 156/306, Loss: 0.5194138288497925\n",
      "Iteration: 157/306, Loss: 0.29462990164756775\n",
      "Iteration: 158/306, Loss: 0.23870958387851715\n",
      "Iteration: 159/306, Loss: 0.4323924481868744\n",
      "Iteration: 160/306, Loss: 0.23119832575321198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 161/306, Loss: 0.1602451652288437\n",
      "Iteration: 162/306, Loss: 0.2548167109489441\n",
      "Iteration: 163/306, Loss: 0.21647630631923676\n",
      "Iteration: 164/306, Loss: 0.3430529832839966\n",
      "Iteration: 165/306, Loss: 0.06602606922388077\n",
      "Iteration: 166/306, Loss: 0.15227000415325165\n",
      "Iteration: 167/306, Loss: 0.2299133688211441\n",
      "Iteration: 168/306, Loss: 0.47380173206329346\n",
      "Iteration: 169/306, Loss: 0.9097393751144409\n",
      "Iteration: 170/306, Loss: 0.22431698441505432\n",
      "Iteration: 171/306, Loss: 0.1229451447725296\n",
      "Iteration: 172/306, Loss: 0.06952362507581711\n",
      "Iteration: 173/306, Loss: 0.07320340722799301\n",
      "Iteration: 174/306, Loss: 0.24880404770374298\n",
      "Iteration: 175/306, Loss: 0.30147671699523926\n",
      "Iteration: 176/306, Loss: 0.2933177053928375\n",
      "Iteration: 177/306, Loss: 0.29421988129615784\n",
      "Iteration: 178/306, Loss: 0.6127868294715881\n",
      "Iteration: 179/306, Loss: 0.5566725730895996\n",
      "Iteration: 180/306, Loss: 0.14877158403396606\n",
      "Iteration: 181/306, Loss: 0.16869403421878815\n",
      "Iteration: 182/306, Loss: 0.32465696334838867\n",
      "Iteration: 183/306, Loss: 0.30039435625076294\n",
      "Iteration: 184/306, Loss: 0.20495162904262543\n",
      "Iteration: 185/306, Loss: 0.13642339408397675\n",
      "Iteration: 186/306, Loss: 0.16157913208007812\n",
      "Iteration: 187/306, Loss: 0.42339667677879333\n",
      "Iteration: 188/306, Loss: 0.20528815686702728\n",
      "Iteration: 189/306, Loss: 0.1926657110452652\n",
      "Iteration: 190/306, Loss: 0.3879348337650299\n",
      "Iteration: 191/306, Loss: 0.30796608328819275\n",
      "Iteration: 192/306, Loss: 0.20002663135528564\n",
      "Iteration: 193/306, Loss: 0.21163462102413177\n",
      "Iteration: 194/306, Loss: 0.3530256152153015\n",
      "Iteration: 195/306, Loss: 0.3867303729057312\n",
      "Iteration: 196/306, Loss: 0.5176962018013\n",
      "Iteration: 197/306, Loss: 0.303464412689209\n",
      "Iteration: 198/306, Loss: 0.25214555859565735\n",
      "Iteration: 199/306, Loss: 0.5416704416275024\n",
      "Iteration: 200/306, Loss: 0.3164404034614563\n",
      "Iteration: 201/306, Loss: 0.28294578194618225\n",
      "Iteration: 202/306, Loss: 0.3117328882217407\n",
      "Iteration: 203/306, Loss: 0.1852254569530487\n",
      "Iteration: 204/306, Loss: 0.30845969915390015\n",
      "Iteration: 205/306, Loss: 0.19355736672878265\n",
      "Iteration: 206/306, Loss: 0.3417240083217621\n",
      "Iteration: 207/306, Loss: 0.5482682585716248\n",
      "Iteration: 208/306, Loss: 0.460143119096756\n",
      "Iteration: 209/306, Loss: 0.45949581265449524\n",
      "Iteration: 210/306, Loss: 0.2382134646177292\n",
      "Iteration: 211/306, Loss: 0.3068732023239136\n",
      "Iteration: 212/306, Loss: 0.6318680047988892\n",
      "Iteration: 213/306, Loss: 0.13386140763759613\n",
      "Iteration: 214/306, Loss: 0.22596971690654755\n",
      "Iteration: 215/306, Loss: 0.4780349135398865\n",
      "Iteration: 216/306, Loss: 0.2056991457939148\n",
      "Iteration: 217/306, Loss: 0.2861253321170807\n",
      "Iteration: 218/306, Loss: 0.24612659215927124\n",
      "Iteration: 219/306, Loss: 0.22208429872989655\n",
      "Iteration: 220/306, Loss: 0.1961485743522644\n",
      "Iteration: 221/306, Loss: 0.38773828744888306\n",
      "Iteration: 222/306, Loss: 0.5497795939445496\n",
      "Iteration: 223/306, Loss: 0.23155108094215393\n",
      "Iteration: 224/306, Loss: 0.28533849120140076\n",
      "Iteration: 225/306, Loss: 0.23854069411754608\n",
      "Iteration: 226/306, Loss: 0.7488144040107727\n",
      "Iteration: 227/306, Loss: 0.326891154050827\n",
      "Iteration: 228/306, Loss: 0.05093962326645851\n",
      "Iteration: 229/306, Loss: 0.2793711721897125\n",
      "Iteration: 230/306, Loss: 0.1073957309126854\n",
      "Iteration: 231/306, Loss: 0.4603777825832367\n",
      "Iteration: 232/306, Loss: 0.17737135291099548\n",
      "Iteration: 233/306, Loss: 0.15596312284469604\n",
      "Iteration: 234/306, Loss: 0.22555768489837646\n",
      "Iteration: 235/306, Loss: 0.3410295248031616\n",
      "Iteration: 236/306, Loss: 0.026944218203425407\n",
      "Iteration: 237/306, Loss: 0.6920514702796936\n",
      "Iteration: 238/306, Loss: 0.33015283942222595\n",
      "Iteration: 239/306, Loss: 0.19096016883850098\n",
      "Iteration: 240/306, Loss: 0.3949377238750458\n",
      "Iteration: 241/306, Loss: 0.5181615352630615\n",
      "Iteration: 242/306, Loss: 0.38740652799606323\n",
      "Iteration: 243/306, Loss: 0.5338675379753113\n",
      "Iteration: 244/306, Loss: 0.23619946837425232\n",
      "Iteration: 245/306, Loss: 0.3761221766471863\n",
      "Iteration: 246/306, Loss: 0.583924412727356\n",
      "Iteration: 247/306, Loss: 0.03272821009159088\n",
      "Iteration: 248/306, Loss: 0.683617115020752\n",
      "Iteration: 249/306, Loss: 0.15767964720726013\n",
      "Iteration: 250/306, Loss: 0.9369105696678162\n",
      "Iteration: 251/306, Loss: 0.1978757530450821\n",
      "Iteration: 252/306, Loss: 0.5176569223403931\n",
      "Iteration: 253/306, Loss: 0.8309726119041443\n",
      "Iteration: 254/306, Loss: 0.22660912573337555\n",
      "Iteration: 255/306, Loss: 0.37260058522224426\n",
      "Iteration: 256/306, Loss: 0.6003230810165405\n",
      "Iteration: 257/306, Loss: 0.5539133548736572\n",
      "Iteration: 258/306, Loss: 0.21637976169586182\n",
      "Iteration: 259/306, Loss: 0.25960493087768555\n",
      "Iteration: 260/306, Loss: 0.19485703110694885\n",
      "Iteration: 261/306, Loss: 0.40636682510375977\n",
      "Iteration: 262/306, Loss: 0.4596661329269409\n",
      "Iteration: 263/306, Loss: 0.14494918286800385\n",
      "Iteration: 264/306, Loss: 0.24567817151546478\n",
      "Iteration: 265/306, Loss: 0.8144206404685974\n",
      "Iteration: 266/306, Loss: 0.3074500262737274\n",
      "Iteration: 267/306, Loss: 0.49966904520988464\n",
      "Iteration: 268/306, Loss: 0.4518947899341583\n",
      "Iteration: 269/306, Loss: 0.16820712387561798\n",
      "Iteration: 270/306, Loss: 0.17258146405220032\n",
      "Iteration: 271/306, Loss: 0.3224667012691498\n",
      "Iteration: 272/306, Loss: 0.24016164243221283\n",
      "Iteration: 273/306, Loss: 0.47509175539016724\n",
      "Iteration: 274/306, Loss: 0.14606934785842896\n",
      "Iteration: 275/306, Loss: 0.2022479772567749\n",
      "Iteration: 276/306, Loss: 0.20582394301891327\n",
      "Iteration: 277/306, Loss: 0.3894847333431244\n",
      "Iteration: 278/306, Loss: 0.15386925637722015\n",
      "Iteration: 279/306, Loss: 0.06938087195158005\n",
      "Iteration: 280/306, Loss: 0.21499603986740112\n",
      "Iteration: 281/306, Loss: 0.19687531888484955\n",
      "Iteration: 282/306, Loss: 1.2710411548614502\n",
      "Iteration: 283/306, Loss: 0.6754294037818909\n",
      "Iteration: 284/306, Loss: 0.44903743267059326\n",
      "Iteration: 285/306, Loss: 0.4608492851257324\n",
      "Iteration: 286/306, Loss: 0.3720106780529022\n",
      "Iteration: 287/306, Loss: 0.10380426049232483\n",
      "Iteration: 288/306, Loss: 0.563544750213623\n",
      "Iteration: 289/306, Loss: 0.6442108750343323\n",
      "Iteration: 290/306, Loss: 0.1882062554359436\n",
      "Iteration: 291/306, Loss: 0.19575011730194092\n",
      "Iteration: 292/306, Loss: 0.44594594836235046\n",
      "Iteration: 293/306, Loss: 0.060496848076581955\n",
      "Iteration: 294/306, Loss: 0.4117775559425354\n",
      "Iteration: 295/306, Loss: 0.09694719314575195\n",
      "Iteration: 296/306, Loss: 0.18794824182987213\n",
      "Iteration: 297/306, Loss: 0.08884464204311371\n",
      "Iteration: 298/306, Loss: 0.14129777252674103\n",
      "Iteration: 299/306, Loss: 0.2990272641181946\n",
      "Iteration: 300/306, Loss: 0.2090827077627182\n",
      "Iteration: 301/306, Loss: 0.15209588408470154\n",
      "Iteration: 302/306, Loss: 0.18483415246009827\n",
      "Iteration: 303/306, Loss: 0.09338444471359253\n",
      "Iteration: 304/306, Loss: 0.14182527363300323\n",
      "Iteration: 305/306, Loss: 0.013157475739717484\n",
      "Iteration: 306/306, Loss: 0.20630818605422974\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version:\", torch.__version__)\n",
    "\n",
    "# create own Dataset\n",
    "my_dataset = myOwnDataset(\n",
    "    root=config.train_data_dir, annotation=config.train_coco, transforms=get_transform()\n",
    ")\n",
    "\n",
    "test = myOwnDataset(\n",
    "    root=config.test_data_dir, annotation=config.test_coco, transforms=get_transform()\n",
    ")\n",
    "\n",
    "# own DataLoader\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    my_dataset,\n",
    "    batch_size=config.train_batch_size,\n",
    "    shuffle=config.train_shuffle_dl,\n",
    "    num_workers=config.num_workers_dl,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "#test Dataloader\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "test, batch_size=1, shuffle=False, num_workers=0,\n",
    "collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "# select device (whether GPU or CPU)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print('Running on ', device)\n",
    "\n",
    "# DataLoader is iterable over Dataset\n",
    "for imgs, annotations in data_loader:\n",
    "    imgs = list(img.to(device) for img in imgs)\n",
    "    annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
    "    print(annotations)\n",
    "\n",
    "\n",
    "model = get_model_instance_segmentation(config.num_classes)\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# parameters\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(\n",
    "    params, lr=config.lr, momentum=config.momentum, weight_decay=config.weight_decay\n",
    ")\n",
    "\n",
    "len_dataloader = len(data_loader)\n",
    "\n",
    "# Training\n",
    "for epoch in range(config.num_epochs):\n",
    "    print(f\"Epoch: {epoch}/{config.num_epochs}\")\n",
    "    model.train()\n",
    "    i = 0\n",
    "    for imgs, annotations in data_loader:\n",
    "        i += 1\n",
    "        imgs = list(img.to(device) for img in imgs)\n",
    "        annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
    "        loss_dict = model(imgs, annotations)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Iteration: {i}/{len_dataloader}, Loss: {losses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e493a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './frcnn_net_evaluate.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e1d5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
